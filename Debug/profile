/* 
 * Command line: opannotate --source ./RPDE 
 * 
 * Interpretation of command line:
 * Output annotated source file with samples
 * Output all files
 * 
 * CPU: Intel Haswell microarchitecture, speed 2.301e+06 MHz (estimated)
 * Counted CPU_CLK_UNHALTED events (Clock cycles when not halted) with a unit mask of 0x00 (No unit mask) count 100000
 */
/* 
 * Total samples for file : "/build/buildd/eglibc-2.19/elf/dl-lookup.c"
 * 
 *      9 12.5000
 */


 /* do_lookup_x total:      6  8.3333 */
 /* check_match.9458 total:      2  2.7778 */
 /* _dl_lookup_symbol_x total:      1  1.3889 */
/* 
 * Total samples for file : "/usr/include/c++/4.6/bits/vector.tcc"
 * 
 *      3  4.1667
 */


               :// Vector implementation (out of line) -*- C++ -*-
               :
               :// Copyright (C) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,
               :// 2011 Free Software Foundation, Inc.
               ://
               :// This file is part of the GNU ISO C++ Library.  This library is free
               :// software; you can redistribute it and/or modify it under the
               :// terms of the GNU General Public License as published by the
               :// Free Software Foundation; either version 3, or (at your option)
               :// any later version.
               :
               :// This library is distributed in the hope that it will be useful,
               :// but WITHOUT ANY WARRANTY; without even the implied warranty of
               :// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
               :// GNU General Public License for more details.
               :
               :// Under Section 7 of GPL version 3, you are granted additional
               :// permissions described in the GCC Runtime Library Exception, version
               :// 3.1, as published by the Free Software Foundation.
               :
               :// You should have received a copy of the GNU General Public License and
               :// a copy of the GCC Runtime Library Exception along with this program;
               :// see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
               :// <http://www.gnu.org/licenses/>.
               :
               :/*
               : *
               : * Copyright (c) 1994
               : * Hewlett-Packard Company
               : *
               : * Permission to use, copy, modify, distribute and sell this software
               : * and its documentation for any purpose is hereby granted without fee,
               : * provided that the above copyright notice appear in all copies and
               : * that both that copyright notice and this permission notice appear
               : * in supporting documentation.  Hewlett-Packard Company makes no
               : * representations about the suitability of this software for any
               : * purpose.  It is provided "as is" without express or implied warranty.
               : *
               : *
               : * Copyright (c) 1996
               : * Silicon Graphics Computer Systems, Inc.
               : *
               : * Permission to use, copy, modify, distribute and sell this software
               : * and its documentation for any purpose is hereby granted without fee,
               : * provided that the above copyright notice appear in all copies and
               : * that both that copyright notice and this permission notice appear
               : * in supporting documentation.  Silicon Graphics makes no
               : * representations about the suitability of this  software for any
               : * purpose.  It is provided "as is" without express or implied warranty.
               : */
               :
               :/** @file bits/vector.tcc
               : *  This is an internal header file, included by other library headers.
               : *  Do not attempt to use it directly. @headername{vector}
               : */
               :
               :#ifndef _VECTOR_TCC
               :#define _VECTOR_TCC 1
               :
               :namespace std _GLIBCXX_VISIBILITY(default)
               :{
               :_GLIBCXX_BEGIN_NAMESPACE_CONTAINER
               :
               :  template<typename _Tp, typename _Alloc>
               :    void
               :    vector<_Tp, _Alloc>::
               :    reserve(size_type __n)
               :    {
               :      if (__n > this->max_size())
               :	__throw_length_error(__N("vector::reserve"));
               :      if (this->capacity() < __n)
               :	{
               :	  const size_type __old_size = size();
               :	  pointer __tmp = _M_allocate_and_copy(__n,
               :		 _GLIBCXX_MAKE_MOVE_ITERATOR(this->_M_impl._M_start),
               :		 _GLIBCXX_MAKE_MOVE_ITERATOR(this->_M_impl._M_finish));
               :	  std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
               :			_M_get_Tp_allocator());
               :	  _M_deallocate(this->_M_impl._M_start,
               :			this->_M_impl._M_end_of_storage
               :			- this->_M_impl._M_start);
               :	  this->_M_impl._M_start = __tmp;
               :	  this->_M_impl._M_finish = __tmp + __old_size;
               :	  this->_M_impl._M_end_of_storage = this->_M_impl._M_start + __n;
               :	}
               :    }
               :
               :#ifdef __GXX_EXPERIMENTAL_CXX0X__
               :  template<typename _Tp, typename _Alloc>
               :    template<typename... _Args>
               :      void
               :      vector<_Tp, _Alloc>::
               :      emplace_back(_Args&&... __args)
               :      {
               :	if (this->_M_impl._M_finish != this->_M_impl._M_end_of_storage)
               :	  {
               :	    this->_M_impl.construct(this->_M_impl._M_finish,
               :				    std::forward<_Args>(__args)...);
               :	    ++this->_M_impl._M_finish;
               :	  }
               :	else
               :	  _M_insert_aux(end(), std::forward<_Args>(__args)...);
               :      }
               :#endif
               :
               :  template<typename _Tp, typename _Alloc>
               :    typename vector<_Tp, _Alloc>::iterator
               :    vector<_Tp, _Alloc>::
               :    insert(iterator __position, const value_type& __x)
               :    {
               :      const size_type __n = __position - begin();
               :      if (this->_M_impl._M_finish != this->_M_impl._M_end_of_storage
               :	  && __position == end())
               :	{
               :	  this->_M_impl.construct(this->_M_impl._M_finish, __x);
               :	  ++this->_M_impl._M_finish;
               :	}
               :      else
               :	{
               :#ifdef __GXX_EXPERIMENTAL_CXX0X__
               :	  if (this->_M_impl._M_finish != this->_M_impl._M_end_of_storage)
               :	    {
               :	      _Tp __x_copy = __x;
               :	      _M_insert_aux(__position, std::move(__x_copy));
               :	    }
               :	  else
               :#endif
               :	    _M_insert_aux(__position, __x);
               :	}
               :      return iterator(this->_M_impl._M_start + __n);
               :    }
               :
               :  template<typename _Tp, typename _Alloc>
               :    typename vector<_Tp, _Alloc>::iterator
               :    vector<_Tp, _Alloc>::
               :    erase(iterator __position)
               :    {
               :      if (__position + 1 != end())
               :	_GLIBCXX_MOVE3(__position + 1, end(), __position);
               :      --this->_M_impl._M_finish;
               :      this->_M_impl.destroy(this->_M_impl._M_finish);
               :      return __position;
               :    }
               :
               :  template<typename _Tp, typename _Alloc>
               :    typename vector<_Tp, _Alloc>::iterator
               :    vector<_Tp, _Alloc>::
               :    erase(iterator __first, iterator __last)
               :    {
               :      if (__first != __last)
               :	{
               :	  if (__last != end())
               :	    _GLIBCXX_MOVE3(__last, end(), __first);
               :	  _M_erase_at_end(__first.base() + (end() - __last));
               :	}
               :      return __first;
               :    }
               :
               :  template<typename _Tp, typename _Alloc>
               :    vector<_Tp, _Alloc>&
               :    vector<_Tp, _Alloc>:: /* std::vector<Point, std::allocator<Point> >::operator=(std::vector<Point, std::allocator<Point> > const&) total:      1  1.3889 */
               :    operator=(const vector<_Tp, _Alloc>& __x)
               :    {
               :      if (&__x != this)
               :	{
               :	  const size_type __xlen = __x.size();
               :	  if (__xlen > capacity())
               :	    {
               :	      pointer __tmp = _M_allocate_and_copy(__xlen, __x.begin(),
               :						   __x.end());
               :	      std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
               :			    _M_get_Tp_allocator());
               :	      _M_deallocate(this->_M_impl._M_start,
               :			    this->_M_impl._M_end_of_storage
               :			    - this->_M_impl._M_start);
               :	      this->_M_impl._M_start = __tmp;
               :	      this->_M_impl._M_end_of_storage = this->_M_impl._M_start + __xlen;
               :	    }
               :	  else if (size() >= __xlen)
               :	    {
               :	      std::_Destroy(std::copy(__x.begin(), __x.end(), begin()),
               :			    end(), _M_get_Tp_allocator());
               :	    }
               :	  else
               :	    {
               :	      std::copy(__x._M_impl._M_start, __x._M_impl._M_start + size(),
               :			this->_M_impl._M_start);
               :	      std::__uninitialized_copy_a(__x._M_impl._M_start + size(),
               :					  __x._M_impl._M_finish,
               :					  this->_M_impl._M_finish,
               :					  _M_get_Tp_allocator());
               :	    }
               :	  this->_M_impl._M_finish = this->_M_impl._M_start + __xlen;
               :	}
               :      return *this;
     1  1.3889 :    }
               :
               :  template<typename _Tp, typename _Alloc>
               :    void
               :    vector<_Tp, _Alloc>::
               :    _M_fill_assign(size_t __n, const value_type& __val)
               :    {
               :      if (__n > capacity())
               :	{
               :	  vector __tmp(__n, __val, _M_get_Tp_allocator());
               :	  __tmp.swap(*this);
               :	}
               :      else if (__n > size())
               :	{
               :	  std::fill(begin(), end(), __val);
               :	  std::__uninitialized_fill_n_a(this->_M_impl._M_finish,
               :					__n - size(), __val,
               :					_M_get_Tp_allocator());
               :	  this->_M_impl._M_finish += __n - size();
               :	}
               :      else
               :        _M_erase_at_end(std::fill_n(this->_M_impl._M_start, __n, __val));
               :    }
               :
               :  template<typename _Tp, typename _Alloc>
               :    template<typename _InputIterator>
               :      void
               :      vector<_Tp, _Alloc>::
               :      _M_assign_aux(_InputIterator __first, _InputIterator __last,
               :		    std::input_iterator_tag)
               :      {
               :	pointer __cur(this->_M_impl._M_start);
               :	for (; __first != __last && __cur != this->_M_impl._M_finish;
               :	     ++__cur, ++__first)
               :	  *__cur = *__first;
               :	if (__first == __last)
               :	  _M_erase_at_end(__cur);
               :	else
               :	  insert(end(), __first, __last);
               :      }
               :
               :  template<typename _Tp, typename _Alloc>
               :    template<typename _ForwardIterator>
               :      void
               :      vector<_Tp, _Alloc>::
               :      _M_assign_aux(_ForwardIterator __first, _ForwardIterator __last,
               :		    std::forward_iterator_tag)
               :      {
               :	const size_type __len = std::distance(__first, __last);
               :
               :	if (__len > capacity())
               :	  {
               :	    pointer __tmp(_M_allocate_and_copy(__len, __first, __last));
               :	    std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
               :			  _M_get_Tp_allocator());
               :	    _M_deallocate(this->_M_impl._M_start,
               :			  this->_M_impl._M_end_of_storage
               :			  - this->_M_impl._M_start);
               :	    this->_M_impl._M_start = __tmp;
               :	    this->_M_impl._M_finish = this->_M_impl._M_start + __len;
               :	    this->_M_impl._M_end_of_storage = this->_M_impl._M_finish;
               :	  }
               :	else if (size() >= __len)
               :	  _M_erase_at_end(std::copy(__first, __last, this->_M_impl._M_start));
               :	else
               :	  {
               :	    _ForwardIterator __mid = __first;
               :	    std::advance(__mid, size());
               :	    std::copy(__first, __mid, this->_M_impl._M_start);
               :	    this->_M_impl._M_finish =
               :	      std::__uninitialized_copy_a(__mid, __last,
               :					  this->_M_impl._M_finish,
               :					  _M_get_Tp_allocator());
               :	  }
               :      }
               :
               :#ifdef __GXX_EXPERIMENTAL_CXX0X__
               :  template<typename _Tp, typename _Alloc>
               :    template<typename... _Args>
               :      typename vector<_Tp, _Alloc>::iterator
               :      vector<_Tp, _Alloc>::
               :      emplace(iterator __position, _Args&&... __args)
               :      {
               :	const size_type __n = __position - begin();
               :	if (this->_M_impl._M_finish != this->_M_impl._M_end_of_storage
               :	    && __position == end())
               :	  {
               :	    this->_M_impl.construct(this->_M_impl._M_finish,
               :				    std::forward<_Args>(__args)...);
               :	    ++this->_M_impl._M_finish;
               :	  }
               :	else
               :	  _M_insert_aux(__position, std::forward<_Args>(__args)...);
               :	return iterator(this->_M_impl._M_start + __n);
               :      }
               :
               :  template<typename _Tp, typename _Alloc>
               :    template<typename... _Args>
               :      void
               :      vector<_Tp, _Alloc>::
               :      _M_insert_aux(iterator __position, _Args&&... __args)
               :#else
               :  template<typename _Tp, typename _Alloc>
               :    void
               :    vector<_Tp, _Alloc>::
               :    _M_insert_aux(iterator __position, const _Tp& __x)
               :#endif
               :    {
               :      if (this->_M_impl._M_finish != this->_M_impl._M_end_of_storage)
               :	{
               :	  this->_M_impl.construct(this->_M_impl._M_finish,
               :				  _GLIBCXX_MOVE(*(this->_M_impl._M_finish
               :						  - 1)));
               :	  ++this->_M_impl._M_finish;
               :#ifndef __GXX_EXPERIMENTAL_CXX0X__
               :	  _Tp __x_copy = __x;
               :#endif
               :	  _GLIBCXX_MOVE_BACKWARD3(__position.base(),
               :				  this->_M_impl._M_finish - 2,
               :				  this->_M_impl._M_finish - 1);
               :#ifndef __GXX_EXPERIMENTAL_CXX0X__
               :	  *__position = __x_copy;
               :#else
               :	  *__position = _Tp(std::forward<_Args>(__args)...);
               :#endif
               :	}
               :      else
               :	{
               :	  const size_type __len =
               :	    _M_check_len(size_type(1), "vector::_M_insert_aux");
               :	  const size_type __elems_before = __position - begin();
               :	  pointer __new_start(this->_M_allocate(__len));
               :	  pointer __new_finish(__new_start);
               :	  __try
               :	    {
               :	      // The order of the three operations is dictated by the C++0x
               :	      // case, where the moves could alter a new element belonging
               :	      // to the existing vector.  This is an issue only for callers
               :	      // taking the element by const lvalue ref (see 23.1/13).
               :	      this->_M_impl.construct(__new_start + __elems_before,
               :#ifdef __GXX_EXPERIMENTAL_CXX0X__
               :				      std::forward<_Args>(__args)...);
               :#else
               :	                              __x);
               :#endif
               :	      __new_finish = 0;
               :
               :	      __new_finish =
               :		std::__uninitialized_move_a(this->_M_impl._M_start,
               :					    __position.base(), __new_start,
               :					    _M_get_Tp_allocator());
               :	      ++__new_finish;
               :
               :	      __new_finish =
               :		std::__uninitialized_move_a(__position.base(),
               :					    this->_M_impl._M_finish,
               :					    __new_finish,
               :					    _M_get_Tp_allocator());
               :	    }
               :          __catch(...)
               :	    {
               :	      if (!__new_finish)
               :		this->_M_impl.destroy(__new_start + __elems_before);
               :	      else
               :		std::_Destroy(__new_start, __new_finish, _M_get_Tp_allocator());
               :	      _M_deallocate(__new_start, __len);
               :	      __throw_exception_again;
               :	    }
               :	  std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
               :			_M_get_Tp_allocator());
               :	  _M_deallocate(this->_M_impl._M_start,
               :			this->_M_impl._M_end_of_storage
               :			- this->_M_impl._M_start);
               :	  this->_M_impl._M_start = __new_start;
               :	  this->_M_impl._M_finish = __new_finish;
               :	  this->_M_impl._M_end_of_storage = __new_start + __len;
               :	}
               :    }
               :
               :  template<typename _Tp, typename _Alloc>
               :    void
               :    vector<_Tp, _Alloc>::
               :    _M_fill_insert(iterator __position, size_type __n, const value_type& __x)
               :    {
               :      if (__n != 0)
               :	{
               :	  if (size_type(this->_M_impl._M_end_of_storage
               :			- this->_M_impl._M_finish) >= __n)
               :	    {
               :	      value_type __x_copy = __x;
               :	      const size_type __elems_after = end() - __position;
               :	      pointer __old_finish(this->_M_impl._M_finish);
               :	      if (__elems_after > __n)
               :		{
               :		  std::__uninitialized_move_a(this->_M_impl._M_finish - __n,
               :					      this->_M_impl._M_finish,
               :					      this->_M_impl._M_finish,
               :					      _M_get_Tp_allocator());
               :		  this->_M_impl._M_finish += __n;
               :		  _GLIBCXX_MOVE_BACKWARD3(__position.base(),
               :					  __old_finish - __n, __old_finish);
               :		  std::fill(__position.base(), __position.base() + __n,
               :			    __x_copy);
               :		}
               :	      else
               :		{
               :		  std::__uninitialized_fill_n_a(this->_M_impl._M_finish,
               :						__n - __elems_after,
               :						__x_copy,
               :						_M_get_Tp_allocator());
               :		  this->_M_impl._M_finish += __n - __elems_after;
               :		  std::__uninitialized_move_a(__position.base(), __old_finish,
               :					      this->_M_impl._M_finish,
               :					      _M_get_Tp_allocator());
               :		  this->_M_impl._M_finish += __elems_after;
               :		  std::fill(__position.base(), __old_finish, __x_copy);
               :		}
               :	    }
               :	  else
               :	    {
               :	      const size_type __len =
               :		_M_check_len(__n, "vector::_M_fill_insert");
               :	      const size_type __elems_before = __position - begin();
               :	      pointer __new_start(this->_M_allocate(__len));
               :	      pointer __new_finish(__new_start);
               :	      __try
               :		{
               :		  // See _M_insert_aux above.
               :		  std::__uninitialized_fill_n_a(__new_start + __elems_before,
               :						__n, __x,
               :						_M_get_Tp_allocator());
               :		  __new_finish = 0;
               :
               :		  __new_finish =
               :		    std::__uninitialized_move_a(this->_M_impl._M_start,
               :						__position.base(),
               :						__new_start,
               :						_M_get_Tp_allocator());
               :		  __new_finish += __n;
               :
               :		  __new_finish =
               :		    std::__uninitialized_move_a(__position.base(),
               :						this->_M_impl._M_finish,
               :						__new_finish,
               :						_M_get_Tp_allocator());
               :		}
               :	      __catch(...)
               :		{
               :		  if (!__new_finish)
               :		    std::_Destroy(__new_start + __elems_before,
               :				  __new_start + __elems_before + __n,
               :				  _M_get_Tp_allocator());
               :		  else
               :		    std::_Destroy(__new_start, __new_finish,
               :				  _M_get_Tp_allocator());
               :		  _M_deallocate(__new_start, __len);
               :		  __throw_exception_again;
               :		}
               :	      std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
               :			    _M_get_Tp_allocator());
               :	      _M_deallocate(this->_M_impl._M_start,
               :			    this->_M_impl._M_end_of_storage
               :			    - this->_M_impl._M_start);
               :	      this->_M_impl._M_start = __new_start;
               :	      this->_M_impl._M_finish = __new_finish;
               :	      this->_M_impl._M_end_of_storage = __new_start + __len;
               :	    }
               :	}
               :    }
               :
               :#ifdef __GXX_EXPERIMENTAL_CXX0X__
               :  template<typename _Tp, typename _Alloc>
               :    void
     1  1.3889 :    vector<_Tp, _Alloc>:: /* std::vector<double, std::allocator<double> >::_M_default_append(unsigned long) total:      2  2.7778 */
               :    _M_default_append(size_type __n)
               :    {
     1  1.3889 :      if (__n != 0)
               :	{
               :	  if (size_type(this->_M_impl._M_end_of_storage
               :			- this->_M_impl._M_finish) >= __n)
               :	    {
               :	      std::__uninitialized_default_n_a(this->_M_impl._M_finish,
               :					       __n, _M_get_Tp_allocator());
               :	      this->_M_impl._M_finish += __n;
               :	    }
               :	  else
               :	    {
               :	      const size_type __len =
               :		_M_check_len(__n, "vector::_M_default_append");
               :	      const size_type __old_size = this->size();
               :	      pointer __new_start(this->_M_allocate(__len));
               :	      pointer __new_finish(__new_start);
               :	      __try
               :		{
               :		  __new_finish =
               :		    std::__uninitialized_move_a(this->_M_impl._M_start,
               :						this->_M_impl._M_finish,
               :						__new_start,
               :						_M_get_Tp_allocator());
               :		  std::__uninitialized_default_n_a(__new_finish, __n,
               :						   _M_get_Tp_allocator());
               :		  __new_finish += __n;
               :		}
               :	      __catch(...)
               :		{
               :		  std::_Destroy(__new_start, __new_finish,
               :				_M_get_Tp_allocator());
               :		  _M_deallocate(__new_start, __len);
               :		  __throw_exception_again;
               :		}
               :	      std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
               :			    _M_get_Tp_allocator());
               :	      _M_deallocate(this->_M_impl._M_start,
               :			    this->_M_impl._M_end_of_storage
               :			    - this->_M_impl._M_start);
               :	      this->_M_impl._M_start = __new_start;
               :	      this->_M_impl._M_finish = __new_finish;
               :	      this->_M_impl._M_end_of_storage = __new_start + __len;
               :	    }
               :	}
               :    }
               :#endif
               :
               :  template<typename _Tp, typename _Alloc>
               :    template<typename _InputIterator>
               :      void
               :      vector<_Tp, _Alloc>::
               :      _M_range_insert(iterator __pos, _InputIterator __first,
               :		      _InputIterator __last, std::input_iterator_tag)
               :      {
               :	for (; __first != __last; ++__first)
               :	  {
               :	    __pos = insert(__pos, *__first);
               :	    ++__pos;
               :	  }
               :      }
               :
               :  template<typename _Tp, typename _Alloc>
               :    template<typename _ForwardIterator>
               :      void
               :      vector<_Tp, _Alloc>::
               :      _M_range_insert(iterator __position, _ForwardIterator __first,
               :		      _ForwardIterator __last, std::forward_iterator_tag)
               :      {
               :	if (__first != __last)
               :	  {
               :	    const size_type __n = std::distance(__first, __last);
               :	    if (size_type(this->_M_impl._M_end_of_storage
               :			  - this->_M_impl._M_finish) >= __n)
               :	      {
               :		const size_type __elems_after = end() - __position;
               :		pointer __old_finish(this->_M_impl._M_finish);
               :		if (__elems_after > __n)
               :		  {
               :		    std::__uninitialized_move_a(this->_M_impl._M_finish - __n,
               :						this->_M_impl._M_finish,
               :						this->_M_impl._M_finish,
               :						_M_get_Tp_allocator());
               :		    this->_M_impl._M_finish += __n;
               :		    _GLIBCXX_MOVE_BACKWARD3(__position.base(),
               :					    __old_finish - __n, __old_finish);
               :		    std::copy(__first, __last, __position);
               :		  }
               :		else
               :		  {
               :		    _ForwardIterator __mid = __first;
               :		    std::advance(__mid, __elems_after);
               :		    std::__uninitialized_copy_a(__mid, __last,
               :						this->_M_impl._M_finish,
               :						_M_get_Tp_allocator());
               :		    this->_M_impl._M_finish += __n - __elems_after;
               :		    std::__uninitialized_move_a(__position.base(),
               :						__old_finish,
               :						this->_M_impl._M_finish,
               :						_M_get_Tp_allocator());
               :		    this->_M_impl._M_finish += __elems_after;
               :		    std::copy(__first, __mid, __position);
               :		  }
               :	      }
               :	    else
               :	      {
               :		const size_type __len =
               :		  _M_check_len(__n, "vector::_M_range_insert");
               :		pointer __new_start(this->_M_allocate(__len));
               :		pointer __new_finish(__new_start);
               :		__try
               :		  {
               :		    __new_finish =
               :		      std::__uninitialized_move_a(this->_M_impl._M_start,
               :						  __position.base(),
               :						  __new_start,
               :						  _M_get_Tp_allocator());
               :		    __new_finish =
               :		      std::__uninitialized_copy_a(__first, __last,
               :						  __new_finish,
               :						  _M_get_Tp_allocator());
               :		    __new_finish =
               :		      std::__uninitialized_move_a(__position.base(),
               :						  this->_M_impl._M_finish,
               :						  __new_finish,
               :						  _M_get_Tp_allocator());
               :		  }
               :		__catch(...)
               :		  {
               :		    std::_Destroy(__new_start, __new_finish,
               :				  _M_get_Tp_allocator());
               :		    _M_deallocate(__new_start, __len);
               :		    __throw_exception_again;
               :		  }
               :		std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
               :			      _M_get_Tp_allocator());
               :		_M_deallocate(this->_M_impl._M_start,
               :			      this->_M_impl._M_end_of_storage
               :			      - this->_M_impl._M_start);
               :		this->_M_impl._M_start = __new_start;
               :		this->_M_impl._M_finish = __new_finish;
               :		this->_M_impl._M_end_of_storage = __new_start + __len;
               :	      }
               :	  }
               :      }
               :
               :
               :  // vector<bool>
               :
               :  template<typename _Alloc>
               :    void
               :    vector<bool, _Alloc>::
               :    reserve(size_type __n)
               :    {
               :      if (__n > this->max_size())
               :	__throw_length_error(__N("vector::reserve"));
               :      if (this->capacity() < __n)
               :	{
               :	  _Bit_type* __q = this->_M_allocate(__n);
               :	  this->_M_impl._M_finish = _M_copy_aligned(begin(), end(),
               :						    iterator(__q, 0));
               :	  this->_M_deallocate();
               :	  this->_M_impl._M_start = iterator(__q, 0);
               :	  this->_M_impl._M_end_of_storage = (__q + (__n + int(_S_word_bit) - 1)
               :					     / int(_S_word_bit));
               :	}
               :    }
               :
               :  template<typename _Alloc>
               :    void
               :    vector<bool, _Alloc>::
               :    _M_fill_insert(iterator __position, size_type __n, bool __x)
               :    {
               :      if (__n == 0)
               :	return;
               :      if (capacity() - size() >= __n)
               :	{
               :	  std::copy_backward(__position, end(),
               :			     this->_M_impl._M_finish + difference_type(__n));
               :	  std::fill(__position, __position + difference_type(__n), __x);
               :	  this->_M_impl._M_finish += difference_type(__n);
               :	}
               :      else
               :	{
               :	  const size_type __len = 
               :	    _M_check_len(__n, "vector<bool>::_M_fill_insert");
               :	  _Bit_type * __q = this->_M_allocate(__len);
               :	  iterator __i = _M_copy_aligned(begin(), __position,
               :					 iterator(__q, 0));
               :	  std::fill(__i, __i + difference_type(__n), __x);
               :	  this->_M_impl._M_finish = std::copy(__position, end(),
               :					      __i + difference_type(__n));
               :	  this->_M_deallocate();
               :	  this->_M_impl._M_end_of_storage = (__q + ((__len
               :						     + int(_S_word_bit) - 1)
               :						    / int(_S_word_bit)));
               :	  this->_M_impl._M_start = iterator(__q, 0);
               :	}
               :    }
               :
               :  template<typename _Alloc>
               :    template<typename _ForwardIterator>
               :      void
               :      vector<bool, _Alloc>::
               :      _M_insert_range(iterator __position, _ForwardIterator __first, 
               :		      _ForwardIterator __last, std::forward_iterator_tag)
               :      {
               :	if (__first != __last)
               :	  {
               :	    size_type __n = std::distance(__first, __last);
               :	    if (capacity() - size() >= __n)
               :	      {
               :		std::copy_backward(__position, end(),
               :				   this->_M_impl._M_finish
               :				   + difference_type(__n));
               :		std::copy(__first, __last, __position);
               :		this->_M_impl._M_finish += difference_type(__n);
               :	      }
               :	    else
               :	      {
               :		const size_type __len =
               :		  _M_check_len(__n, "vector<bool>::_M_insert_range");
               :		_Bit_type * __q = this->_M_allocate(__len);
               :		iterator __i = _M_copy_aligned(begin(), __position,
               :					       iterator(__q, 0));
               :		__i = std::copy(__first, __last, __i);
               :		this->_M_impl._M_finish = std::copy(__position, end(), __i);
               :		this->_M_deallocate();
               :		this->_M_impl._M_end_of_storage = (__q
               :						   + ((__len
               :						       + int(_S_word_bit) - 1)
               :						      / int(_S_word_bit)));
               :		this->_M_impl._M_start = iterator(__q, 0);
               :	      }
               :	  }
               :      }
               :
               :  template<typename _Alloc>
               :    void
               :    vector<bool, _Alloc>::
               :    _M_insert_aux(iterator __position, bool __x)
               :    {
               :      if (this->_M_impl._M_finish._M_p != this->_M_impl._M_end_of_storage)
               :	{
               :	  std::copy_backward(__position, this->_M_impl._M_finish, 
               :			     this->_M_impl._M_finish + 1);
               :	  *__position = __x;
               :	  ++this->_M_impl._M_finish;
               :	}
               :      else
               :	{
               :	  const size_type __len =
               :	    _M_check_len(size_type(1), "vector<bool>::_M_insert_aux");
               :	  _Bit_type * __q = this->_M_allocate(__len);
               :	  iterator __i = _M_copy_aligned(begin(), __position,
               :					 iterator(__q, 0));
               :	  *__i++ = __x;
               :	  this->_M_impl._M_finish = std::copy(__position, end(), __i);
               :	  this->_M_deallocate();
               :	  this->_M_impl._M_end_of_storage = (__q + ((__len
               :						     + int(_S_word_bit) - 1)
               :						    / int(_S_word_bit)));
               :	  this->_M_impl._M_start = iterator(__q, 0);
               :	}
               :    }
               :
               :_GLIBCXX_END_NAMESPACE_CONTAINER
               :} // namespace std
               :
               :#ifdef __GXX_EXPERIMENTAL_CXX0X__
               :
               :namespace std _GLIBCXX_VISIBILITY(default)
               :{
               :_GLIBCXX_BEGIN_NAMESPACE_VERSION
               :
               :  template<typename _Alloc>
               :    size_t
               :    hash<_GLIBCXX_STD_C::vector<bool, _Alloc>>::
               :    operator()(const _GLIBCXX_STD_C::vector<bool, _Alloc>& __b) const
               :    {
               :      size_t __hash = 0;
               :      using _GLIBCXX_STD_C::_S_word_bit;
               :      using _GLIBCXX_STD_C::_Bit_type;
               :
               :      const size_t __words = __b.size() / _S_word_bit;
               :      if (__words)
               :	{
               :	  const size_t __clength = __words * sizeof(_Bit_type);
               :	  __hash = std::_Hash_impl::hash(__b._M_impl._M_start._M_p, __clength);
               :	}
               :
               :      const size_t __extrabits = __b.size() % _S_word_bit;
               :      if (__extrabits)
               :	{
               :	  _Bit_type __hiword = *__b._M_impl._M_finish._M_p;
               :	  __hiword &= ~((~static_cast<_Bit_type>(0)) << __extrabits);
               :
               :	  const size_t __clength
               :	    = (__extrabits + __CHAR_BIT__ - 1) / __CHAR_BIT__;
               :	  if (__words)
               :	    __hash = std::_Hash_impl::hash(&__hiword, __clength, __hash);
               :	  else
               :	    __hash = std::_Hash_impl::hash(&__hiword, __clength);
               :	}
               :
               :      return __hash;
               :    }
               :
               :_GLIBCXX_END_NAMESPACE_VERSION
               :} // namespace std
               :
               :#endif // __GXX_EXPERIMENTAL_CXX0X__
               :
               :#endif /* _VECTOR_TCC */
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/Core/products/TriangularSolverMatrix.h"
 * 
 *      3  4.1667
 */


               :// This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2009 Gael Guennebaud <gael.guennebaud@inria.fr>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :#ifndef EIGEN_TRIANGULAR_SOLVER_MATRIX_H
               :#define EIGEN_TRIANGULAR_SOLVER_MATRIX_H
               :
               :namespace Eigen { 
               :
               :namespace internal {
               :
               :// if the rhs is row major, let's transpose the product
               :template <typename Scalar, typename Index, int Side, int Mode, bool Conjugate, int TriStorageOrder>
               :struct triangular_solve_matrix<Scalar,Index,Side,Mode,Conjugate,TriStorageOrder,RowMajor>
               :{
               :  static void run(
               :    Index size, Index cols,
               :    const Scalar*  tri, Index triStride,
               :    Scalar* _other, Index otherStride,
               :    level3_blocking<Scalar,Scalar>& blocking)
               :  {
               :    triangular_solve_matrix<
               :      Scalar, Index, Side==OnTheLeft?OnTheRight:OnTheLeft,
               :      (Mode&UnitDiag) | ((Mode&Upper) ? Lower : Upper),
               :      NumTraits<Scalar>::IsComplex && Conjugate,
               :      TriStorageOrder==RowMajor ? ColMajor : RowMajor, ColMajor>
               :      ::run(size, cols, tri, triStride, _other, otherStride, blocking);
               :  }
               :};
               :
               :/* Optimized triangular solver with multiple right hand side and the triangular matrix on the left
               : */
               :template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder>
               :struct triangular_solve_matrix<Scalar,Index,OnTheLeft,Mode,Conjugate,TriStorageOrder,ColMajor>
               :{
               :  static EIGEN_DONT_INLINE void run(
               :    Index size, Index otherSize,
               :    const Scalar* _tri, Index triStride,
               :    Scalar* _other, Index otherStride,
               :    level3_blocking<Scalar,Scalar>& blocking);
               :};
               :template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder>
     1  1.3889 :EIGEN_DONT_INLINE void triangular_solve_matrix<Scalar,Index,OnTheLeft,Mode,Conjugate,TriStorageOrder,ColMajor>::run( /* Eigen::internal::triangular_solve_matrix<double, long, 1, 5, false, 0, 0>::run(long, long, double const*, long, double*, long, Eigen::internal::level3_blocking<double, double>&)      2  2.7778, Eigen::internal::triangular_solve_matrix<double, long, 1, 2, false, 0, 0>::run(long, long, double const*, long, double*, long, Eigen::internal::level3_blocking<double, double>&)      1  1.3889, total:      3  4.1667 */
               :    Index size, Index otherSize,
               :    const Scalar* _tri, Index triStride,
               :    Scalar* _other, Index otherStride,
               :    level3_blocking<Scalar,Scalar>& blocking)
               :  {
               :    Index cols = otherSize;
               :    const_blas_data_mapper<Scalar, Index, TriStorageOrder> tri(_tri,triStride);
               :    blas_data_mapper<Scalar, Index, ColMajor> other(_other,otherStride);
               :
               :    typedef gebp_traits<Scalar,Scalar> Traits;
               :    enum {
               :      SmallPanelWidth   = EIGEN_PLAIN_ENUM_MAX(Traits::mr,Traits::nr),
               :      IsLower = (Mode&Lower) == Lower
               :    };
               :
               :    Index kc = blocking.kc();                   // cache block size along the K direction
               :    Index mc = (std::min)(size,blocking.mc());  // cache block size along the M direction
               :
               :    std::size_t sizeA = kc*mc;
               :    std::size_t sizeB = kc*cols;
               :    std::size_t sizeW = kc*Traits::WorkSpaceFactor;
               :
               :    ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
               :    ei_declare_aligned_stack_constructed_variable(Scalar, blockB, sizeB, blocking.blockB());
               :    ei_declare_aligned_stack_constructed_variable(Scalar, blockW, sizeW, blocking.blockW());
               :
               :    conj_if<Conjugate> conj;
               :    gebp_kernel<Scalar, Scalar, Index, Traits::mr, Traits::nr, Conjugate, false> gebp_kernel;
               :    gemm_pack_lhs<Scalar, Index, Traits::mr, Traits::LhsProgress, TriStorageOrder> pack_lhs;
               :    gemm_pack_rhs<Scalar, Index, Traits::nr, ColMajor, false, true> pack_rhs;
               :
               :    // the goal here is to subdivise the Rhs panels such that we keep some cache
               :    // coherence when accessing the rhs elements
               :    std::ptrdiff_t l1, l2;
               :    manage_caching_sizes(GetAction, &l1, &l2);
               :    Index subcols = cols>0 ? l2/(4 * sizeof(Scalar) * otherStride) : 0;
               :    subcols = std::max<Index>((subcols/Traits::nr)*Traits::nr, Traits::nr);
               :
               :    for(Index k2=IsLower ? 0 : size;
               :        IsLower ? k2<size : k2>0;
               :        IsLower ? k2+=kc : k2-=kc)
               :    {
               :      const Index actual_kc = (std::min)(IsLower ? size-k2 : k2, kc);
               :
               :      // We have selected and packed a big horizontal panel R1 of rhs. Let B be the packed copy of this panel,
               :      // and R2 the remaining part of rhs. The corresponding vertical panel of lhs is split into
               :      // A11 (the triangular part) and A21 the remaining rectangular part.
               :      // Then the high level algorithm is:
               :      //  - B = R1                    => general block copy (done during the next step)
               :      //  - R1 = A11^-1 B             => tricky part
               :      //  - update B from the new R1  => actually this has to be performed continuously during the above step
               :      //  - R2 -= A21 * B             => GEPP
               :
               :      // The tricky part: compute R1 = A11^-1 B while updating B from R1
               :      // The idea is to split A11 into multiple small vertical panels.
               :      // Each panel can be split into a small triangular part T1k which is processed without optimization,
               :      // and the remaining small part T2k which is processed using gebp with appropriate block strides
               :      for(Index j2=0; j2<cols; j2+=subcols)
               :      {
               :        Index actual_cols = (std::min)(cols-j2,subcols);
               :        // for each small vertical panels [T1k^T, T2k^T]^T of lhs
               :        for (Index k1=0; k1<actual_kc; k1+=SmallPanelWidth)
               :        {
               :          Index actualPanelWidth = std::min<Index>(actual_kc-k1, SmallPanelWidth);
               :          // tr solve
               :          for (Index k=0; k<actualPanelWidth; ++k)
               :          {
               :            // TODO write a small kernel handling this (can be shared with trsv)
               :            Index i  = IsLower ? k2+k1+k : k2-k1-k-1;
               :            Index s  = IsLower ? k2+k1 : i+1;
               :            Index rs = actualPanelWidth - k - 1; // remaining size
               :
               :            Scalar a = (Mode & UnitDiag) ? Scalar(1) : Scalar(1)/conj(tri(i,i));
               :            for (Index j=j2; j<j2+actual_cols; ++j)
               :            {
               :              if (TriStorageOrder==RowMajor)
               :              {
               :                Scalar b(0);
               :                const Scalar* l = &tri(i,s);
               :                Scalar* r = &other(s,j);
               :                for (Index i3=0; i3<k; ++i3)
               :                  b += conj(l[i3]) * r[i3];
               :
               :                other(i,j) = (other(i,j) - b)*a;
               :              }
               :              else
               :              {
               :                Index s = IsLower ? i+1 : i-rs;
     1  1.3889 :                Scalar b = (other(i,j) *= a);
               :                Scalar* r = &other(s,j);
               :                const Scalar* l = &tri(s,i);
               :                for (Index i3=0;i3<rs;++i3)
               :                  r[i3] -= b * conj(l[i3]);
               :              }
               :            }
               :          }
               :
               :          Index lengthTarget = actual_kc-k1-actualPanelWidth;
               :          Index startBlock   = IsLower ? k2+k1 : k2-k1-actualPanelWidth;
               :          Index blockBOffset = IsLower ? k1 : lengthTarget;
               :
               :          // update the respective rows of B from other
               :          pack_rhs(blockB+actual_kc*j2, &other(startBlock,j2), otherStride, actualPanelWidth, actual_cols, actual_kc, blockBOffset);
               :
               :          // GEBP
     1  1.3889 :          if (lengthTarget>0)
               :          {
               :            Index startTarget  = IsLower ? k2+k1+actualPanelWidth : k2-actual_kc;
               :
               :            pack_lhs(blockA, &tri(startTarget,startBlock), triStride, actualPanelWidth, lengthTarget);
               :
               :            gebp_kernel(&other(startTarget,j2), otherStride, blockA, blockB+actual_kc*j2, lengthTarget, actualPanelWidth, actual_cols, Scalar(-1),
               :                        actualPanelWidth, actual_kc, 0, blockBOffset, blockW);
               :          }
               :        }
               :      }
               :      
               :      // R2 -= A21 * B => GEPP
               :      {
               :        Index start = IsLower ? k2+kc : 0;
               :        Index end   = IsLower ? size : k2-kc;
               :        for(Index i2=start; i2<end; i2+=mc)
               :        {
               :          const Index actual_mc = (std::min)(mc,end-i2);
               :          if (actual_mc>0)
               :          {
               :            pack_lhs(blockA, &tri(i2, IsLower ? k2 : k2-kc), triStride, actual_kc, actual_mc);
               :
               :            gebp_kernel(_other+i2, otherStride, blockA, blockB, actual_mc, actual_kc, cols, Scalar(-1), -1, -1, 0, 0, blockW);
               :          }
               :        }
               :      }
               :    }
               :  }
               :
               :/* Optimized triangular solver with multiple left hand sides and the trinagular matrix on the right
               : */
               :template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder>
               :struct triangular_solve_matrix<Scalar,Index,OnTheRight,Mode,Conjugate,TriStorageOrder,ColMajor>
               :{
               :  static EIGEN_DONT_INLINE void run(
               :    Index size, Index otherSize,
               :    const Scalar* _tri, Index triStride,
               :    Scalar* _other, Index otherStride,
               :    level3_blocking<Scalar,Scalar>& blocking);
               :};
               :template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder>
               :EIGEN_DONT_INLINE void triangular_solve_matrix<Scalar,Index,OnTheRight,Mode,Conjugate,TriStorageOrder,ColMajor>::run(
               :    Index size, Index otherSize,
               :    const Scalar* _tri, Index triStride,
               :    Scalar* _other, Index otherStride,
               :    level3_blocking<Scalar,Scalar>& blocking)
               :  {
               :    Index rows = otherSize;
               :    const_blas_data_mapper<Scalar, Index, TriStorageOrder> rhs(_tri,triStride);
               :    blas_data_mapper<Scalar, Index, ColMajor> lhs(_other,otherStride);
               :
               :    typedef gebp_traits<Scalar,Scalar> Traits;
               :    enum {
               :      RhsStorageOrder   = TriStorageOrder,
               :      SmallPanelWidth   = EIGEN_PLAIN_ENUM_MAX(Traits::mr,Traits::nr),
               :      IsLower = (Mode&Lower) == Lower
               :    };
               :
               :    Index kc = blocking.kc();                   // cache block size along the K direction
               :    Index mc = (std::min)(rows,blocking.mc());  // cache block size along the M direction
               :
               :    std::size_t sizeA = kc*mc;
               :    std::size_t sizeB = kc*size;
               :    std::size_t sizeW = kc*Traits::WorkSpaceFactor;
               :
               :    ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
               :    ei_declare_aligned_stack_constructed_variable(Scalar, blockB, sizeB, blocking.blockB());
               :    ei_declare_aligned_stack_constructed_variable(Scalar, blockW, sizeW, blocking.blockW());
               :
               :    conj_if<Conjugate> conj;
               :    gebp_kernel<Scalar,Scalar, Index, Traits::mr, Traits::nr, false, Conjugate> gebp_kernel;
               :    gemm_pack_rhs<Scalar, Index, Traits::nr,RhsStorageOrder> pack_rhs;
               :    gemm_pack_rhs<Scalar, Index, Traits::nr,RhsStorageOrder,false,true> pack_rhs_panel;
               :    gemm_pack_lhs<Scalar, Index, Traits::mr, Traits::LhsProgress, ColMajor, false, true> pack_lhs_panel;
               :
               :    for(Index k2=IsLower ? size : 0;
               :        IsLower ? k2>0 : k2<size;
               :        IsLower ? k2-=kc : k2+=kc)
               :    {
               :      const Index actual_kc = (std::min)(IsLower ? k2 : size-k2, kc);
               :      Index actual_k2 = IsLower ? k2-actual_kc : k2 ;
               :
               :      Index startPanel = IsLower ? 0 : k2+actual_kc;
               :      Index rs = IsLower ? actual_k2 : size - actual_k2 - actual_kc;
               :      Scalar* geb = blockB+actual_kc*actual_kc;
               :
               :      if (rs>0) pack_rhs(geb, &rhs(actual_k2,startPanel), triStride, actual_kc, rs);
               :
               :      // triangular packing (we only pack the panels off the diagonal,
               :      // neglecting the blocks overlapping the diagonal
               :      {
               :        for (Index j2=0; j2<actual_kc; j2+=SmallPanelWidth)
               :        {
               :          Index actualPanelWidth = std::min<Index>(actual_kc-j2, SmallPanelWidth);
               :          Index actual_j2 = actual_k2 + j2;
               :          Index panelOffset = IsLower ? j2+actualPanelWidth : 0;
               :          Index panelLength = IsLower ? actual_kc-j2-actualPanelWidth : j2;
               :
               :          if (panelLength>0)
               :          pack_rhs_panel(blockB+j2*actual_kc,
               :                         &rhs(actual_k2+panelOffset, actual_j2), triStride,
               :                         panelLength, actualPanelWidth,
               :                         actual_kc, panelOffset);
               :        }
               :      }
               :
               :      for(Index i2=0; i2<rows; i2+=mc)
               :      {
               :        const Index actual_mc = (std::min)(mc,rows-i2);
               :
               :        // triangular solver kernel
               :        {
               :          // for each small block of the diagonal (=> vertical panels of rhs)
               :          for (Index j2 = IsLower
               :                      ? (actual_kc - ((actual_kc%SmallPanelWidth) ? Index(actual_kc%SmallPanelWidth)
               :                                                                  : Index(SmallPanelWidth)))
               :                      : 0;
               :               IsLower ? j2>=0 : j2<actual_kc;
               :               IsLower ? j2-=SmallPanelWidth : j2+=SmallPanelWidth)
               :          {
               :            Index actualPanelWidth = std::min<Index>(actual_kc-j2, SmallPanelWidth);
               :            Index absolute_j2 = actual_k2 + j2;
               :            Index panelOffset = IsLower ? j2+actualPanelWidth : 0;
               :            Index panelLength = IsLower ? actual_kc - j2 - actualPanelWidth : j2;
               :
               :            // GEBP
               :            if(panelLength>0)
               :            {
               :              gebp_kernel(&lhs(i2,absolute_j2), otherStride,
               :                          blockA, blockB+j2*actual_kc,
               :                          actual_mc, panelLength, actualPanelWidth,
               :                          Scalar(-1),
               :                          actual_kc, actual_kc, // strides
               :                          panelOffset, panelOffset, // offsets
               :                          blockW);  // workspace
               :            }
               :
               :            // unblocked triangular solve
               :            for (Index k=0; k<actualPanelWidth; ++k)
               :            {
               :              Index j = IsLower ? absolute_j2+actualPanelWidth-k-1 : absolute_j2+k;
               :
               :              Scalar* r = &lhs(i2,j);
               :              for (Index k3=0; k3<k; ++k3)
               :              {
               :                Scalar b = conj(rhs(IsLower ? j+1+k3 : absolute_j2+k3,j));
               :                Scalar* a = &lhs(i2,IsLower ? j+1+k3 : absolute_j2+k3);
               :                for (Index i=0; i<actual_mc; ++i)
               :                  r[i] -= a[i] * b;
               :              }
               :              Scalar b = (Mode & UnitDiag) ? Scalar(1) : Scalar(1)/conj(rhs(j,j));
               :              for (Index i=0; i<actual_mc; ++i)
               :                r[i] *= b;
               :            }
               :
               :            // pack the just computed part of lhs to A
               :            pack_lhs_panel(blockA, _other+absolute_j2*otherStride+i2, otherStride,
               :                           actualPanelWidth, actual_mc,
               :                           actual_kc, j2);
               :          }
               :        }
               :
               :        if (rs>0)
               :          gebp_kernel(_other+i2+startPanel*otherStride, otherStride, blockA, geb,
               :                      actual_mc, actual_kc, rs, Scalar(-1),
               :                      -1, -1, 0, 0, blockW);
               :      }
               :    }
               :  }
               :
               :} // end namespace internal
               :
               :} // end namespace Eigen
               :
               :#endif // EIGEN_TRIANGULAR_SOLVER_MATRIX_H
/* 
 * Total samples for file : "/build/buildd/eglibc-2.19/malloc/malloc.c"
 * 
 *      3  4.1667
 */


 /* malloc total:      1  1.3889 */
 /* _int_malloc total:      1  1.3889 */
 /* malloc_consolidate total:      1  1.3889 */
/* 
 * Total samples for file : "/build/buildd/eglibc-2.19/elf/../sysdeps/x86_64/dl-machine.h"
 * 
 *      3  4.1667
 */


/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/SparseLU/SparseLU_panel_dfs.h"
 * 
 *      2  2.7778
 */


               :// This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2012 Dsir Nuentsa-Wakam <desire.nuentsa_wakam@inria.fr>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :/* 
               : 
               : * NOTE: This file is the modified version of [s,d,c,z]panel_dfs.c file in SuperLU 
               : 
               : * -- SuperLU routine (version 2.0) --
               : * Univ. of California Berkeley, Xerox Palo Alto Research Center,
               : * and Lawrence Berkeley National Lab.
               : * November 15, 1997
               : *
               : * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.
               : *
               : * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY
               : * EXPRESSED OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.
               : *
               : * Permission is hereby granted to use or copy this program for any
               : * purpose, provided the above notices are retained on all copies.
               : * Permission to modify the code and to distribute modified code is
               : * granted, provided the above notices are retained, and a notice that
               : * the code was modified is included with the above copyright notice.
               : */
               :#ifndef SPARSELU_PANEL_DFS_H
               :#define SPARSELU_PANEL_DFS_H
               :
               :namespace Eigen {
               :
               :namespace internal {
               :  
               :template<typename IndexVector>
               :struct panel_dfs_traits
               :{
               :  typedef typename IndexVector::Scalar Index;
               :  panel_dfs_traits(Index jcol, Index* marker)
               :    : m_jcol(jcol), m_marker(marker)
               :  {}
               :  bool update_segrep(Index krep, Index jj)
               :  {
               :    if(m_marker[krep]<m_jcol)
               :    {
               :      m_marker[krep] = jj; 
               :      return true;
               :    }
               :    return false;
               :  }
               :  void mem_expand(IndexVector& /*glu.lsub*/, Index /*nextl*/, Index /*chmark*/) {}
               :  enum { ExpandMem = false };
               :  Index m_jcol;
               :  Index* m_marker;
               :};
               :
               :
               :template <typename Scalar, typename Index>
               :template <typename Traits>
               :void SparseLUImpl<Scalar,Index>::dfs_kernel(const Index jj, IndexVector& perm_r, /* void Eigen::internal::SparseLUImpl<double, int>::dfs_kernel<Eigen::internal::column_dfs_traits<Eigen::Matrix<int, -1, 1, 0, -1, 1>, Eigen::Matrix<double, -1, 1, 0, -1, 1> > >(int, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, int&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Ref<Eigen::Matrix<int, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> >, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Ref<Eigen::Matrix<int, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> >, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::internal::LU_GlobalLU_t<Eigen::Matrix<int, -1, 1, 0, -1, 1>, Eigen::Matrix<double, -1, 1, 0, -1, 1> >&, int&, int, Eigen::internal::column_dfs_traits<Eigen::Matrix<int, -1, 1, 0, -1, 1>, Eigen::Matrix<double, -1, 1, 0, -1, 1> >&) total:      1  1.3889 */
               :                   Index& nseg, IndexVector& panel_lsub, IndexVector& segrep,
               :                   Ref<IndexVector> repfnz_col, IndexVector& xprune, Ref<IndexVector> marker, IndexVector& parent,
               :                   IndexVector& xplore, GlobalLU_t& glu,
               :                   Index& nextl_col, Index krow, Traits& traits
               :                  )
               :{
               :  
               :  Index kmark = marker(krow);
               :      
               :  // For each unmarked krow of jj
               :  marker(krow) = jj; 
     1  1.3889 :  Index kperm = perm_r(krow); 
               :  if (kperm == emptyIdxLU ) {
               :    // krow is in L : place it in structure of L(*, jj)
     1  1.3889 :    panel_lsub(nextl_col++) = krow;  // krow is indexed into A
               :    
               :    traits.mem_expand(panel_lsub, nextl_col, kmark);
               :  }
               :  else 
               :  {
               :    // krow is in U : if its supernode-representative krep
               :    // has been explored, update repfnz(*)
               :    // krep = supernode representative of the current row
               :    Index krep = glu.xsup(glu.supno(kperm)+1) - 1; 
               :    // First nonzero element in the current column:
               :    Index myfnz = repfnz_col(krep); 
               :    
               :    if (myfnz != emptyIdxLU )
               :    {
               :      // Representative visited before
               :      if (myfnz > kperm ) repfnz_col(krep) = kperm; 
               :      
               :    }
               :    else 
               :    {
               :      // Otherwise, perform dfs starting at krep
               :      Index oldrep = emptyIdxLU; 
               :      parent(krep) = oldrep; 
               :      repfnz_col(krep) = kperm; 
               :      Index xdfs =  glu.xlsub(krep); 
               :      Index maxdfs = xprune(krep); 
               :      
               :      Index kpar;
               :      do 
               :      {
               :        // For each unmarked kchild of krep
               :        while (xdfs < maxdfs) 
               :        {
               :          Index kchild = glu.lsub(xdfs); 
               :          xdfs++; 
               :          Index chmark = marker(kchild); 
               :          
               :          if (chmark != jj ) 
               :          {
               :            marker(kchild) = jj; 
               :            Index chperm = perm_r(kchild); 
               :            
               :            if (chperm == emptyIdxLU) 
               :            {
               :              // case kchild is in L: place it in L(*, j)
               :              panel_lsub(nextl_col++) = kchild;
               :              traits.mem_expand(panel_lsub, nextl_col, chmark);
               :            }
               :            else
               :            {
               :              // case kchild is in U :
               :              // chrep = its supernode-rep. If its rep has been explored, 
               :              // update its repfnz(*)
               :              Index chrep = glu.xsup(glu.supno(chperm)+1) - 1; 
               :              myfnz = repfnz_col(chrep); 
               :              
               :              if (myfnz != emptyIdxLU) 
               :              { // Visited before 
               :                if (myfnz > chperm) 
               :                  repfnz_col(chrep) = chperm; 
               :              }
               :              else 
               :              { // Cont. dfs at snode-rep of kchild
               :                xplore(krep) = xdfs; 
               :                oldrep = krep; 
               :                krep = chrep; // Go deeper down G(L)
               :                parent(krep) = oldrep; 
               :                repfnz_col(krep) = chperm; 
               :                xdfs = glu.xlsub(krep); 
               :                maxdfs = xprune(krep); 
               :                
               :              } // end if myfnz != -1
               :            } // end if chperm == -1 
               :                
               :          } // end if chmark !=jj
               :        } // end while xdfs < maxdfs
               :        
               :        // krow has no more unexplored nbrs :
               :        //    Place snode-rep krep in postorder DFS, if this 
               :        //    segment is seen for the first time. (Note that 
               :        //    "repfnz(krep)" may change later.)
               :        //    Baktrack dfs to its parent
               :        if(traits.update_segrep(krep,jj))
               :        //if (marker1(krep) < jcol )
               :        {
               :          segrep(nseg) = krep; 
               :          ++nseg; 
               :          //marker1(krep) = jj; 
               :        }
               :        
               :        kpar = parent(krep); // Pop recursion, mimic recursion 
               :        if (kpar == emptyIdxLU) 
               :          break; // dfs done 
               :        krep = kpar; 
               :        xdfs = xplore(krep); 
               :        maxdfs = xprune(krep); 
               :
               :      } while (kpar != emptyIdxLU); // Do until empty stack 
               :      
               :    } // end if (myfnz = -1)
               :
               :  } // end if (kperm == -1)   
               :}
               :
               :/**
               : * \brief Performs a symbolic factorization on a panel of columns [jcol, jcol+w)
               : * 
               : * A supernode representative is the last column of a supernode.
               : * The nonzeros in U[*,j] are segments that end at supernodes representatives
               : * 
               : * The routine returns a list of the supernodal representatives 
               : * in topological order of the dfs that generates them. This list is 
               : * a superset of the topological order of each individual column within 
               : * the panel.
               : * The location of the first nonzero in each supernodal segment 
               : * (supernodal entry location) is also returned. Each column has 
               : * a separate list for this purpose. 
               : * 
               : * Two markers arrays are used for dfs :
               : *    marker[i] == jj, if i was visited during dfs of current column jj;
               : *    marker1[i] >= jcol, if i was visited by earlier columns in this panel; 
               : * 
               : * \param[in] m number of rows in the matrix
               : * \param[in] w Panel size
               : * \param[in] jcol Starting  column of the panel
               : * \param[in] A Input matrix in column-major storage
               : * \param[in] perm_r Row permutation
               : * \param[out] nseg Number of U segments
               : * \param[out] dense Accumulate the column vectors of the panel
               : * \param[out] panel_lsub Subscripts of the row in the panel 
               : * \param[out] segrep Segment representative i.e first nonzero row of each segment
               : * \param[out] repfnz First nonzero location in each row
               : * \param[out] xprune The pruned elimination tree
               : * \param[out] marker work vector
               : * \param  parent The elimination tree
               : * \param xplore work vector
               : * \param glu The global data structure
               : * 
               : */
               :
               :template <typename Scalar, typename Index>
               :void SparseLUImpl<Scalar,Index>::panel_dfs(const Index m, const Index w, const Index jcol, MatrixType& A, IndexVector& perm_r, Index& nseg, ScalarVector& dense, IndexVector& panel_lsub, IndexVector& segrep, IndexVector& repfnz, IndexVector& xprune, IndexVector& marker, IndexVector& parent, IndexVector& xplore, GlobalLU_t& glu) /* Eigen::internal::SparseLUImpl<double, int>::panel_dfs(int, int, int, Eigen::SparseMatrix<double, 0, int>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, int&, Eigen::Matrix<double, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::internal::LU_GlobalLU_t<Eigen::Matrix<int, -1, 1, 0, -1, 1>, Eigen::Matrix<double, -1, 1, 0, -1, 1> >&) total:      2  2.7778 */
               :{
               :  Index nextl_col; // Next available position in panel_lsub[*,jj] 
               :  
               :  // Initialize pointers 
               :  VectorBlock<IndexVector> marker1(marker, m, m); 
               :  nseg = 0; 
               :  
               :  panel_dfs_traits<IndexVector> traits(jcol, marker1.data());
               :  
               :  // For each column in the panel 
               :  for (Index jj = jcol; jj < jcol + w; jj++) 
               :  {
               :    nextl_col = (jj - jcol) * m; 
               :    
               :    VectorBlock<IndexVector> repfnz_col(repfnz, nextl_col, m); // First nonzero location in each row
               :    VectorBlock<ScalarVector> dense_col(dense,nextl_col, m); // Accumulate a column vector here
               :    
               :    
               :    // For each nnz in A[*, jj] do depth first search
               :    for (typename MatrixType::InnerIterator it(A, jj); it; ++it)
               :    {
               :      Index krow = it.row(); 
               :      dense_col(krow) = it.value();
               :      
               :      Index kmark = marker(krow); 
               :      if (kmark == jj) 
               :        continue; // krow visited before, go to the next nonzero
               :      
               :      dfs_kernel(jj, perm_r, nseg, panel_lsub, segrep, repfnz_col, xprune, marker, parent,
               :                   xplore, glu, nextl_col, krow, traits);
               :    }// end for nonzeros in column jj
               :    
               :  } // end for column jj
               :}
               :
               :} // end namespace internal
               :} // end namespace Eigen
               :
               :#endif // SPARSELU_PANEL_DFS_H
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/SparseLU/SparseLU_column_dfs.h"
 * 
 *      2  2.7778
 */


               :// This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2012 Dsir Nuentsa-Wakam <desire.nuentsa_wakam@inria.fr>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :/* 
               : 
               : * NOTE: This file is the modified version of [s,d,c,z]column_dfs.c file in SuperLU 
               : 
               : * -- SuperLU routine (version 2.0) --
               : * Univ. of California Berkeley, Xerox Palo Alto Research Center,
               : * and Lawrence Berkeley National Lab.
               : * November 15, 1997
               : *
               : * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.
               : *
               : * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY
               : * EXPRESSED OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.
               : *
               : * Permission is hereby granted to use or copy this program for any
               : * purpose, provided the above notices are retained on all copies.
               : * Permission to modify the code and to distribute modified code is
               : * granted, provided the above notices are retained, and a notice that
               : * the code was modified is included with the above copyright notice.
               : */
               :#ifndef SPARSELU_COLUMN_DFS_H
               :#define SPARSELU_COLUMN_DFS_H
               :
               :template <typename Scalar, typename Index> class SparseLUImpl;
               :namespace Eigen {
               :
               :namespace internal {
               :
               :template<typename IndexVector, typename ScalarVector>
               :struct column_dfs_traits : no_assignment_operator
               :{
               :  typedef typename ScalarVector::Scalar Scalar;
               :  typedef typename IndexVector::Scalar Index;
               :  column_dfs_traits(Index jcol, Index& jsuper, typename SparseLUImpl<Scalar, Index>::GlobalLU_t& glu, SparseLUImpl<Scalar, Index>& luImpl)
               :   : m_jcol(jcol), m_jsuper_ref(jsuper), m_glu(glu), m_luImpl(luImpl)
               : {}
               :  bool update_segrep(Index /*krep*/, Index /*jj*/)
               :  {
               :    return true;
               :  }
               :  void mem_expand(IndexVector& lsub, Index& nextl, Index chmark)
               :  {
     1  1.3889 :    if (nextl >= m_glu.nzlmax)
               :      m_luImpl.memXpand(lsub, m_glu.nzlmax, nextl, LSUB, m_glu.num_expansions); 
               :    if (chmark != (m_jcol-1)) m_jsuper_ref = emptyIdxLU;
               :  }
               :  enum { ExpandMem = true };
               :  
               :  Index m_jcol;
               :  Index& m_jsuper_ref;
               :  typename SparseLUImpl<Scalar, Index>::GlobalLU_t& m_glu;
               :  SparseLUImpl<Scalar, Index>& m_luImpl;
               :};
               :
               :
               :/**
               : * \brief Performs a symbolic factorization on column jcol and decide the supernode boundary
               : * 
               : * A supernode representative is the last column of a supernode.
               : * The nonzeros in U[*,j] are segments that end at supernodes representatives. 
               : * The routine returns a list of the supernodal representatives 
               : * in topological order of the dfs that generates them. 
               : * The location of the first nonzero in each supernodal segment 
               : * (supernodal entry location) is also returned. 
               : * 
               : * \param m number of rows in the matrix
               : * \param jcol Current column 
               : * \param perm_r Row permutation
               : * \param maxsuper  Maximum number of column allowed in a supernode
               : * \param [in,out] nseg Number of segments in current U[*,j] - new segments appended
               : * \param lsub_col defines the rhs vector to start the dfs
               : * \param [in,out] segrep Segment representatives - new segments appended 
               : * \param repfnz  First nonzero location in each row
               : * \param xprune 
               : * \param marker  marker[i] == jj, if i was visited during dfs of current column jj;
               : * \param parent
               : * \param xplore working array
               : * \param glu global LU data 
               : * \return 0 success
               : *         > 0 number of bytes allocated when run out of space
               : * 
               : */
               :template <typename Scalar, typename Index>
               :Index SparseLUImpl<Scalar,Index>::column_dfs(const Index m, const Index jcol, IndexVector& perm_r, Index maxsuper, Index& nseg,  BlockIndexVector lsub_col, IndexVector& segrep, BlockIndexVector repfnz, IndexVector& xprune, IndexVector& marker, IndexVector& parent, IndexVector& xplore, GlobalLU_t& glu) /* Eigen::internal::SparseLUImpl<double, int>::column_dfs(int, int, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, int, int&, Eigen::Ref<Eigen::Matrix<int, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> >, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Ref<Eigen::Matrix<int, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> >, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::internal::LU_GlobalLU_t<Eigen::Matrix<int, -1, 1, 0, -1, 1>, Eigen::Matrix<double, -1, 1, 0, -1, 1> >&) total:      1  1.3889 */
               :{
               :  
               :  Index jsuper = glu.supno(jcol); 
               :  Index nextl = glu.xlsub(jcol); 
               :  VectorBlock<IndexVector> marker2(marker, 2*m, m); 
               :  
               :  
               :  column_dfs_traits<IndexVector, ScalarVector> traits(jcol, jsuper, glu, *this);
               :  
               :  // For each nonzero in A(*,jcol) do dfs 
     1  1.3889 :  for (Index k = 0; ((k < m) ? lsub_col[k] != emptyIdxLU : false) ; k++)
               :  {
               :    Index krow = lsub_col(k); 
               :    lsub_col(k) = emptyIdxLU; 
               :    Index kmark = marker2(krow); 
               :    
               :    // krow was visited before, go to the next nonz; 
               :    if (kmark == jcol) continue;
               :    
               :    dfs_kernel(jcol, perm_r, nseg, glu.lsub, segrep, repfnz, xprune, marker2, parent,
               :                   xplore, glu, nextl, krow, traits);
               :  } // for each nonzero ... 
               :  
               :  Index fsupc, jptr, jm1ptr, ito, ifrom, istop;
               :  Index nsuper = glu.supno(jcol);
               :  Index jcolp1 = jcol + 1;
               :  Index jcolm1 = jcol - 1;
               :  
               :  // check to see if j belongs in the same supernode as j-1
               :  if ( jcol == 0 )
               :  { // Do nothing for column 0 
               :    nsuper = glu.supno(0) = 0 ;
               :  }
               :  else 
               :  {
               :    fsupc = glu.xsup(nsuper); 
               :    jptr = glu.xlsub(jcol); // Not yet compressed
               :    jm1ptr = glu.xlsub(jcolm1); 
               :    
               :    // Use supernodes of type T2 : see SuperLU paper
               :    if ( (nextl-jptr != jptr-jm1ptr-1) ) jsuper = emptyIdxLU;
               :    
               :    // Make sure the number of columns in a supernode doesn't
               :    // exceed threshold
               :    if ( (jcol - fsupc) >= maxsuper) jsuper = emptyIdxLU; 
               :    
               :    /* If jcol starts a new supernode, reclaim storage space in
               :     * glu.lsub from previous supernode. Note we only store 
               :     * the subscript set of the first and last columns of 
               :     * a supernode. (first for num values, last for pruning)
               :     */
               :    if (jsuper == emptyIdxLU)
               :    { // starts a new supernode 
               :      if ( (fsupc < jcolm1-1) ) 
               :      { // >= 3 columns in nsuper
               :        ito = glu.xlsub(fsupc+1);
               :        glu.xlsub(jcolm1) = ito; 
               :        istop = ito + jptr - jm1ptr; 
               :        xprune(jcolm1) = istop; // intialize xprune(jcol-1)
               :        glu.xlsub(jcol) = istop; 
               :        
               :        for (ifrom = jm1ptr; ifrom < nextl; ++ifrom, ++ito)
               :          glu.lsub(ito) = glu.lsub(ifrom); 
               :        nextl = ito;  // = istop + length(jcol)
               :      }
               :      nsuper++; 
               :      glu.supno(jcol) = nsuper; 
               :    } // if a new supernode 
               :  } // end else:  jcol > 0
               :  
               :  // Tidy up the pointers before exit
               :  glu.xsup(nsuper+1) = jcolp1; 
               :  glu.supno(jcolp1) = nsuper; 
               :  xprune(jcol) = nextl;  // Intialize upper bound for pruning
               :  glu.xlsub(jcolp1) = nextl; 
               :  
               :  return 0; 
               :}
               :
               :} // end namespace internal
               :
               :} // end namespace Eigen
               :
               :#endif
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/SparseLU/SparseLU.h"
 * 
 *      2  2.7778
 */


               :// This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2012 Dsir Nuentsa-Wakam <desire.nuentsa_wakam@inria.fr>
               :// Copyright (C) 2012 Gael Guennebaud <gael.guennebaud@inria.fr>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :
               :#ifndef EIGEN_SPARSE_LU_H
               :#define EIGEN_SPARSE_LU_H
               :
               :namespace Eigen {
               :
               :template <typename _MatrixType, typename _OrderingType = COLAMDOrdering<typename _MatrixType::Index> > class SparseLU;
               :template <typename MappedSparseMatrixType> struct SparseLUMatrixLReturnType;
               :template <typename MatrixLType, typename MatrixUType> struct SparseLUMatrixUReturnType;
               :
               :/** \ingroup SparseLU_Module
               :  * \class SparseLU
               :  * 
               :  * \brief Sparse supernodal LU factorization for general matrices
               :  * 
               :  * This class implements the supernodal LU factorization for general matrices.
               :  * It uses the main techniques from the sequential SuperLU package 
               :  * (http://crd-legacy.lbl.gov/~xiaoye/SuperLU/). It handles transparently real 
               :  * and complex arithmetics with single and double precision, depending on the 
               :  * scalar type of your input matrix. 
               :  * The code has been optimized to provide BLAS-3 operations during supernode-panel updates. 
               :  * It benefits directly from the built-in high-performant Eigen BLAS routines. 
               :  * Moreover, when the size of a supernode is very small, the BLAS calls are avoided to 
               :  * enable a better optimization from the compiler. For best performance, 
               :  * you should compile it with NDEBUG flag to avoid the numerous bounds checking on vectors. 
               :  * 
               :  * An important parameter of this class is the ordering method. It is used to reorder the columns 
               :  * (and eventually the rows) of the matrix to reduce the number of new elements that are created during 
               :  * numerical factorization. The cheapest method available is COLAMD. 
               :  * See  \link OrderingMethods_Module the OrderingMethods module \endlink for the list of 
               :  * built-in and external ordering methods. 
               :  *
               :  * Simple example with key steps 
               :  * \code
               :  * VectorXd x(n), b(n);
               :  * SparseMatrix<double, ColMajor> A;
               :  * SparseLU<SparseMatrix<scalar, ColMajor>, COLAMDOrdering<Index> >   solver;
               :  * // fill A and b;
               :  * // Compute the ordering permutation vector from the structural pattern of A
               :  * solver.analyzePattern(A); 
               :  * // Compute the numerical factorization 
               :  * solver.factorize(A); 
               :  * //Use the factors to solve the linear system 
               :  * x = solver.solve(b); 
               :  * \endcode
               :  * 
               :  * \warning The input matrix A should be in a \b compressed and \b column-major form.
               :  * Otherwise an expensive copy will be made. You can call the inexpensive makeCompressed() to get a compressed matrix.
               :  * 
               :  * \note Unlike the initial SuperLU implementation, there is no step to equilibrate the matrix. 
               :  * For badly scaled matrices, this step can be useful to reduce the pivoting during factorization. 
               :  * If this is the case for your matrices, you can try the basic scaling method at
               :  *  "unsupported/Eigen/src/IterativeSolvers/Scaling.h"
               :  * 
               :  * \tparam _MatrixType The type of the sparse matrix. It must be a column-major SparseMatrix<>
               :  * \tparam _OrderingType The ordering method to use, either AMD, COLAMD or METIS. Default is COLMAD
               :  * 
               :  * 
               :  * \sa \ref TutorialSparseDirectSolvers
               :  * \sa \ref OrderingMethods_Module
               :  */
               :template <typename _MatrixType, typename _OrderingType>
               :class SparseLU : public internal::SparseLUImpl<typename _MatrixType::Scalar, typename _MatrixType::Index>
               :{
               :  public:
               :    typedef _MatrixType MatrixType; 
               :    typedef _OrderingType OrderingType;
               :    typedef typename MatrixType::Scalar Scalar; 
               :    typedef typename MatrixType::RealScalar RealScalar; 
               :    typedef typename MatrixType::Index Index; 
               :    typedef SparseMatrix<Scalar,ColMajor,Index> NCMatrix;
               :    typedef internal::MappedSuperNodalMatrix<Scalar, Index> SCMatrix; 
               :    typedef Matrix<Scalar,Dynamic,1> ScalarVector;
               :    typedef Matrix<Index,Dynamic,1> IndexVector;
               :    typedef PermutationMatrix<Dynamic, Dynamic, Index> PermutationType;
               :    typedef internal::SparseLUImpl<Scalar, Index> Base;
               :    
               :  public:
               :    SparseLU():m_isInitialized(true),m_lastError(""),m_Ustore(0,0,0,0,0,0),m_symmetricmode(false),m_diagpivotthresh(1.0),m_detPermR(1)
               :    {
               :      initperfvalues(); 
               :    }
               :    SparseLU(const MatrixType& matrix):m_isInitialized(true),m_lastError(""),m_Ustore(0,0,0,0,0,0),m_symmetricmode(false),m_diagpivotthresh(1.0),m_detPermR(1)
               :    {
               :      initperfvalues(); 
               :      compute(matrix);
               :    }
               :    
               :    ~SparseLU()
               :    {
               :      // Free all explicit dynamic pointers 
               :    }
               :    
               :    void analyzePattern (const MatrixType& matrix);
               :    void factorize (const MatrixType& matrix);
               :    void simplicialfactorize(const MatrixType& matrix);
               :    
               :    /**
               :      * Compute the symbolic and numeric factorization of the input sparse matrix.
               :      * The input matrix should be in column-major storage. 
               :      */
               :    void compute (const MatrixType& matrix)
               :    {
               :      // Analyze 
               :      analyzePattern(matrix); 
               :      //Factorize
               :      factorize(matrix);
               :    } 
               :    
               :    inline Index rows() const { return m_mat.rows(); }
               :    inline Index cols() const { return m_mat.cols(); }
               :    /** Indicate that the pattern of the input matrix is symmetric */
               :    void isSymmetric(bool sym)
               :    {
               :      m_symmetricmode = sym;
               :    }
               :    
               :    /** \returns an expression of the matrix L, internally stored as supernodes
               :      * The only operation available with this expression is the triangular solve
               :      * \code
               :      * y = b; matrixL().solveInPlace(y);
               :      * \endcode
               :      */
               :    SparseLUMatrixLReturnType<SCMatrix> matrixL() const
               :    {
               :      return SparseLUMatrixLReturnType<SCMatrix>(m_Lstore);
               :    }
               :    /** \returns an expression of the matrix U,
               :      * The only operation available with this expression is the triangular solve
               :      * \code
               :      * y = b; matrixU().solveInPlace(y);
               :      * \endcode
               :      */
               :    SparseLUMatrixUReturnType<SCMatrix,MappedSparseMatrix<Scalar,ColMajor,Index> > matrixU() const
               :    {
               :      return SparseLUMatrixUReturnType<SCMatrix, MappedSparseMatrix<Scalar,ColMajor,Index> >(m_Lstore, m_Ustore);
               :    }
               :
               :    /**
               :      * \returns a reference to the row matrix permutation \f$ P_r \f$ such that \f$P_r A P_c^T = L U\f$
               :      * \sa colsPermutation()
               :      */
               :    inline const PermutationType& rowsPermutation() const
               :    {
               :      return m_perm_r;
               :    }
               :    /**
               :      * \returns a reference to the column matrix permutation\f$ P_c^T \f$ such that \f$P_r A P_c^T = L U\f$
               :      * \sa rowsPermutation()
               :      */
               :    inline const PermutationType& colsPermutation() const
               :    {
               :      return m_perm_c;
               :    }
               :    /** Set the threshold used for a diagonal entry to be an acceptable pivot. */
               :    void setPivotThreshold(const RealScalar& thresh)
               :    {
               :      m_diagpivotthresh = thresh; 
               :    }
               :
               :    /** \returns the solution X of \f$ A X = B \f$ using the current decomposition of A.
               :      *
               :      * \warning the destination matrix X in X = this->solve(B) must be colmun-major.
               :      *
               :      * \sa compute()
               :      */
               :    template<typename Rhs>
               :    inline const internal::solve_retval<SparseLU, Rhs> solve(const MatrixBase<Rhs>& B) const 
               :    {
               :      eigen_assert(m_factorizationIsOk && "SparseLU is not initialized."); 
               :      eigen_assert(rows()==B.rows()
               :                    && "SparseLU::solve(): invalid number of rows of the right hand side matrix B");
               :          return internal::solve_retval<SparseLU, Rhs>(*this, B.derived());
               :    }
               :
               :    /** \returns the solution X of \f$ A X = B \f$ using the current decomposition of A.
               :      *
               :      * \sa compute()
               :      */
               :    template<typename Rhs>
               :    inline const internal::sparse_solve_retval<SparseLU, Rhs> solve(const SparseMatrixBase<Rhs>& B) const 
               :    {
               :      eigen_assert(m_factorizationIsOk && "SparseLU is not initialized."); 
               :      eigen_assert(rows()==B.rows()
               :                    && "SparseLU::solve(): invalid number of rows of the right hand side matrix B");
               :          return internal::sparse_solve_retval<SparseLU, Rhs>(*this, B.derived());
               :    }
               :    
               :    /** \brief Reports whether previous computation was successful.
               :      *
               :      * \returns \c Success if computation was succesful,
               :      *          \c NumericalIssue if the LU factorization reports a problem, zero diagonal for instance
               :      *          \c InvalidInput if the input matrix is invalid
               :      *
               :      * \sa iparm()          
               :      */
               :    ComputationInfo info() const
               :    {
               :      eigen_assert(m_isInitialized && "Decomposition is not initialized.");
               :      return m_info;
               :    }
               :    
               :    /**
               :      * \returns A string describing the type of error
               :      */
               :    std::string lastErrorMessage() const
               :    {
               :      return m_lastError; 
               :    }
               :
               :    template<typename Rhs, typename Dest>
               :    bool _solve(const MatrixBase<Rhs> &B, MatrixBase<Dest> &X_base) const
               :    {
               :      Dest& X(X_base.derived());
               :      eigen_assert(m_factorizationIsOk && "The matrix should be factorized first");
               :      EIGEN_STATIC_ASSERT((Dest::Flags&RowMajorBit)==0,
               :                        THIS_METHOD_IS_ONLY_FOR_COLUMN_MAJOR_MATRICES);
               :      
               :      // Permute the right hand side to form X = Pr*B
               :      // on return, X is overwritten by the computed solution
               :      X.resize(B.rows(),B.cols());
               :
               :      // this ugly const_cast_derived() helps to detect aliasing when applying the permutations
               :      for(Index j = 0; j < B.cols(); ++j)
               :        X.col(j) = rowsPermutation() * B.const_cast_derived().col(j);
               :      
               :      //Forward substitution with L
               :      this->matrixL().solveInPlace(X);
               :      this->matrixU().solveInPlace(X);
               :      
               :      // Permute back the solution 
               :      for (Index j = 0; j < B.cols(); ++j)
               :        X.col(j) = colsPermutation().inverse() * X.col(j);
               :      
               :      return true; 
               :    }
               :    
               :    /**
               :      * \returns the absolute value of the determinant of the matrix of which
               :      * *this is the QR decomposition.
               :      *
               :      * \warning a determinant can be very big or small, so for matrices
               :      * of large enough dimension, there is a risk of overflow/underflow.
               :      * One way to work around that is to use logAbsDeterminant() instead.
               :      *
               :      * \sa logAbsDeterminant(), signDeterminant()
               :      */
               :     Scalar absDeterminant()
               :    {
               :      eigen_assert(m_factorizationIsOk && "The matrix should be factorized first.");
               :      // Initialize with the determinant of the row matrix
               :      Scalar det = Scalar(1.);
               :      // Note that the diagonal blocks of U are stored in supernodes,
               :      // which are available in the  L part :)
               :      for (Index j = 0; j < this->cols(); ++j)
               :      {
               :        for (typename SCMatrix::InnerIterator it(m_Lstore, j); it; ++it)
               :        {
               :          if(it.index() == j)
               :          {
               :            det *= (std::abs)(it.value());
               :            break;
               :          }
               :        }
               :       }
               :       return det;
               :     }
               :
               :     /** \returns the natural log of the absolute value of the determinant of the matrix
               :       * of which **this is the QR decomposition
               :       *
               :       * \note This method is useful to work around the risk of overflow/underflow that's
               :       * inherent to the determinant computation.
               :       *
               :       * \sa absDeterminant(), signDeterminant()
               :       */
               :     Scalar logAbsDeterminant() const
               :     {
               :       eigen_assert(m_factorizationIsOk && "The matrix should be factorized first.");
               :       Scalar det = Scalar(0.);
               :       for (Index j = 0; j < this->cols(); ++j)
               :       {
               :         for (typename SCMatrix::InnerIterator it(m_Lstore, j); it; ++it)
               :         {
               :           if(it.row() < j) continue;
               :           if(it.row() == j)
               :           {
               :             det += (std::log)((std::abs)(it.value()));
               :             break;
               :           }
               :         }
               :       }
               :       return det;
               :     }
               :
               :     /** \returns A number representing the sign of the determinant
               :       *
               :       * \sa absDeterminant(), logAbsDeterminant()
               :       */
               :     Scalar signDeterminant()
               :     {
               :       eigen_assert(m_factorizationIsOk && "The matrix should be factorized first.");
               :       return Scalar(m_detPermR);
               :     }
               :
               :  protected:
               :    // Functions 
               :    void initperfvalues()
               :    {
               :      m_perfv.panel_size = 1;
               :      m_perfv.relax = 1; 
               :      m_perfv.maxsuper = 128; 
               :      m_perfv.rowblk = 16; 
               :      m_perfv.colblk = 8; 
               :      m_perfv.fillfactor = 20;  
               :    }
               :      
               :    // Variables 
               :    mutable ComputationInfo m_info;
               :    bool m_isInitialized;
               :    bool m_factorizationIsOk;
               :    bool m_analysisIsOk;
               :    std::string m_lastError;
               :    NCMatrix m_mat; // The input (permuted ) matrix 
               :    SCMatrix m_Lstore; // The lower triangular matrix (supernodal)
               :    MappedSparseMatrix<Scalar,ColMajor,Index> m_Ustore; // The upper triangular matrix
               :    PermutationType m_perm_c; // Column permutation 
               :    PermutationType m_perm_r ; // Row permutation
               :    IndexVector m_etree; // Column elimination tree 
               :    
               :    typename Base::GlobalLU_t m_glu; 
               :                               
               :    // SparseLU options 
               :    bool m_symmetricmode;
               :    // values for performance 
               :    internal::perfvalues<Index> m_perfv; 
               :    RealScalar m_diagpivotthresh; // Specifies the threshold used for a diagonal entry to be an acceptable pivot
               :    Index m_nnzL, m_nnzU; // Nonzeros in L and U factors 
               :    Index m_detPermR; // Determinant of the coefficient matrix
               :  private:
               :    // Disable copy constructor 
               :    SparseLU (const SparseLU& );
               :  
               :}; // End class SparseLU
               :
               :
               :
               :// Functions needed by the anaysis phase
               :/** 
               :  * Compute the column permutation to minimize the fill-in
               :  * 
               :  *  - Apply this permutation to the input matrix - 
               :  * 
               :  *  - Compute the column elimination tree on the permuted matrix 
               :  * 
               :  *  - Postorder the elimination tree and the column permutation
               :  * 
               :  */
               :template <typename MatrixType, typename OrderingType>
               :void SparseLU<MatrixType, OrderingType>::analyzePattern(const MatrixType& mat)
               :{
               :  
               :  //TODO  It is possible as in SuperLU to compute row and columns scaling vectors to equilibrate the matrix mat.
               :  
               :  OrderingType ord; 
               :  ord(mat,m_perm_c);
               :  
               :  // Apply the permutation to the column of the input  matrix
               :  //First copy the whole input matrix. 
               :  m_mat = mat;
               :  if (m_perm_c.size()) {
               :    m_mat.uncompress(); //NOTE: The effect of this command is only to create the InnerNonzeros pointers. FIXME : This vector is filled but not subsequently used.  
               :    //Then, permute only the column pointers
               :    const Index * outerIndexPtr;
               :    if (mat.isCompressed()) outerIndexPtr = mat.outerIndexPtr();
               :    else
               :    {
               :      Index *outerIndexPtr_t = new Index[mat.cols()+1];
               :      for(Index i = 0; i <= mat.cols(); i++) outerIndexPtr_t[i] = m_mat.outerIndexPtr()[i];
               :      outerIndexPtr = outerIndexPtr_t;
               :    }
               :    for (Index i = 0; i < mat.cols(); i++)
               :    {
               :      m_mat.outerIndexPtr()[m_perm_c.indices()(i)] = outerIndexPtr[i];
               :      m_mat.innerNonZeroPtr()[m_perm_c.indices()(i)] = outerIndexPtr[i+1] - outerIndexPtr[i];
               :    }
               :    if(!mat.isCompressed()) delete[] outerIndexPtr;
               :  }
               :  // Compute the column elimination tree of the permuted matrix 
               :  IndexVector firstRowElt;
               :  internal::coletree(m_mat, m_etree,firstRowElt); 
               :     
               :  // In symmetric mode, do not do postorder here
               :  if (!m_symmetricmode) {
               :    IndexVector post, iwork; 
               :    // Post order etree
               :    internal::treePostorder(m_mat.cols(), m_etree, post); 
               :      
               :   
               :    // Renumber etree in postorder 
               :    Index m = m_mat.cols(); 
               :    iwork.resize(m+1);
               :    for (Index i = 0; i < m; ++i) iwork(post(i)) = post(m_etree(i));
               :    m_etree = iwork;
               :    
               :    // Postmultiply A*Pc by post, i.e reorder the matrix according to the postorder of the etree
               :    PermutationType post_perm(m); 
               :    for (Index i = 0; i < m; i++) 
               :      post_perm.indices()(i) = post(i); 
               :        
               :    // Combine the two permutations : postorder the permutation for future use
               :    if(m_perm_c.size()) {
               :      m_perm_c = post_perm * m_perm_c;
               :    }
               :    
               :  } // end postordering 
               :  
               :  m_analysisIsOk = true; 
               :}
               :
               :// Functions needed by the numerical factorization phase
               :
               :
               :/** 
               :  *  - Numerical factorization 
               :  *  - Interleaved with the symbolic factorization 
               :  * On exit,  info is 
               :  * 
               :  *    = 0: successful factorization
               :  * 
               :  *    > 0: if info = i, and i is
               :  * 
               :  *       <= A->ncol: U(i,i) is exactly zero. The factorization has
               :  *          been completed, but the factor U is exactly singular,
               :  *          and division by zero will occur if it is used to solve a
               :  *          system of equations.
               :  * 
               :  *       > A->ncol: number of bytes allocated when memory allocation
               :  *         failure occurred, plus A->ncol. If lwork = -1, it is
               :  *         the estimated amount of space needed, plus A->ncol.  
               :  */
               :template <typename MatrixType, typename OrderingType>
               :void SparseLU<MatrixType, OrderingType>::factorize(const MatrixType& matrix) /* Eigen::SparseLU<Eigen::SparseMatrix<double, 0, int>, Eigen::COLAMDOrdering<int> >::factorize(Eigen::SparseMatrix<double, 0, int> const&) total:      2  2.7778 */
               :{
               :  using internal::emptyIdxLU;
               :  eigen_assert(m_analysisIsOk && "analyzePattern() should be called first"); 
               :  eigen_assert((matrix.rows() == matrix.cols()) && "Only for squared matrices");
               :  
               :  typedef typename IndexVector::Scalar Index; 
               :  
               :  
               :  // Apply the column permutation computed in analyzepattern()
               :  //   m_mat = matrix * m_perm_c.inverse(); 
               :  m_mat = matrix;
               :  if (m_perm_c.size()) 
               :  {
               :    m_mat.uncompress(); //NOTE: The effect of this command is only to create the InnerNonzeros pointers.
               :    //Then, permute only the column pointers
               :    const Index * outerIndexPtr;
               :    if (matrix.isCompressed()) outerIndexPtr = matrix.outerIndexPtr();
               :    else
               :    {
               :      Index* outerIndexPtr_t = new Index[matrix.cols()+1];
               :      for(Index i = 0; i <= matrix.cols(); i++) outerIndexPtr_t[i] = m_mat.outerIndexPtr()[i];
               :      outerIndexPtr = outerIndexPtr_t;
               :    }
               :    for (Index i = 0; i < matrix.cols(); i++)
               :    {
               :      m_mat.outerIndexPtr()[m_perm_c.indices()(i)] = outerIndexPtr[i];
               :      m_mat.innerNonZeroPtr()[m_perm_c.indices()(i)] = outerIndexPtr[i+1] - outerIndexPtr[i];
               :    }
               :    if(!matrix.isCompressed()) delete[] outerIndexPtr;
               :  } 
               :  else 
               :  { //FIXME This should not be needed if the empty permutation is handled transparently
               :    m_perm_c.resize(matrix.cols());
               :    for(Index i = 0; i < matrix.cols(); ++i) m_perm_c.indices()(i) = i;
               :  }
               :  
               :  Index m = m_mat.rows();
               :  Index n = m_mat.cols();
               :  Index nnz = m_mat.nonZeros();
               :  Index maxpanel = m_perfv.panel_size * m;
               :  // Allocate working storage common to the factor routines
               :  Index lwork = 0;
     1  1.3889 :  Index info = Base::memInit(m, n, nnz, lwork, m_perfv.fillfactor, m_perfv.panel_size, m_glu); 
               :  if (info) 
               :  {
               :    m_lastError = "UNABLE TO ALLOCATE WORKING MEMORY\n\n" ;
               :    m_factorizationIsOk = false;
               :    return ; 
               :  }
               :  
               :  // Set up pointers for integer working arrays 
               :  IndexVector segrep(m); segrep.setZero();
               :  IndexVector parent(m); parent.setZero();
               :  IndexVector xplore(m); xplore.setZero();
               :  IndexVector repfnz(maxpanel);
               :  IndexVector panel_lsub(maxpanel);
               :  IndexVector xprune(n); xprune.setZero();
               :  IndexVector marker(m*internal::LUNoMarker); marker.setZero();
               :  
               :  repfnz.setConstant(-1); 
               :  panel_lsub.setConstant(-1);
               :  
               :  // Set up pointers for scalar working arrays 
               :  ScalarVector dense; 
               :  dense.setZero(maxpanel);
               :  ScalarVector tempv; 
               :  tempv.setZero(internal::LUnumTempV(m, m_perfv.panel_size, m_perfv.maxsuper, /*m_perfv.rowblk*/m) );
               :  
               :  // Compute the inverse of perm_c
               :  PermutationType iperm_c(m_perm_c.inverse()); 
               :  
               :  // Identify initial relaxed snodes
               :  IndexVector relax_end(n);
               :  if ( m_symmetricmode == true ) 
               :    Base::heap_relax_snode(n, m_etree, m_perfv.relax, marker, relax_end);
               :  else
               :    Base::relax_snode(n, m_etree, m_perfv.relax, marker, relax_end);
               :  
               :  
               :  m_perm_r.resize(m); 
               :  m_perm_r.indices().setConstant(-1);
               :  marker.setConstant(-1);
               :  m_detPermR = 1; // Record the determinant of the row permutation
               :  
               :  m_glu.supno(0) = emptyIdxLU; m_glu.xsup.setConstant(0);
               :  m_glu.xsup(0) = m_glu.xlsub(0) = m_glu.xusub(0) = m_glu.xlusup(0) = Index(0);
               :  
               :  // Work on one 'panel' at a time. A panel is one of the following :
               :  //  (a) a relaxed supernode at the bottom of the etree, or
               :  //  (b) panel_size contiguous columns, <panel_size> defined by the user
               :  Index jcol; 
               :  IndexVector panel_histo(n);
               :  Index pivrow; // Pivotal row number in the original row matrix
               :  Index nseg1; // Number of segments in U-column above panel row jcol
               :  Index nseg; // Number of segments in each U-column 
               :  Index irep; 
               :  Index i, k, jj; 
               :  for (jcol = 0; jcol < n; )
               :  {
               :    // Adjust panel size so that a panel won't overlap with the next relaxed snode. 
               :    Index panel_size = m_perfv.panel_size; // upper bound on panel width
               :    for (k = jcol + 1; k < (std::min)(jcol+panel_size, n); k++)
               :    {
               :      if (relax_end(k) != emptyIdxLU) 
               :      {
               :        panel_size = k - jcol; 
               :        break; 
               :      }
               :    }
               :    if (k == n) 
               :      panel_size = n - jcol; 
               :      
               :    // Symbolic outer factorization on a panel of columns 
               :    Base::panel_dfs(m, panel_size, jcol, m_mat, m_perm_r.indices(), nseg1, dense, panel_lsub, segrep, repfnz, xprune, marker, parent, xplore, m_glu); 
               :    
               :    // Numeric sup-panel updates in topological order 
               :    Base::panel_bmod(m, panel_size, jcol, nseg1, dense, tempv, segrep, repfnz, m_glu); 
               :    
               :    // Sparse LU within the panel, and below the panel diagonal 
     1  1.3889 :    for ( jj = jcol; jj< jcol + panel_size; jj++) 
               :    {
               :      k = (jj - jcol) * m; // Column index for w-wide arrays 
               :      
               :      nseg = nseg1; // begin after all the panel segments
               :      //Depth-first-search for the current column
               :      VectorBlock<IndexVector> panel_lsubk(panel_lsub, k, m);
               :      VectorBlock<IndexVector> repfnz_k(repfnz, k, m); 
               :      info = Base::column_dfs(m, jj, m_perm_r.indices(), m_perfv.maxsuper, nseg, panel_lsubk, segrep, repfnz_k, xprune, marker, parent, xplore, m_glu); 
               :      if ( info ) 
               :      {
               :        m_lastError =  "UNABLE TO EXPAND MEMORY IN COLUMN_DFS() ";
               :        m_info = NumericalIssue; 
               :        m_factorizationIsOk = false; 
               :        return; 
               :      }
               :      // Numeric updates to this column 
               :      VectorBlock<ScalarVector> dense_k(dense, k, m); 
               :      VectorBlock<IndexVector> segrep_k(segrep, nseg1, m-nseg1); 
               :      info = Base::column_bmod(jj, (nseg - nseg1), dense_k, tempv, segrep_k, repfnz_k, jcol, m_glu); 
               :      if ( info ) 
               :      {
               :        m_lastError = "UNABLE TO EXPAND MEMORY IN COLUMN_BMOD() ";
               :        m_info = NumericalIssue; 
               :        m_factorizationIsOk = false; 
               :        return; 
               :      }
               :      
               :      // Copy the U-segments to ucol(*)
               :      info = Base::copy_to_ucol(jj, nseg, segrep, repfnz_k ,m_perm_r.indices(), dense_k, m_glu); 
               :      if ( info ) 
               :      {
               :        m_lastError = "UNABLE TO EXPAND MEMORY IN COPY_TO_UCOL() ";
               :        m_info = NumericalIssue; 
               :        m_factorizationIsOk = false; 
               :        return; 
               :      }
               :      
               :      // Form the L-segment 
               :      info = Base::pivotL(jj, m_diagpivotthresh, m_perm_r.indices(), iperm_c.indices(), pivrow, m_glu);
               :      if ( info ) 
               :      {
               :        m_lastError = "THE MATRIX IS STRUCTURALLY SINGULAR ... ZERO COLUMN AT ";
               :        std::ostringstream returnInfo;
               :        returnInfo << info; 
               :        m_lastError += returnInfo.str();
               :        m_info = NumericalIssue; 
               :        m_factorizationIsOk = false; 
               :        return; 
               :      }
               :      
               :      // Update the determinant of the row permutation matrix
               :      if (pivrow != jj) m_detPermR *= -1;
               :
               :      // Prune columns (0:jj-1) using column jj
               :      Base::pruneL(jj, m_perm_r.indices(), pivrow, nseg, segrep, repfnz_k, xprune, m_glu); 
               :      
               :      // Reset repfnz for this column 
               :      for (i = 0; i < nseg; i++)
               :      {
               :        irep = segrep(i); 
               :        repfnz_k(irep) = emptyIdxLU; 
               :      }
               :    } // end SparseLU within the panel  
               :    jcol += panel_size;  // Move to the next panel
               :  } // end for -- end elimination 
               :  
               :  // Count the number of nonzeros in factors 
               :  Base::countnz(n, m_nnzL, m_nnzU, m_glu); 
               :  // Apply permutation  to the L subscripts 
               :  Base::fixupL(n, m_perm_r.indices(), m_glu); 
               :  
               :  // Create supernode matrix L 
               :  m_Lstore.setInfos(m, n, m_glu.lusup, m_glu.xlusup, m_glu.lsub, m_glu.xlsub, m_glu.supno, m_glu.xsup); 
               :  // Create the column major upper sparse matrix  U; 
               :  new (&m_Ustore) MappedSparseMatrix<Scalar, ColMajor, Index> ( m, n, m_nnzU, m_glu.xusub.data(), m_glu.usub.data(), m_glu.ucol.data() ); 
               :  
               :  m_info = Success;
               :  m_factorizationIsOk = true;
               :}
               :
               :template<typename MappedSupernodalType>
               :struct SparseLUMatrixLReturnType : internal::no_assignment_operator
               :{
               :  typedef typename MappedSupernodalType::Index Index;
               :  typedef typename MappedSupernodalType::Scalar Scalar;
               :  SparseLUMatrixLReturnType(const MappedSupernodalType& mapL) : m_mapL(mapL)
               :  { }
               :  Index rows() { return m_mapL.rows(); }
               :  Index cols() { return m_mapL.cols(); }
               :  template<typename Dest>
               :  void solveInPlace( MatrixBase<Dest> &X) const
               :  {
               :    m_mapL.solveInPlace(X);
               :  }
               :  const MappedSupernodalType& m_mapL;
               :};
               :
               :template<typename MatrixLType, typename MatrixUType>
               :struct SparseLUMatrixUReturnType : internal::no_assignment_operator
               :{
               :  typedef typename MatrixLType::Index Index;
               :  typedef typename MatrixLType::Scalar Scalar;
               :  SparseLUMatrixUReturnType(const MatrixLType& mapL, const MatrixUType& mapU)
               :  : m_mapL(mapL),m_mapU(mapU)
               :  { }
               :  Index rows() { return m_mapL.rows(); }
               :  Index cols() { return m_mapL.cols(); }
               :
               :  template<typename Dest>   void solveInPlace(MatrixBase<Dest> &X) const
               :  {
               :    Index nrhs = X.cols();
               :    Index n = X.rows();
               :    // Backward solve with U
               :    for (Index k = m_mapL.nsuper(); k >= 0; k--)
               :    {
               :      Index fsupc = m_mapL.supToCol()[k];
               :      Index lda = m_mapL.colIndexPtr()[fsupc+1] - m_mapL.colIndexPtr()[fsupc]; // leading dimension
               :      Index nsupc = m_mapL.supToCol()[k+1] - fsupc;
               :      Index luptr = m_mapL.colIndexPtr()[fsupc];
               :
               :      if (nsupc == 1)
               :      {
               :        for (Index j = 0; j < nrhs; j++)
               :        {
               :          X(fsupc, j) /= m_mapL.valuePtr()[luptr];
               :        }
               :      }
               :      else
               :      {
               :        Map<const Matrix<Scalar,Dynamic,Dynamic>, 0, OuterStride<> > A( &(m_mapL.valuePtr()[luptr]), nsupc, nsupc, OuterStride<>(lda) );
               :        Map< Matrix<Scalar,Dynamic,Dynamic>, 0, OuterStride<> > U (&(X(fsupc,0)), nsupc, nrhs, OuterStride<>(n) );
               :        U = A.template triangularView<Upper>().solve(U);
               :      }
               :
               :      for (Index j = 0; j < nrhs; ++j)
               :      {
               :        for (Index jcol = fsupc; jcol < fsupc + nsupc; jcol++)
               :        {
               :          typename MatrixUType::InnerIterator it(m_mapU, jcol);
               :          for ( ; it; ++it)
               :          {
               :            Index irow = it.index();
               :            X(irow, j) -= X(jcol, j) * it.value();
               :          }
               :        }
               :      }
               :    } // End For U-solve
               :  }
               :  const MatrixLType& m_mapL;
               :  const MatrixUType& m_mapU;
               :};
               :
               :namespace internal {
               :  
               :template<typename _MatrixType, typename Derived, typename Rhs>
               :struct solve_retval<SparseLU<_MatrixType,Derived>, Rhs>
               :  : solve_retval_base<SparseLU<_MatrixType,Derived>, Rhs>
               :{
               :  typedef SparseLU<_MatrixType,Derived> Dec;
               :  EIGEN_MAKE_SOLVE_HELPERS(Dec,Rhs)
               :
               :  template<typename Dest> void evalTo(Dest& dst) const
               :  {
               :    dec()._solve(rhs(),dst);
               :  }
               :};
               :
               :template<typename _MatrixType, typename Derived, typename Rhs>
               :struct sparse_solve_retval<SparseLU<_MatrixType,Derived>, Rhs>
               :  : sparse_solve_retval_base<SparseLU<_MatrixType,Derived>, Rhs>
               :{
               :  typedef SparseLU<_MatrixType,Derived> Dec;
               :  EIGEN_MAKE_SPARSE_SOLVE_HELPERS(Dec,Rhs)
               :
               :  template<typename Dest> void evalTo(Dest& dst) const
               :  {
               :    this->defaultEvalTo(dst);
               :  }
               :};
               :} // end namespace internal
               :
               :} // End namespace Eigen 
               :
               :#endif
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/SparseCore/MappedSparseMatrix.h"
 * 
 *      2  2.7778
 */


               :// This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :#ifndef EIGEN_MAPPED_SPARSEMATRIX_H
               :#define EIGEN_MAPPED_SPARSEMATRIX_H
               :
               :namespace Eigen { 
               :
               :/** \class MappedSparseMatrix
               :  *
               :  * \brief Sparse matrix
               :  *
               :  * \param _Scalar the scalar type, i.e. the type of the coefficients
               :  *
               :  * See http://www.netlib.org/linalg/html_templates/node91.html for details on the storage scheme.
               :  *
               :  */
               :namespace internal {
               :template<typename _Scalar, int _Flags, typename _Index>
               :struct traits<MappedSparseMatrix<_Scalar, _Flags, _Index> > : traits<SparseMatrix<_Scalar, _Flags, _Index> >
               :{};
               :}
               :
               :template<typename _Scalar, int _Flags, typename _Index>
               :class MappedSparseMatrix
               :  : public SparseMatrixBase<MappedSparseMatrix<_Scalar, _Flags, _Index> >
               :{
               :  public:
               :    EIGEN_SPARSE_PUBLIC_INTERFACE(MappedSparseMatrix)
               :    enum { IsRowMajor = Base::IsRowMajor };
               :
               :  protected:
               :
               :    Index   m_outerSize;
               :    Index   m_innerSize;
               :    Index   m_nnz;
               :    Index*  m_outerIndex;
               :    Index*  m_innerIndices;
               :    Scalar* m_values;
               :
               :  public:
               :
               :    inline Index rows() const { return IsRowMajor ? m_outerSize : m_innerSize; }
               :    inline Index cols() const { return IsRowMajor ? m_innerSize : m_outerSize; }
               :    inline Index innerSize() const { return m_innerSize; }
               :    inline Index outerSize() const { return m_outerSize; }
               :    
               :    bool isCompressed() const { return true; }
               :
               :    //----------------------------------------
               :    // direct access interface
               :    inline const Scalar* valuePtr() const { return m_values; }
               :    inline Scalar* valuePtr() { return m_values; }
               :
               :    inline const Index* innerIndexPtr() const { return m_innerIndices; }
               :    inline Index* innerIndexPtr() { return m_innerIndices; }
               :
               :    inline const Index* outerIndexPtr() const { return m_outerIndex; }
               :    inline Index* outerIndexPtr() { return m_outerIndex; }
               :    //----------------------------------------
               :
               :    inline Scalar coeff(Index row, Index col) const
               :    {
               :      const Index outer = IsRowMajor ? row : col;
               :      const Index inner = IsRowMajor ? col : row;
               :
               :      Index start = m_outerIndex[outer];
               :      Index end = m_outerIndex[outer+1];
               :      if (start==end)
               :        return Scalar(0);
               :      else if (end>0 && inner==m_innerIndices[end-1])
               :        return m_values[end-1];
               :      // ^^  optimization: let's first check if it is the last coefficient
               :      // (very common in high level algorithms)
               :
               :      const Index* r = std::lower_bound(&m_innerIndices[start],&m_innerIndices[end-1],inner);
               :      const Index id = r-&m_innerIndices[0];
               :      return ((*r==inner) && (id<end)) ? m_values[id] : Scalar(0);
               :    }
               :
               :    inline Scalar& coeffRef(Index row, Index col)
               :    {
               :      const Index outer = IsRowMajor ? row : col;
               :      const Index inner = IsRowMajor ? col : row;
               :
               :      Index start = m_outerIndex[outer];
               :      Index end = m_outerIndex[outer+1];
               :      eigen_assert(end>=start && "you probably called coeffRef on a non finalized matrix");
               :      eigen_assert(end>start && "coeffRef cannot be called on a zero coefficient");
               :      Index* r = std::lower_bound(&m_innerIndices[start],&m_innerIndices[end],inner);
               :      const Index id = r-&m_innerIndices[0];
               :      eigen_assert((*r==inner) && (id<end) && "coeffRef cannot be called on a zero coefficient");
               :      return m_values[id];
               :    }
               :
               :    class InnerIterator;
               :    class ReverseInnerIterator;
               :
               :    /** \returns the number of non zero coefficients */
               :    inline Index nonZeros() const  { return m_nnz; }
               :
               :    inline MappedSparseMatrix(Index rows, Index cols, Index nnz, Index* outerIndexPtr, Index* innerIndexPtr, Scalar* valuePtr)
               :      : m_outerSize(IsRowMajor?rows:cols), m_innerSize(IsRowMajor?cols:rows), m_nnz(nnz), m_outerIndex(outerIndexPtr),
               :        m_innerIndices(innerIndexPtr), m_values(valuePtr)
               :    {}
               :
               :    /** Empty destructor */
               :    inline ~MappedSparseMatrix() {}
               :};
               :
               :template<typename Scalar, int _Flags, typename _Index>
               :class MappedSparseMatrix<Scalar,_Flags,_Index>::InnerIterator
               :{
               :  public:
               :    InnerIterator(const MappedSparseMatrix& mat, Index outer)
               :      : m_matrix(mat),
               :        m_outer(outer),
               :        m_id(mat.outerIndexPtr()[outer]),
               :        m_start(m_id),
     1  1.3889 :        m_end(mat.outerIndexPtr()[outer+1])
               :    {}
               :
               :    inline InnerIterator& operator++() { m_id++; return *this; }
               :
               :    inline Scalar value() const { return m_matrix.valuePtr()[m_id]; }
               :    inline Scalar& valueRef() { return const_cast<Scalar&>(m_matrix.valuePtr()[m_id]); }
               :
               :    inline Index index() const { return m_matrix.innerIndexPtr()[m_id]; }
               :    inline Index row() const { return IsRowMajor ? m_outer : index(); }
               :    inline Index col() const { return IsRowMajor ? index() : m_outer; }
               :
     1  1.3889 :    inline operator bool() const { return (m_id < m_end) && (m_id>=m_start); }
               :
               :  protected:
               :    const MappedSparseMatrix& m_matrix;
               :    const Index m_outer;
               :    Index m_id;
               :    const Index m_start;
               :    const Index m_end;
               :};
               :
               :template<typename Scalar, int _Flags, typename _Index>
               :class MappedSparseMatrix<Scalar,_Flags,_Index>::ReverseInnerIterator
               :{
               :  public:
               :    ReverseInnerIterator(const MappedSparseMatrix& mat, Index outer)
               :      : m_matrix(mat),
               :        m_outer(outer),
               :        m_id(mat.outerIndexPtr()[outer+1]),
               :        m_start(mat.outerIndexPtr()[outer]),
               :        m_end(m_id)
               :    {}
               :
               :    inline ReverseInnerIterator& operator--() { m_id--; return *this; }
               :
               :    inline Scalar value() const { return m_matrix.valuePtr()[m_id-1]; }
               :    inline Scalar& valueRef() { return const_cast<Scalar&>(m_matrix.valuePtr()[m_id-1]); }
               :
               :    inline Index index() const { return m_matrix.innerIndexPtr()[m_id-1]; }
               :    inline Index row() const { return IsRowMajor ? m_outer : index(); }
               :    inline Index col() const { return IsRowMajor ? index() : m_outer; }
               :
               :    inline operator bool() const { return (m_id <= m_end) && (m_id>m_start); }
               :
               :  protected:
               :    const MappedSparseMatrix& m_matrix;
               :    const Index m_outer;
               :    Index m_id;
               :    const Index m_start;
               :    const Index m_end;
               :};
               :
               :} // end namespace Eigen
               :
               :#endif // EIGEN_MAPPED_SPARSEMATRIX_H
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/OrderingMethods/Eigen_Colamd.h"
 * 
 *      2  2.7778
 */


               :// // This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2012 Desire Nuentsa Wakam <desire.nuentsa_wakam@inria.fr>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :// This file is modified from the colamd/symamd library. The copyright is below
               :
               ://   The authors of the code itself are Stefan I. Larimore and Timothy A.
               ://   Davis (davis@cise.ufl.edu), University of Florida.  The algorithm was
               ://   developed in collaboration with John Gilbert, Xerox PARC, and Esmond
               ://   Ng, Oak Ridge National Laboratory.
               :// 
               ://     Date:
               :// 
               ://   September 8, 2003.  Version 2.3.
               :// 
               ://     Acknowledgements:
               :// 
               ://   This work was supported by the National Science Foundation, under
               ://   grants DMS-9504974 and DMS-9803599.
               :// 
               ://     Notice:
               :// 
               ://   Copyright (c) 1998-2003 by the University of Florida.
               ://   All Rights Reserved.
               :// 
               ://   THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY
               ://   EXPRESSED OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.
               :// 
               ://   Permission is hereby granted to use, copy, modify, and/or distribute
               ://   this program, provided that the Copyright, this License, and the
               ://   Availability of the original version is retained on all copies and made
               ://   accessible to the end-user of any code or package that includes COLAMD
               ://   or any modified version of COLAMD. 
               :// 
               ://     Availability:
               :// 
               ://   The colamd/symamd library is available at
               :// 
               ://       http://www.cise.ufl.edu/research/sparse/colamd/
               :
               ://   This is the http://www.cise.ufl.edu/research/sparse/colamd/colamd.h
               ://   file.  It is required by the colamd.c, colamdmex.c, and symamdmex.c
               ://   files, and by any C code that calls the routines whose prototypes are
               ://   listed below, or that uses the colamd/symamd definitions listed below.
               :  
               :#ifndef EIGEN_COLAMD_H
               :#define EIGEN_COLAMD_H
               :
               :namespace internal {
               :/* Ensure that debugging is turned off: */
               :#ifndef COLAMD_NDEBUG
               :#define COLAMD_NDEBUG
               :#endif /* NDEBUG */
               :/* ========================================================================== */
               :/* === Knob and statistics definitions ====================================== */
               :/* ========================================================================== */
               :
               :/* size of the knobs [ ] array.  Only knobs [0..1] are currently used. */
               :#define COLAMD_KNOBS 20
               :
               :/* number of output statistics.  Only stats [0..6] are currently used. */
               :#define COLAMD_STATS 20 
               :
               :/* knobs [0] and stats [0]: dense row knob and output statistic. */
               :#define COLAMD_DENSE_ROW 0
               :
               :/* knobs [1] and stats [1]: dense column knob and output statistic. */
               :#define COLAMD_DENSE_COL 1
               :
               :/* stats [2]: memory defragmentation count output statistic */
               :#define COLAMD_DEFRAG_COUNT 2
               :
               :/* stats [3]: colamd status:  zero OK, > 0 warning or notice, < 0 error */
               :#define COLAMD_STATUS 3
               :
               :/* stats [4..6]: error info, or info on jumbled columns */ 
               :#define COLAMD_INFO1 4
               :#define COLAMD_INFO2 5
               :#define COLAMD_INFO3 6
               :
               :/* error codes returned in stats [3]: */
               :#define COLAMD_OK       (0)
               :#define COLAMD_OK_BUT_JUMBLED     (1)
               :#define COLAMD_ERROR_A_not_present    (-1)
               :#define COLAMD_ERROR_p_not_present    (-2)
               :#define COLAMD_ERROR_nrow_negative    (-3)
               :#define COLAMD_ERROR_ncol_negative    (-4)
               :#define COLAMD_ERROR_nnz_negative   (-5)
               :#define COLAMD_ERROR_p0_nonzero     (-6)
               :#define COLAMD_ERROR_A_too_small    (-7)
               :#define COLAMD_ERROR_col_length_negative  (-8)
               :#define COLAMD_ERROR_row_index_out_of_bounds  (-9)
               :#define COLAMD_ERROR_out_of_memory    (-10)
               :#define COLAMD_ERROR_internal_error   (-999)
               :
               :/* ========================================================================== */
               :/* === Definitions ========================================================== */
               :/* ========================================================================== */
               :
               :#define COLAMD_MAX(a,b) (((a) > (b)) ? (a) : (b))
               :#define COLAMD_MIN(a,b) (((a) < (b)) ? (a) : (b))
               :
               :#define ONES_COMPLEMENT(r) (-(r)-1)
               :
               :/* -------------------------------------------------------------------------- */
               :
               :#define COLAMD_EMPTY (-1)
               :
               :/* Row and column status */
               :#define ALIVE (0)
               :#define DEAD  (-1)
               :
               :/* Column status */
               :#define DEAD_PRINCIPAL    (-1)
               :#define DEAD_NON_PRINCIPAL  (-2)
               :
               :/* Macros for row and column status update and checking. */
               :#define ROW_IS_DEAD(r)      ROW_IS_MARKED_DEAD (Row[r].shared2.mark)
               :#define ROW_IS_MARKED_DEAD(row_mark)  (row_mark < ALIVE)
               :#define ROW_IS_ALIVE(r)     (Row [r].shared2.mark >= ALIVE)
               :#define COL_IS_DEAD(c)      (Col [c].start < ALIVE)
               :#define COL_IS_ALIVE(c)     (Col [c].start >= ALIVE)
               :#define COL_IS_DEAD_PRINCIPAL(c)  (Col [c].start == DEAD_PRINCIPAL)
               :#define KILL_ROW(r)     { Row [r].shared2.mark = DEAD ; }
               :#define KILL_PRINCIPAL_COL(c)   { Col [c].start = DEAD_PRINCIPAL ; }
               :#define KILL_NON_PRINCIPAL_COL(c) { Col [c].start = DEAD_NON_PRINCIPAL ; }
               :
               :/* ========================================================================== */
               :/* === Colamd reporting mechanism =========================================== */
               :/* ========================================================================== */
               :
               :// == Row and Column structures ==
               :template <typename Index>
               :struct colamd_col
               :{
               :  Index start ;   /* index for A of first row in this column, or DEAD */
               :  /* if column is dead */
               :  Index length ;  /* number of rows in this column */
               :  union
               :  {
               :    Index thickness ; /* number of original columns represented by this */
               :    /* col, if the column is alive */
               :    Index parent ;  /* parent in parent tree super-column structure, if */
               :    /* the column is dead */
               :  } shared1 ;
               :  union
               :  {
               :    Index score ; /* the score used to maintain heap, if col is alive */
               :    Index order ; /* pivot ordering of this column, if col is dead */
               :  } shared2 ;
               :  union
               :  {
               :    Index headhash ;  /* head of a hash bucket, if col is at the head of */
               :    /* a degree list */
               :    Index hash ;  /* hash value, if col is not in a degree list */
               :    Index prev ;  /* previous column in degree list, if col is in a */
               :    /* degree list (but not at the head of a degree list) */
               :  } shared3 ;
               :  union
               :  {
               :    Index degree_next ; /* next column, if col is in a degree list */
               :    Index hash_next ;   /* next column, if col is in a hash list */
               :  } shared4 ;
               :  
               :};
               : 
               :template <typename Index>
               :struct Colamd_Row
               :{
               :  Index start ;   /* index for A of first col in this row */
               :  Index length ;  /* number of principal columns in this row */
               :  union
               :  {
               :    Index degree ;  /* number of principal & non-principal columns in row */
               :    Index p ;   /* used as a row pointer in init_rows_cols () */
               :  } shared1 ;
               :  union
               :  {
               :    Index mark ;  /* for computing set differences and marking dead rows*/
               :    Index first_column ;/* first column in row (used in garbage collection) */
               :  } shared2 ;
               :  
               :};
               : 
               :/* ========================================================================== */
               :/* === Colamd recommended memory size ======================================= */
               :/* ========================================================================== */
               : 
               :/*
               :  The recommended length Alen of the array A passed to colamd is given by
               :  the COLAMD_RECOMMENDED (nnz, n_row, n_col) macro.  It returns -1 if any
               :  argument is negative.  2*nnz space is required for the row and column
               :  indices of the matrix. colamd_c (n_col) + colamd_r (n_row) space is
               :  required for the Col and Row arrays, respectively, which are internal to
               :  colamd.  An additional n_col space is the minimal amount of "elbow room",
               :  and nnz/5 more space is recommended for run time efficiency.
               :  
               :  This macro is not needed when using symamd.
               :  
               :  Explicit typecast to Index added Sept. 23, 2002, COLAMD version 2.2, to avoid
               :  gcc -pedantic warning messages.
               :*/
               :template <typename Index>
               :inline Index colamd_c(Index n_col) 
               :{ return Index( ((n_col) + 1) * sizeof (colamd_col<Index>) / sizeof (Index) ) ; }
               :
               :template <typename Index>
               :inline Index  colamd_r(Index n_row)
               :{ return Index(((n_row) + 1) * sizeof (Colamd_Row<Index>) / sizeof (Index)); }
               :
               :// Prototypes of non-user callable routines
               :template <typename Index>
               :static Index init_rows_cols (Index n_row, Index n_col, Colamd_Row<Index> Row [], colamd_col<Index> col [], Index A [], Index p [], Index stats[COLAMD_STATS] ); 
               :
               :template <typename Index>
               :static void init_scoring (Index n_row, Index n_col, Colamd_Row<Index> Row [], colamd_col<Index> Col [], Index A [], Index head [], double knobs[COLAMD_KNOBS], Index *p_n_row2, Index *p_n_col2, Index *p_max_deg);
               :
               :template <typename Index>
               :static Index find_ordering (Index n_row, Index n_col, Index Alen, Colamd_Row<Index> Row [], colamd_col<Index> Col [], Index A [], Index head [], Index n_col2, Index max_deg, Index pfree);
               :
               :template <typename Index>
               :static void order_children (Index n_col, colamd_col<Index> Col [], Index p []);
               :
               :template <typename Index>
               :static void detect_super_cols (colamd_col<Index> Col [], Index A [], Index head [], Index row_start, Index row_length ) ;
               :
               :template <typename Index>
               :static Index garbage_collection (Index n_row, Index n_col, Colamd_Row<Index> Row [], colamd_col<Index> Col [], Index A [], Index *pfree) ;
               :
               :template <typename Index>
               :static inline  Index clear_mark (Index n_row, Colamd_Row<Index> Row [] ) ;
               :
               :/* === No debugging ========================================================= */
               :
               :#define COLAMD_DEBUG0(params) ;
               :#define COLAMD_DEBUG1(params) ;
               :#define COLAMD_DEBUG2(params) ;
               :#define COLAMD_DEBUG3(params) ;
               :#define COLAMD_DEBUG4(params) ;
               :
               :#define COLAMD_ASSERT(expression) ((void) 0)
               :
               :
               :/**
               : * \brief Returns the recommended value of Alen 
               : * 
               : * Returns recommended value of Alen for use by colamd.  
               : * Returns -1 if any input argument is negative.  
               : * The use of this routine or macro is optional.  
               : * Note that the macro uses its arguments   more than once, 
               : * so be careful for side effects, if you pass expressions as arguments to COLAMD_RECOMMENDED.  
               : * 
               : * \param nnz nonzeros in A
               : * \param n_row number of rows in A
               : * \param n_col number of columns in A
               : * \return recommended value of Alen for use by colamd
               : */
               :template <typename Index>
               :inline Index colamd_recommended ( Index nnz, Index n_row, Index n_col)
               :{
     1  1.3889 :  if ((nnz) < 0 || (n_row) < 0 || (n_col) < 0)
               :    return (-1);
               :  else
               :    return (2 * (nnz) + colamd_c (n_col) + colamd_r (n_row) + (n_col) + ((nnz) / 5)); 
               :}
               :
               :/**
               : * \brief set default parameters  The use of this routine is optional.
               : * 
               : * Colamd: rows with more than (knobs [COLAMD_DENSE_ROW] * n_col)
               : * entries are removed prior to ordering.  Columns with more than
               : * (knobs [COLAMD_DENSE_COL] * n_row) entries are removed prior to
               : * ordering, and placed last in the output column ordering. 
               : *
               : * COLAMD_DENSE_ROW and COLAMD_DENSE_COL are defined as 0 and 1,
               : * respectively, in colamd.h.  Default values of these two knobs
               : * are both 0.5.  Currently, only knobs [0] and knobs [1] are
               : * used, but future versions may use more knobs.  If so, they will
               : * be properly set to their defaults by the future version of
               : * colamd_set_defaults, so that the code that calls colamd will
               : * not need to change, assuming that you either use
               : * colamd_set_defaults, or pass a (double *) NULL pointer as the
               : * knobs array to colamd or symamd.
               : * 
               : * \param knobs parameter settings for colamd
               : */
               :
               :static inline void colamd_set_defaults(double knobs[COLAMD_KNOBS])
               :{
               :  /* === Local variables ================================================== */
               :  
               :  int i ;
               :
               :  if (!knobs)
               :  {
               :    return ;      /* no knobs to initialize */
               :  }
               :  for (i = 0 ; i < COLAMD_KNOBS ; i++)
               :  {
               :    knobs [i] = 0 ;
               :  }
               :  knobs [COLAMD_DENSE_ROW] = 0.5 ;  /* ignore rows over 50% dense */
               :  knobs [COLAMD_DENSE_COL] = 0.5 ;  /* ignore columns over 50% dense */
               :}
               :
               :/** 
               : * \brief  Computes a column ordering using the column approximate minimum degree ordering
               : * 
               : * Computes a column ordering (Q) of A such that P(AQ)=LU or
               : * (AQ)'AQ=LL' have less fill-in and require fewer floating point
               : * operations than factorizing the unpermuted matrix A or A'A,
               : * respectively.
               : * 
               : * 
               : * \param n_row number of rows in A
               : * \param n_col number of columns in A
               : * \param Alen, size of the array A
               : * \param A row indices of the matrix, of size ALen
               : * \param p column pointers of A, of size n_col+1
               : * \param knobs parameter settings for colamd
               : * \param stats colamd output statistics and error codes
               : */
               :template <typename Index>
               :static bool colamd(Index n_row, Index n_col, Index Alen, Index *A, Index *p, double knobs[COLAMD_KNOBS], Index stats[COLAMD_STATS])
               :{
               :  /* === Local variables ================================================== */
               :  
               :  Index i ;     /* loop index */
               :  Index nnz ;     /* nonzeros in A */
               :  Index Row_size ;    /* size of Row [], in integers */
               :  Index Col_size ;    /* size of Col [], in integers */
               :  Index need ;      /* minimum required length of A */
               :  Colamd_Row<Index> *Row ;   /* pointer into A of Row [0..n_row] array */
               :  colamd_col<Index> *Col ;   /* pointer into A of Col [0..n_col] array */
               :  Index n_col2 ;    /* number of non-dense, non-empty columns */
               :  Index n_row2 ;    /* number of non-dense, non-empty rows */
               :  Index ngarbage ;    /* number of garbage collections performed */
               :  Index max_deg ;   /* maximum row degree */
               :  double default_knobs [COLAMD_KNOBS] ; /* default knobs array */
               :  
               :  
               :  /* === Check the input arguments ======================================== */
               :  
               :  if (!stats)
               :  {
               :    COLAMD_DEBUG0 (("colamd: stats not present\n")) ;
               :    return (false) ;
               :  }
               :  for (i = 0 ; i < COLAMD_STATS ; i++)
               :  {
               :    stats [i] = 0 ;
               :  }
               :  stats [COLAMD_STATUS] = COLAMD_OK ;
               :  stats [COLAMD_INFO1] = -1 ;
               :  stats [COLAMD_INFO2] = -1 ;
               :  
               :  if (!A)   /* A is not present */
               :  {
               :    stats [COLAMD_STATUS] = COLAMD_ERROR_A_not_present ;
               :    COLAMD_DEBUG0 (("colamd: A not present\n")) ;
               :    return (false) ;
               :  }
               :  
               :  if (!p)   /* p is not present */
               :  {
               :    stats [COLAMD_STATUS] = COLAMD_ERROR_p_not_present ;
               :    COLAMD_DEBUG0 (("colamd: p not present\n")) ;
               :    return (false) ;
               :  }
               :  
               :  if (n_row < 0)  /* n_row must be >= 0 */
               :  {
               :    stats [COLAMD_STATUS] = COLAMD_ERROR_nrow_negative ;
               :    stats [COLAMD_INFO1] = n_row ;
               :    COLAMD_DEBUG0 (("colamd: nrow negative %d\n", n_row)) ;
               :    return (false) ;
               :  }
               :  
               :  if (n_col < 0)  /* n_col must be >= 0 */
               :  {
               :    stats [COLAMD_STATUS] = COLAMD_ERROR_ncol_negative ;
               :    stats [COLAMD_INFO1] = n_col ;
               :    COLAMD_DEBUG0 (("colamd: ncol negative %d\n", n_col)) ;
               :    return (false) ;
               :  }
               :  
               :  nnz = p [n_col] ;
               :  if (nnz < 0)  /* nnz must be >= 0 */
               :  {
               :    stats [COLAMD_STATUS] = COLAMD_ERROR_nnz_negative ;
               :    stats [COLAMD_INFO1] = nnz ;
               :    COLAMD_DEBUG0 (("colamd: number of entries negative %d\n", nnz)) ;
               :    return (false) ;
               :  }
               :  
               :  if (p [0] != 0)
               :  {
               :    stats [COLAMD_STATUS] = COLAMD_ERROR_p0_nonzero ;
               :    stats [COLAMD_INFO1] = p [0] ;
               :    COLAMD_DEBUG0 (("colamd: p[0] not zero %d\n", p [0])) ;
               :    return (false) ;
               :  }
               :  
               :  /* === If no knobs, set default knobs =================================== */
               :  
               :  if (!knobs)
               :  {
               :    colamd_set_defaults (default_knobs) ;
               :    knobs = default_knobs ;
               :  }
               :  
               :  /* === Allocate the Row and Col arrays from array A ===================== */
               :  
               :  Col_size = colamd_c (n_col) ;
               :  Row_size = colamd_r (n_row) ;
               :  need = 2*nnz + n_col + Col_size + Row_size ;
               :  
               :  if (need > Alen)
               :  {
               :    /* not enough space in array A to perform the ordering */
               :    stats [COLAMD_STATUS] = COLAMD_ERROR_A_too_small ;
               :    stats [COLAMD_INFO1] = need ;
               :    stats [COLAMD_INFO2] = Alen ;
               :    COLAMD_DEBUG0 (("colamd: Need Alen >= %d, given only Alen = %d\n", need,Alen));
               :    return (false) ;
               :  }
               :  
               :  Alen -= Col_size + Row_size ;
               :  Col = (colamd_col<Index> *) &A [Alen] ;
               :  Row = (Colamd_Row<Index> *) &A [Alen + Col_size] ;
               :
               :  /* === Construct the row and column data structures ===================== */
               :  
               :  if (!Eigen::internal::init_rows_cols (n_row, n_col, Row, Col, A, p, stats))
               :  {
               :    /* input matrix is invalid */
               :    COLAMD_DEBUG0 (("colamd: Matrix invalid\n")) ;
               :    return (false) ;
               :  }
               :  
               :  /* === Initialize scores, kill dense rows/columns ======================= */
               :
               :  Eigen::internal::init_scoring (n_row, n_col, Row, Col, A, p, knobs,
               :		&n_row2, &n_col2, &max_deg) ;
               :  
               :  /* === Order the supercolumns =========================================== */
               :  
               :  ngarbage = Eigen::internal::find_ordering (n_row, n_col, Alen, Row, Col, A, p,
               :			    n_col2, max_deg, 2*nnz) ;
               :  
               :  /* === Order the non-principal columns ================================== */
               :  
               :  Eigen::internal::order_children (n_col, Col, p) ;
               :  
               :  /* === Return statistics in stats ======================================= */
               :  
               :  stats [COLAMD_DENSE_ROW] = n_row - n_row2 ;
               :  stats [COLAMD_DENSE_COL] = n_col - n_col2 ;
               :  stats [COLAMD_DEFRAG_COUNT] = ngarbage ;
               :  COLAMD_DEBUG0 (("colamd: done.\n")) ; 
               :  return (true) ;
               :}
               :
               :/* ========================================================================== */
               :/* === NON-USER-CALLABLE ROUTINES: ========================================== */
               :/* ========================================================================== */
               :
               :/* There are no user-callable routines beyond this point in the file */
               :
               :
               :/* ========================================================================== */
               :/* === init_rows_cols ======================================================= */
               :/* ========================================================================== */
               :
               :/*
               :  Takes the column form of the matrix in A and creates the row form of the
               :  matrix.  Also, row and column attributes are stored in the Col and Row
               :  structs.  If the columns are un-sorted or contain duplicate row indices,
               :  this routine will also sort and remove duplicate row indices from the
               :  column form of the matrix.  Returns false if the matrix is invalid,
               :  true otherwise.  Not user-callable.
               :*/
               :template <typename Index>
               :static Index init_rows_cols  /* returns true if OK, or false otherwise */
               :  (
               :    /* === Parameters ======================================================= */
               :
               :    Index n_row,      /* number of rows of A */
               :    Index n_col,      /* number of columns of A */
               :    Colamd_Row<Index> Row [],    /* of size n_row+1 */
               :    colamd_col<Index> Col [],    /* of size n_col+1 */
               :    Index A [],     /* row indices of A, of size Alen */
               :    Index p [],     /* pointers to columns in A, of size n_col+1 */
               :    Index stats [COLAMD_STATS]  /* colamd statistics */ 
               :    )
               :{
               :  /* === Local variables ================================================== */
               :
               :  Index col ;     /* a column index */
               :  Index row ;     /* a row index */
               :  Index *cp ;     /* a column pointer */
               :  Index *cp_end ;   /* a pointer to the end of a column */
               :  Index *rp ;     /* a row pointer */
               :  Index *rp_end ;   /* a pointer to the end of a row */
               :  Index last_row ;    /* previous row */
               :
               :  /* === Initialize columns, and check column pointers ==================== */
               :
               :  for (col = 0 ; col < n_col ; col++)
               :  {
               :    Col [col].start = p [col] ;
               :    Col [col].length = p [col+1] - p [col] ;
               :
               :    if (Col [col].length < 0)
               :    {
               :      /* column pointers must be non-decreasing */
               :      stats [COLAMD_STATUS] = COLAMD_ERROR_col_length_negative ;
               :      stats [COLAMD_INFO1] = col ;
               :      stats [COLAMD_INFO2] = Col [col].length ;
               :      COLAMD_DEBUG0 (("colamd: col %d length %d < 0\n", col, Col [col].length)) ;
               :      return (false) ;
               :    }
               :
               :    Col [col].shared1.thickness = 1 ;
               :    Col [col].shared2.score = 0 ;
               :    Col [col].shared3.prev = COLAMD_EMPTY ;
               :    Col [col].shared4.degree_next = COLAMD_EMPTY ;
               :  }
               :
               :  /* p [0..n_col] no longer needed, used as "head" in subsequent routines */
               :
               :  /* === Scan columns, compute row degrees, and check row indices ========= */
               :
               :  stats [COLAMD_INFO3] = 0 ;  /* number of duplicate or unsorted row indices*/
               :
               :  for (row = 0 ; row < n_row ; row++)
               :  {
               :    Row [row].length = 0 ;
               :    Row [row].shared2.mark = -1 ;
               :  }
               :
               :  for (col = 0 ; col < n_col ; col++)
               :  {
               :    last_row = -1 ;
               :
               :    cp = &A [p [col]] ;
               :    cp_end = &A [p [col+1]] ;
               :
               :    while (cp < cp_end)
               :    {
               :      row = *cp++ ;
               :
               :      /* make sure row indices within range */
               :      if (row < 0 || row >= n_row)
               :      {
               :	stats [COLAMD_STATUS] = COLAMD_ERROR_row_index_out_of_bounds ;
               :	stats [COLAMD_INFO1] = col ;
               :	stats [COLAMD_INFO2] = row ;
               :	stats [COLAMD_INFO3] = n_row ;
               :	COLAMD_DEBUG0 (("colamd: row %d col %d out of bounds\n", row, col)) ;
               :	return (false) ;
               :      }
               :
               :      if (row <= last_row || Row [row].shared2.mark == col)
               :      {
               :	/* row index are unsorted or repeated (or both), thus col */
               :	/* is jumbled.  This is a notice, not an error condition. */
               :	stats [COLAMD_STATUS] = COLAMD_OK_BUT_JUMBLED ;
               :	stats [COLAMD_INFO1] = col ;
               :	stats [COLAMD_INFO2] = row ;
               :	(stats [COLAMD_INFO3]) ++ ;
               :	COLAMD_DEBUG1 (("colamd: row %d col %d unsorted/duplicate\n",row,col));
               :      }
               :
               :      if (Row [row].shared2.mark != col)
               :      {
               :	Row [row].length++ ;
               :      }
               :      else
               :      {
               :	/* this is a repeated entry in the column, */
               :	/* it will be removed */
               :	Col [col].length-- ;
               :      }
               :
               :      /* mark the row as having been seen in this column */
               :      Row [row].shared2.mark = col ;
               :
               :      last_row = row ;
               :    }
               :  }
               :
               :  /* === Compute row pointers ============================================= */
               :
               :  /* row form of the matrix starts directly after the column */
               :  /* form of matrix in A */
               :  Row [0].start = p [n_col] ;
               :  Row [0].shared1.p = Row [0].start ;
               :  Row [0].shared2.mark = -1 ;
               :  for (row = 1 ; row < n_row ; row++)
               :  {
               :    Row [row].start = Row [row-1].start + Row [row-1].length ;
               :    Row [row].shared1.p = Row [row].start ;
               :    Row [row].shared2.mark = -1 ;
               :  }
               :
               :  /* === Create row form ================================================== */
               :
               :  if (stats [COLAMD_STATUS] == COLAMD_OK_BUT_JUMBLED)
               :  {
               :    /* if cols jumbled, watch for repeated row indices */
               :    for (col = 0 ; col < n_col ; col++)
               :    {
               :      cp = &A [p [col]] ;
               :      cp_end = &A [p [col+1]] ;
               :      while (cp < cp_end)
               :      {
               :	row = *cp++ ;
               :	if (Row [row].shared2.mark != col)
               :	{
               :	  A [(Row [row].shared1.p)++] = col ;
               :	  Row [row].shared2.mark = col ;
               :	}
               :      }
               :    }
               :  }
               :  else
               :  {
               :    /* if cols not jumbled, we don't need the mark (this is faster) */
               :    for (col = 0 ; col < n_col ; col++)
               :    {
               :      cp = &A [p [col]] ;
               :      cp_end = &A [p [col+1]] ;
     1  1.3889 :      while (cp < cp_end)
               :      {
               :	A [(Row [*cp++].shared1.p)++] = col ;
               :      }
               :    }
               :  }
               :
               :  /* === Clear the row marks and set row degrees ========================== */
               :
               :  for (row = 0 ; row < n_row ; row++)
               :  {
               :    Row [row].shared2.mark = 0 ;
               :    Row [row].shared1.degree = Row [row].length ;
               :  }
               :
               :  /* === See if we need to re-create columns ============================== */
               :
               :  if (stats [COLAMD_STATUS] == COLAMD_OK_BUT_JUMBLED)
               :  {
               :    COLAMD_DEBUG0 (("colamd: reconstructing column form, matrix jumbled\n")) ;
               :
               :
               :    /* === Compute col pointers ========================================= */
               :
               :    /* col form of the matrix starts at A [0]. */
               :    /* Note, we may have a gap between the col form and the row */
               :    /* form if there were duplicate entries, if so, it will be */
               :    /* removed upon the first garbage collection */
               :    Col [0].start = 0 ;
               :    p [0] = Col [0].start ;
               :    for (col = 1 ; col < n_col ; col++)
               :    {
               :      /* note that the lengths here are for pruned columns, i.e. */
               :      /* no duplicate row indices will exist for these columns */
               :      Col [col].start = Col [col-1].start + Col [col-1].length ;
               :      p [col] = Col [col].start ;
               :    }
               :
               :    /* === Re-create col form =========================================== */
               :
               :    for (row = 0 ; row < n_row ; row++)
               :    {
               :      rp = &A [Row [row].start] ;
               :      rp_end = rp + Row [row].length ;
               :      while (rp < rp_end)
               :      {
               :	A [(p [*rp++])++] = row ;
               :      }
               :    }
               :  }
               :
               :  /* === Done.  Matrix is not (or no longer) jumbled ====================== */
               :
               :  return (true) ;
               :}
               :
               :
               :/* ========================================================================== */
               :/* === init_scoring ========================================================= */
               :/* ========================================================================== */
               :
               :/*
               :  Kills dense or empty columns and rows, calculates an initial score for
               :  each column, and places all columns in the degree lists.  Not user-callable.
               :*/
               :template <typename Index>
               :static void init_scoring
               :  (
               :    /* === Parameters ======================================================= */
               :
               :    Index n_row,      /* number of rows of A */
               :    Index n_col,      /* number of columns of A */
               :    Colamd_Row<Index> Row [],    /* of size n_row+1 */
               :    colamd_col<Index> Col [],    /* of size n_col+1 */
               :    Index A [],     /* column form and row form of A */
               :    Index head [],    /* of size n_col+1 */
               :    double knobs [COLAMD_KNOBS],/* parameters */
               :    Index *p_n_row2,    /* number of non-dense, non-empty rows */
               :    Index *p_n_col2,    /* number of non-dense, non-empty columns */
               :    Index *p_max_deg    /* maximum row degree */
               :    )
               :{
               :  /* === Local variables ================================================== */
               :
               :  Index c ;     /* a column index */
               :  Index r, row ;    /* a row index */
               :  Index *cp ;     /* a column pointer */
               :  Index deg ;     /* degree of a row or column */
               :  Index *cp_end ;   /* a pointer to the end of a column */
               :  Index *new_cp ;   /* new column pointer */
               :  Index col_length ;    /* length of pruned column */
               :  Index score ;     /* current column score */
               :  Index n_col2 ;    /* number of non-dense, non-empty columns */
               :  Index n_row2 ;    /* number of non-dense, non-empty rows */
               :  Index dense_row_count ; /* remove rows with more entries than this */
               :  Index dense_col_count ; /* remove cols with more entries than this */
               :  Index min_score ;   /* smallest column score */
               :  Index max_deg ;   /* maximum row degree */
               :  Index next_col ;    /* Used to add to degree list.*/
               :
               :
               :  /* === Extract knobs ==================================================== */
               :
               :  dense_row_count = COLAMD_MAX (0, COLAMD_MIN (knobs [COLAMD_DENSE_ROW] * n_col, n_col)) ;
               :  dense_col_count = COLAMD_MAX (0, COLAMD_MIN (knobs [COLAMD_DENSE_COL] * n_row, n_row)) ;
               :  COLAMD_DEBUG1 (("colamd: densecount: %d %d\n", dense_row_count, dense_col_count)) ;
               :  max_deg = 0 ;
               :  n_col2 = n_col ;
               :  n_row2 = n_row ;
               :
               :  /* === Kill empty columns =============================================== */
               :
               :  /* Put the empty columns at the end in their natural order, so that LU */
               :  /* factorization can proceed as far as possible. */
               :  for (c = n_col-1 ; c >= 0 ; c--)
               :  {
               :    deg = Col [c].length ;
               :    if (deg == 0)
               :    {
               :      /* this is a empty column, kill and order it last */
               :      Col [c].shared2.order = --n_col2 ;
               :      KILL_PRINCIPAL_COL (c) ;
               :    }
               :  }
               :  COLAMD_DEBUG1 (("colamd: null columns killed: %d\n", n_col - n_col2)) ;
               :
               :  /* === Kill dense columns =============================================== */
               :
               :  /* Put the dense columns at the end, in their natural order */
               :  for (c = n_col-1 ; c >= 0 ; c--)
               :  {
               :    /* skip any dead columns */
               :    if (COL_IS_DEAD (c))
               :    {
               :      continue ;
               :    }
               :    deg = Col [c].length ;
               :    if (deg > dense_col_count)
               :    {
               :      /* this is a dense column, kill and order it last */
               :      Col [c].shared2.order = --n_col2 ;
               :      /* decrement the row degrees */
               :      cp = &A [Col [c].start] ;
               :      cp_end = cp + Col [c].length ;
               :      while (cp < cp_end)
               :      {
               :	Row [*cp++].shared1.degree-- ;
               :      }
               :      KILL_PRINCIPAL_COL (c) ;
               :    }
               :  }
               :  COLAMD_DEBUG1 (("colamd: Dense and null columns killed: %d\n", n_col - n_col2)) ;
               :
               :  /* === Kill dense and empty rows ======================================== */
               :
               :  for (r = 0 ; r < n_row ; r++)
               :  {
               :    deg = Row [r].shared1.degree ;
               :    COLAMD_ASSERT (deg >= 0 && deg <= n_col) ;
               :    if (deg > dense_row_count || deg == 0)
               :    {
               :      /* kill a dense or empty row */
               :      KILL_ROW (r) ;
               :      --n_row2 ;
               :    }
               :    else
               :    {
               :      /* keep track of max degree of remaining rows */
               :      max_deg = COLAMD_MAX (max_deg, deg) ;
               :    }
               :  }
               :  COLAMD_DEBUG1 (("colamd: Dense and null rows killed: %d\n", n_row - n_row2)) ;
               :
               :  /* === Compute initial column scores ==================================== */
               :
               :  /* At this point the row degrees are accurate.  They reflect the number */
               :  /* of "live" (non-dense) columns in each row.  No empty rows exist. */
               :  /* Some "live" columns may contain only dead rows, however.  These are */
               :  /* pruned in the code below. */
               :
               :  /* now find the initial matlab score for each column */
               :  for (c = n_col-1 ; c >= 0 ; c--)
               :  {
               :    /* skip dead column */
               :    if (COL_IS_DEAD (c))
               :    {
               :      continue ;
               :    }
               :    score = 0 ;
               :    cp = &A [Col [c].start] ;
               :    new_cp = cp ;
               :    cp_end = cp + Col [c].length ;
               :    while (cp < cp_end)
               :    {
               :      /* get a row */
               :      row = *cp++ ;
               :      /* skip if dead */
               :      if (ROW_IS_DEAD (row))
               :      {
               :	continue ;
               :      }
               :      /* compact the column */
               :      *new_cp++ = row ;
               :      /* add row's external degree */
               :      score += Row [row].shared1.degree - 1 ;
               :      /* guard against integer overflow */
               :      score = COLAMD_MIN (score, n_col) ;
               :    }
               :    /* determine pruned column length */
               :    col_length = (Index) (new_cp - &A [Col [c].start]) ;
               :    if (col_length == 0)
               :    {
               :      /* a newly-made null column (all rows in this col are "dense" */
               :      /* and have already been killed) */
               :      COLAMD_DEBUG2 (("Newly null killed: %d\n", c)) ;
               :      Col [c].shared2.order = --n_col2 ;
               :      KILL_PRINCIPAL_COL (c) ;
               :    }
               :    else
               :    {
               :      /* set column length and set score */
               :      COLAMD_ASSERT (score >= 0) ;
               :      COLAMD_ASSERT (score <= n_col) ;
               :      Col [c].length = col_length ;
               :      Col [c].shared2.score = score ;
               :    }
               :  }
               :  COLAMD_DEBUG1 (("colamd: Dense, null, and newly-null columns killed: %d\n",
               :		  n_col-n_col2)) ;
               :
               :  /* At this point, all empty rows and columns are dead.  All live columns */
               :  /* are "clean" (containing no dead rows) and simplicial (no supercolumns */
               :  /* yet).  Rows may contain dead columns, but all live rows contain at */
               :  /* least one live column. */
               :
               :  /* === Initialize degree lists ========================================== */
               :
               :
               :  /* clear the hash buckets */
               :  for (c = 0 ; c <= n_col ; c++)
               :  {
               :    head [c] = COLAMD_EMPTY ;
               :  }
               :  min_score = n_col ;
               :  /* place in reverse order, so low column indices are at the front */
               :  /* of the lists.  This is to encourage natural tie-breaking */
               :  for (c = n_col-1 ; c >= 0 ; c--)
               :  {
               :    /* only add principal columns to degree lists */
               :    if (COL_IS_ALIVE (c))
               :    {
               :      COLAMD_DEBUG4 (("place %d score %d minscore %d ncol %d\n",
               :		      c, Col [c].shared2.score, min_score, n_col)) ;
               :
               :      /* === Add columns score to DList =============================== */
               :
               :      score = Col [c].shared2.score ;
               :
               :      COLAMD_ASSERT (min_score >= 0) ;
               :      COLAMD_ASSERT (min_score <= n_col) ;
               :      COLAMD_ASSERT (score >= 0) ;
               :      COLAMD_ASSERT (score <= n_col) ;
               :      COLAMD_ASSERT (head [score] >= COLAMD_EMPTY) ;
               :
               :      /* now add this column to dList at proper score location */
               :      next_col = head [score] ;
               :      Col [c].shared3.prev = COLAMD_EMPTY ;
               :      Col [c].shared4.degree_next = next_col ;
               :
               :      /* if there already was a column with the same score, set its */
               :      /* previous pointer to this new column */
               :      if (next_col != COLAMD_EMPTY)
               :      {
               :	Col [next_col].shared3.prev = c ;
               :      }
               :      head [score] = c ;
               :
               :      /* see if this score is less than current min */
               :      min_score = COLAMD_MIN (min_score, score) ;
               :
               :
               :    }
               :  }
               :
               :
               :  /* === Return number of remaining columns, and max row degree =========== */
               :
               :  *p_n_col2 = n_col2 ;
               :  *p_n_row2 = n_row2 ;
               :  *p_max_deg = max_deg ;
               :}
               :
               :
               :/* ========================================================================== */
               :/* === find_ordering ======================================================== */
               :/* ========================================================================== */
               :
               :/*
               :  Order the principal columns of the supercolumn form of the matrix
               :  (no supercolumns on input).  Uses a minimum approximate column minimum
               :  degree ordering method.  Not user-callable.
               :*/
               :template <typename Index>
               :static Index find_ordering /* return the number of garbage collections */
               :  (
               :    /* === Parameters ======================================================= */
               :
               :    Index n_row,      /* number of rows of A */
               :    Index n_col,      /* number of columns of A */
               :    Index Alen,     /* size of A, 2*nnz + n_col or larger */
               :    Colamd_Row<Index> Row [],    /* of size n_row+1 */
               :    colamd_col<Index> Col [],    /* of size n_col+1 */
               :    Index A [],     /* column form and row form of A */
               :    Index head [],    /* of size n_col+1 */
               :    Index n_col2,     /* Remaining columns to order */
               :    Index max_deg,    /* Maximum row degree */
               :    Index pfree     /* index of first free slot (2*nnz on entry) */
               :    )
               :{
               :  /* === Local variables ================================================== */
               :
               :  Index k ;     /* current pivot ordering step */
               :  Index pivot_col ;   /* current pivot column */
               :  Index *cp ;     /* a column pointer */
               :  Index *rp ;     /* a row pointer */
               :  Index pivot_row ;   /* current pivot row */
               :  Index *new_cp ;   /* modified column pointer */
               :  Index *new_rp ;   /* modified row pointer */
               :  Index pivot_row_start ; /* pointer to start of pivot row */
               :  Index pivot_row_degree ;  /* number of columns in pivot row */
               :  Index pivot_row_length ;  /* number of supercolumns in pivot row */
               :  Index pivot_col_score ; /* score of pivot column */
               :  Index needed_memory ;   /* free space needed for pivot row */
               :  Index *cp_end ;   /* pointer to the end of a column */
               :  Index *rp_end ;   /* pointer to the end of a row */
               :  Index row ;     /* a row index */
               :  Index col ;     /* a column index */
               :  Index max_score ;   /* maximum possible score */
               :  Index cur_score ;   /* score of current column */
               :  unsigned int hash ;   /* hash value for supernode detection */
               :  Index head_column ;   /* head of hash bucket */
               :  Index first_col ;   /* first column in hash bucket */
               :  Index tag_mark ;    /* marker value for mark array */
               :  Index row_mark ;    /* Row [row].shared2.mark */
               :  Index set_difference ;  /* set difference size of row with pivot row */
               :  Index min_score ;   /* smallest column score */
               :  Index col_thickness ;   /* "thickness" (no. of columns in a supercol) */
               :  Index max_mark ;    /* maximum value of tag_mark */
               :  Index pivot_col_thickness ; /* number of columns represented by pivot col */
               :  Index prev_col ;    /* Used by Dlist operations. */
               :  Index next_col ;    /* Used by Dlist operations. */
               :  Index ngarbage ;    /* number of garbage collections performed */
               :
               :
               :  /* === Initialization and clear mark ==================================== */
               :
               :  max_mark = INT_MAX - n_col ;  /* INT_MAX defined in <limits.h> */
               :  tag_mark = Eigen::internal::clear_mark (n_row, Row) ;
               :  min_score = 0 ;
               :  ngarbage = 0 ;
               :  COLAMD_DEBUG1 (("colamd: Ordering, n_col2=%d\n", n_col2)) ;
               :
               :  /* === Order the columns ================================================ */
               :
               :  for (k = 0 ; k < n_col2 ; /* 'k' is incremented below */)
               :  {
               :
               :    /* === Select pivot column, and order it ============================ */
               :
               :    /* make sure degree list isn't empty */
               :    COLAMD_ASSERT (min_score >= 0) ;
               :    COLAMD_ASSERT (min_score <= n_col) ;
               :    COLAMD_ASSERT (head [min_score] >= COLAMD_EMPTY) ;
               :
               :    /* get pivot column from head of minimum degree list */
               :    while (head [min_score] == COLAMD_EMPTY && min_score < n_col)
               :    {
               :      min_score++ ;
               :    }
               :    pivot_col = head [min_score] ;
               :    COLAMD_ASSERT (pivot_col >= 0 && pivot_col <= n_col) ;
               :    next_col = Col [pivot_col].shared4.degree_next ;
               :    head [min_score] = next_col ;
               :    if (next_col != COLAMD_EMPTY)
               :    {
               :      Col [next_col].shared3.prev = COLAMD_EMPTY ;
               :    }
               :
               :    COLAMD_ASSERT (COL_IS_ALIVE (pivot_col)) ;
               :    COLAMD_DEBUG3 (("Pivot col: %d\n", pivot_col)) ;
               :
               :    /* remember score for defrag check */
               :    pivot_col_score = Col [pivot_col].shared2.score ;
               :
               :    /* the pivot column is the kth column in the pivot order */
               :    Col [pivot_col].shared2.order = k ;
               :
               :    /* increment order count by column thickness */
               :    pivot_col_thickness = Col [pivot_col].shared1.thickness ;
               :    k += pivot_col_thickness ;
               :    COLAMD_ASSERT (pivot_col_thickness > 0) ;
               :
               :    /* === Garbage_collection, if necessary ============================= */
               :
               :    needed_memory = COLAMD_MIN (pivot_col_score, n_col - k) ;
               :    if (pfree + needed_memory >= Alen)
               :    {
               :      pfree = Eigen::internal::garbage_collection (n_row, n_col, Row, Col, A, &A [pfree]) ;
               :      ngarbage++ ;
               :      /* after garbage collection we will have enough */
               :      COLAMD_ASSERT (pfree + needed_memory < Alen) ;
               :      /* garbage collection has wiped out the Row[].shared2.mark array */
               :      tag_mark = Eigen::internal::clear_mark (n_row, Row) ;
               :
               :    }
               :
               :    /* === Compute pivot row pattern ==================================== */
               :
               :    /* get starting location for this new merged row */
               :    pivot_row_start = pfree ;
               :
               :    /* initialize new row counts to zero */
               :    pivot_row_degree = 0 ;
               :
               :    /* tag pivot column as having been visited so it isn't included */
               :    /* in merged pivot row */
               :    Col [pivot_col].shared1.thickness = -pivot_col_thickness ;
               :
               :    /* pivot row is the union of all rows in the pivot column pattern */
               :    cp = &A [Col [pivot_col].start] ;
               :    cp_end = cp + Col [pivot_col].length ;
               :    while (cp < cp_end)
               :    {
               :      /* get a row */
               :      row = *cp++ ;
               :      COLAMD_DEBUG4 (("Pivot col pattern %d %d\n", ROW_IS_ALIVE (row), row)) ;
               :      /* skip if row is dead */
               :      if (ROW_IS_DEAD (row))
               :      {
               :	continue ;
               :      }
               :      rp = &A [Row [row].start] ;
               :      rp_end = rp + Row [row].length ;
               :      while (rp < rp_end)
               :      {
               :	/* get a column */
               :	col = *rp++ ;
               :	/* add the column, if alive and untagged */
               :	col_thickness = Col [col].shared1.thickness ;
               :	if (col_thickness > 0 && COL_IS_ALIVE (col))
               :	{
               :	  /* tag column in pivot row */
               :	  Col [col].shared1.thickness = -col_thickness ;
               :	  COLAMD_ASSERT (pfree < Alen) ;
               :	  /* place column in pivot row */
               :	  A [pfree++] = col ;
               :	  pivot_row_degree += col_thickness ;
               :	}
               :      }
               :    }
               :
               :    /* clear tag on pivot column */
               :    Col [pivot_col].shared1.thickness = pivot_col_thickness ;
               :    max_deg = COLAMD_MAX (max_deg, pivot_row_degree) ;
               :
               :
               :    /* === Kill all rows used to construct pivot row ==================== */
               :
               :    /* also kill pivot row, temporarily */
               :    cp = &A [Col [pivot_col].start] ;
               :    cp_end = cp + Col [pivot_col].length ;
               :    while (cp < cp_end)
               :    {
               :      /* may be killing an already dead row */
               :      row = *cp++ ;
               :      COLAMD_DEBUG3 (("Kill row in pivot col: %d\n", row)) ;
               :      KILL_ROW (row) ;
               :    }
               :
               :    /* === Select a row index to use as the new pivot row =============== */
               :
               :    pivot_row_length = pfree - pivot_row_start ;
               :    if (pivot_row_length > 0)
               :    {
               :      /* pick the "pivot" row arbitrarily (first row in col) */
               :      pivot_row = A [Col [pivot_col].start] ;
               :      COLAMD_DEBUG3 (("Pivotal row is %d\n", pivot_row)) ;
               :    }
               :    else
               :    {
               :      /* there is no pivot row, since it is of zero length */
               :      pivot_row = COLAMD_EMPTY ;
               :      COLAMD_ASSERT (pivot_row_length == 0) ;
               :    }
               :    COLAMD_ASSERT (Col [pivot_col].length > 0 || pivot_row_length == 0) ;
               :
               :    /* === Approximate degree computation =============================== */
               :
               :    /* Here begins the computation of the approximate degree.  The column */
               :    /* score is the sum of the pivot row "length", plus the size of the */
               :    /* set differences of each row in the column minus the pattern of the */
               :    /* pivot row itself.  The column ("thickness") itself is also */
               :    /* excluded from the column score (we thus use an approximate */
               :    /* external degree). */
               :
               :    /* The time taken by the following code (compute set differences, and */
               :    /* add them up) is proportional to the size of the data structure */
               :    /* being scanned - that is, the sum of the sizes of each column in */
               :    /* the pivot row.  Thus, the amortized time to compute a column score */
               :    /* is proportional to the size of that column (where size, in this */
               :    /* context, is the column "length", or the number of row indices */
               :    /* in that column).  The number of row indices in a column is */
               :    /* monotonically non-decreasing, from the length of the original */
               :    /* column on input to colamd. */
               :
               :    /* === Compute set differences ====================================== */
               :
               :    COLAMD_DEBUG3 (("** Computing set differences phase. **\n")) ;
               :
               :    /* pivot row is currently dead - it will be revived later. */
               :
               :    COLAMD_DEBUG3 (("Pivot row: ")) ;
               :    /* for each column in pivot row */
               :    rp = &A [pivot_row_start] ;
               :    rp_end = rp + pivot_row_length ;
               :    while (rp < rp_end)
               :    {
               :      col = *rp++ ;
               :      COLAMD_ASSERT (COL_IS_ALIVE (col) && col != pivot_col) ;
               :      COLAMD_DEBUG3 (("Col: %d\n", col)) ;
               :
               :      /* clear tags used to construct pivot row pattern */
               :      col_thickness = -Col [col].shared1.thickness ;
               :      COLAMD_ASSERT (col_thickness > 0) ;
               :      Col [col].shared1.thickness = col_thickness ;
               :
               :      /* === Remove column from degree list =========================== */
               :
               :      cur_score = Col [col].shared2.score ;
               :      prev_col = Col [col].shared3.prev ;
               :      next_col = Col [col].shared4.degree_next ;
               :      COLAMD_ASSERT (cur_score >= 0) ;
               :      COLAMD_ASSERT (cur_score <= n_col) ;
               :      COLAMD_ASSERT (cur_score >= COLAMD_EMPTY) ;
               :      if (prev_col == COLAMD_EMPTY)
               :      {
               :	head [cur_score] = next_col ;
               :      }
               :      else
               :      {
               :	Col [prev_col].shared4.degree_next = next_col ;
               :      }
               :      if (next_col != COLAMD_EMPTY)
               :      {
               :	Col [next_col].shared3.prev = prev_col ;
               :      }
               :
               :      /* === Scan the column ========================================== */
               :
               :      cp = &A [Col [col].start] ;
               :      cp_end = cp + Col [col].length ;
               :      while (cp < cp_end)
               :      {
               :	/* get a row */
               :	row = *cp++ ;
               :	row_mark = Row [row].shared2.mark ;
               :	/* skip if dead */
               :	if (ROW_IS_MARKED_DEAD (row_mark))
               :	{
               :	  continue ;
               :	}
               :	COLAMD_ASSERT (row != pivot_row) ;
               :	set_difference = row_mark - tag_mark ;
               :	/* check if the row has been seen yet */
               :	if (set_difference < 0)
               :	{
               :	  COLAMD_ASSERT (Row [row].shared1.degree <= max_deg) ;
               :	  set_difference = Row [row].shared1.degree ;
               :	}
               :	/* subtract column thickness from this row's set difference */
               :	set_difference -= col_thickness ;
               :	COLAMD_ASSERT (set_difference >= 0) ;
               :	/* absorb this row if the set difference becomes zero */
               :	if (set_difference == 0)
               :	{
               :	  COLAMD_DEBUG3 (("aggressive absorption. Row: %d\n", row)) ;
               :	  KILL_ROW (row) ;
               :	}
               :	else
               :	{
               :	  /* save the new mark */
               :	  Row [row].shared2.mark = set_difference + tag_mark ;
               :	}
               :      }
               :    }
               :
               :
               :    /* === Add up set differences for each column ======================= */
               :
               :    COLAMD_DEBUG3 (("** Adding set differences phase. **\n")) ;
               :
               :    /* for each column in pivot row */
               :    rp = &A [pivot_row_start] ;
               :    rp_end = rp + pivot_row_length ;
               :    while (rp < rp_end)
               :    {
               :      /* get a column */
               :      col = *rp++ ;
               :      COLAMD_ASSERT (COL_IS_ALIVE (col) && col != pivot_col) ;
               :      hash = 0 ;
               :      cur_score = 0 ;
               :      cp = &A [Col [col].start] ;
               :      /* compact the column */
               :      new_cp = cp ;
               :      cp_end = cp + Col [col].length ;
               :
               :      COLAMD_DEBUG4 (("Adding set diffs for Col: %d.\n", col)) ;
               :
               :      while (cp < cp_end)
               :      {
               :	/* get a row */
               :	row = *cp++ ;
               :	COLAMD_ASSERT(row >= 0 && row < n_row) ;
               :	row_mark = Row [row].shared2.mark ;
               :	/* skip if dead */
               :	if (ROW_IS_MARKED_DEAD (row_mark))
               :	{
               :	  continue ;
               :	}
               :	COLAMD_ASSERT (row_mark > tag_mark) ;
               :	/* compact the column */
               :	*new_cp++ = row ;
               :	/* compute hash function */
               :	hash += row ;
               :	/* add set difference */
               :	cur_score += row_mark - tag_mark ;
               :	/* integer overflow... */
               :	cur_score = COLAMD_MIN (cur_score, n_col) ;
               :      }
               :
               :      /* recompute the column's length */
               :      Col [col].length = (Index) (new_cp - &A [Col [col].start]) ;
               :
               :      /* === Further mass elimination ================================= */
               :
               :      if (Col [col].length == 0)
               :      {
               :	COLAMD_DEBUG4 (("further mass elimination. Col: %d\n", col)) ;
               :	/* nothing left but the pivot row in this column */
               :	KILL_PRINCIPAL_COL (col) ;
               :	pivot_row_degree -= Col [col].shared1.thickness ;
               :	COLAMD_ASSERT (pivot_row_degree >= 0) ;
               :	/* order it */
               :	Col [col].shared2.order = k ;
               :	/* increment order count by column thickness */
               :	k += Col [col].shared1.thickness ;
               :      }
               :      else
               :      {
               :	/* === Prepare for supercolumn detection ==================== */
               :
               :	COLAMD_DEBUG4 (("Preparing supercol detection for Col: %d.\n", col)) ;
               :
               :	/* save score so far */
               :	Col [col].shared2.score = cur_score ;
               :
               :	/* add column to hash table, for supercolumn detection */
               :	hash %= n_col + 1 ;
               :
               :	COLAMD_DEBUG4 ((" Hash = %d, n_col = %d.\n", hash, n_col)) ;
               :	COLAMD_ASSERT (hash <= n_col) ;
               :
               :	head_column = head [hash] ;
               :	if (head_column > COLAMD_EMPTY)
               :	{
               :	  /* degree list "hash" is non-empty, use prev (shared3) of */
               :	  /* first column in degree list as head of hash bucket */
               :	  first_col = Col [head_column].shared3.headhash ;
               :	  Col [head_column].shared3.headhash = col ;
               :	}
               :	else
               :	{
               :	  /* degree list "hash" is empty, use head as hash bucket */
               :	  first_col = - (head_column + 2) ;
               :	  head [hash] = - (col + 2) ;
               :	}
               :	Col [col].shared4.hash_next = first_col ;
               :
               :	/* save hash function in Col [col].shared3.hash */
               :	Col [col].shared3.hash = (Index) hash ;
               :	COLAMD_ASSERT (COL_IS_ALIVE (col)) ;
               :      }
               :    }
               :
               :    /* The approximate external column degree is now computed.  */
               :
               :    /* === Supercolumn detection ======================================== */
               :
               :    COLAMD_DEBUG3 (("** Supercolumn detection phase. **\n")) ;
               :
               :    Eigen::internal::detect_super_cols (Col, A, head, pivot_row_start, pivot_row_length) ;
               :
               :    /* === Kill the pivotal column ====================================== */
               :
               :    KILL_PRINCIPAL_COL (pivot_col) ;
               :
               :    /* === Clear mark =================================================== */
               :
               :    tag_mark += (max_deg + 1) ;
               :    if (tag_mark >= max_mark)
               :    {
               :      COLAMD_DEBUG2 (("clearing tag_mark\n")) ;
               :      tag_mark = Eigen::internal::clear_mark (n_row, Row) ;
               :    }
               :
               :    /* === Finalize the new pivot row, and column scores ================ */
               :
               :    COLAMD_DEBUG3 (("** Finalize scores phase. **\n")) ;
               :
               :    /* for each column in pivot row */
               :    rp = &A [pivot_row_start] ;
               :    /* compact the pivot row */
               :    new_rp = rp ;
               :    rp_end = rp + pivot_row_length ;
               :    while (rp < rp_end)
               :    {
               :      col = *rp++ ;
               :      /* skip dead columns */
               :      if (COL_IS_DEAD (col))
               :      {
               :	continue ;
               :      }
               :      *new_rp++ = col ;
               :      /* add new pivot row to column */
               :      A [Col [col].start + (Col [col].length++)] = pivot_row ;
               :
               :      /* retrieve score so far and add on pivot row's degree. */
               :      /* (we wait until here for this in case the pivot */
               :      /* row's degree was reduced due to mass elimination). */
               :      cur_score = Col [col].shared2.score + pivot_row_degree ;
               :
               :      /* calculate the max possible score as the number of */
               :      /* external columns minus the 'k' value minus the */
               :      /* columns thickness */
               :      max_score = n_col - k - Col [col].shared1.thickness ;
               :
               :      /* make the score the external degree of the union-of-rows */
               :      cur_score -= Col [col].shared1.thickness ;
               :
               :      /* make sure score is less or equal than the max score */
               :      cur_score = COLAMD_MIN (cur_score, max_score) ;
               :      COLAMD_ASSERT (cur_score >= 0) ;
               :
               :      /* store updated score */
               :      Col [col].shared2.score = cur_score ;
               :
               :      /* === Place column back in degree list ========================= */
               :
               :      COLAMD_ASSERT (min_score >= 0) ;
               :      COLAMD_ASSERT (min_score <= n_col) ;
               :      COLAMD_ASSERT (cur_score >= 0) ;
               :      COLAMD_ASSERT (cur_score <= n_col) ;
               :      COLAMD_ASSERT (head [cur_score] >= COLAMD_EMPTY) ;
               :      next_col = head [cur_score] ;
               :      Col [col].shared4.degree_next = next_col ;
               :      Col [col].shared3.prev = COLAMD_EMPTY ;
               :      if (next_col != COLAMD_EMPTY)
               :      {
               :	Col [next_col].shared3.prev = col ;
               :      }
               :      head [cur_score] = col ;
               :
               :      /* see if this score is less than current min */
               :      min_score = COLAMD_MIN (min_score, cur_score) ;
               :
               :    }
               :
               :    /* === Resurrect the new pivot row ================================== */
               :
               :    if (pivot_row_degree > 0)
               :    {
               :      /* update pivot row length to reflect any cols that were killed */
               :      /* during super-col detection and mass elimination */
               :      Row [pivot_row].start  = pivot_row_start ;
               :      Row [pivot_row].length = (Index) (new_rp - &A[pivot_row_start]) ;
               :      Row [pivot_row].shared1.degree = pivot_row_degree ;
               :      Row [pivot_row].shared2.mark = 0 ;
               :      /* pivot row is no longer dead */
               :    }
               :  }
               :
               :  /* === All principal columns have now been ordered ====================== */
               :
               :  return (ngarbage) ;
               :}
               :
               :
               :/* ========================================================================== */
               :/* === order_children ======================================================= */
               :/* ========================================================================== */
               :
               :/*
               :  The find_ordering routine has ordered all of the principal columns (the
               :  representatives of the supercolumns).  The non-principal columns have not
               :  yet been ordered.  This routine orders those columns by walking up the
               :  parent tree (a column is a child of the column which absorbed it).  The
               :  final permutation vector is then placed in p [0 ... n_col-1], with p [0]
               :  being the first column, and p [n_col-1] being the last.  It doesn't look
               :  like it at first glance, but be assured that this routine takes time linear
               :  in the number of columns.  Although not immediately obvious, the time
               :  taken by this routine is O (n_col), that is, linear in the number of
               :  columns.  Not user-callable.
               :*/
               :template <typename Index>
               :static inline  void order_children
               :(
               :  /* === Parameters ======================================================= */
               :
               :  Index n_col,      /* number of columns of A */
               :  colamd_col<Index> Col [],    /* of size n_col+1 */
               :  Index p []      /* p [0 ... n_col-1] is the column permutation*/
               :  )
               :{
               :  /* === Local variables ================================================== */
               :
               :  Index i ;     /* loop counter for all columns */
               :  Index c ;     /* column index */
               :  Index parent ;    /* index of column's parent */
               :  Index order ;     /* column's order */
               :
               :  /* === Order each non-principal column ================================== */
               :
               :  for (i = 0 ; i < n_col ; i++)
               :  {
               :    /* find an un-ordered non-principal column */
               :    COLAMD_ASSERT (COL_IS_DEAD (i)) ;
               :    if (!COL_IS_DEAD_PRINCIPAL (i) && Col [i].shared2.order == COLAMD_EMPTY)
               :    {
               :      parent = i ;
               :      /* once found, find its principal parent */
               :      do
               :      {
               :	parent = Col [parent].shared1.parent ;
               :      } while (!COL_IS_DEAD_PRINCIPAL (parent)) ;
               :
               :      /* now, order all un-ordered non-principal columns along path */
               :      /* to this parent.  collapse tree at the same time */
               :      c = i ;
               :      /* get order of parent */
               :      order = Col [parent].shared2.order ;
               :
               :      do
               :      {
               :	COLAMD_ASSERT (Col [c].shared2.order == COLAMD_EMPTY) ;
               :
               :	/* order this column */
               :	Col [c].shared2.order = order++ ;
               :	/* collaps tree */
               :	Col [c].shared1.parent = parent ;
               :
               :	/* get immediate parent of this column */
               :	c = Col [c].shared1.parent ;
               :
               :	/* continue until we hit an ordered column.  There are */
               :	/* guarranteed not to be anymore unordered columns */
               :	/* above an ordered column */
               :      } while (Col [c].shared2.order == COLAMD_EMPTY) ;
               :
               :      /* re-order the super_col parent to largest order for this group */
               :      Col [parent].shared2.order = order ;
               :    }
               :  }
               :
               :  /* === Generate the permutation ========================================= */
               :
               :  for (c = 0 ; c < n_col ; c++)
               :  {
               :    p [Col [c].shared2.order] = c ;
               :  }
               :}
               :
               :
               :/* ========================================================================== */
               :/* === detect_super_cols ==================================================== */
               :/* ========================================================================== */
               :
               :/*
               :  Detects supercolumns by finding matches between columns in the hash buckets.
               :  Check amongst columns in the set A [row_start ... row_start + row_length-1].
               :  The columns under consideration are currently *not* in the degree lists,
               :  and have already been placed in the hash buckets.
               :
               :  The hash bucket for columns whose hash function is equal to h is stored
               :  as follows:
               :
               :  if head [h] is >= 0, then head [h] contains a degree list, so:
               :
               :  head [h] is the first column in degree bucket h.
               :  Col [head [h]].headhash gives the first column in hash bucket h.
               :
               :  otherwise, the degree list is empty, and:
               :
               :  -(head [h] + 2) is the first column in hash bucket h.
               :
               :  For a column c in a hash bucket, Col [c].shared3.prev is NOT a "previous
               :  column" pointer.  Col [c].shared3.hash is used instead as the hash number
               :  for that column.  The value of Col [c].shared4.hash_next is the next column
               :  in the same hash bucket.
               :
               :  Assuming no, or "few" hash collisions, the time taken by this routine is
               :  linear in the sum of the sizes (lengths) of each column whose score has
               :  just been computed in the approximate degree computation.
               :  Not user-callable.
               :*/
               :template <typename Index>
               :static void detect_super_cols
               :(
               :  /* === Parameters ======================================================= */
               :  
               :  colamd_col<Index> Col [],    /* of size n_col+1 */
               :  Index A [],     /* row indices of A */
               :  Index head [],    /* head of degree lists and hash buckets */
               :  Index row_start,    /* pointer to set of columns to check */
               :  Index row_length    /* number of columns to check */
               :)
               :{
               :  /* === Local variables ================================================== */
               :
               :  Index hash ;      /* hash value for a column */
               :  Index *rp ;     /* pointer to a row */
               :  Index c ;     /* a column index */
               :  Index super_c ;   /* column index of the column to absorb into */
               :  Index *cp1 ;      /* column pointer for column super_c */
               :  Index *cp2 ;      /* column pointer for column c */
               :  Index length ;    /* length of column super_c */
               :  Index prev_c ;    /* column preceding c in hash bucket */
               :  Index i ;     /* loop counter */
               :  Index *rp_end ;   /* pointer to the end of the row */
               :  Index col ;     /* a column index in the row to check */
               :  Index head_column ;   /* first column in hash bucket or degree list */
               :  Index first_col ;   /* first column in hash bucket */
               :
               :  /* === Consider each column in the row ================================== */
               :
               :  rp = &A [row_start] ;
               :  rp_end = rp + row_length ;
               :  while (rp < rp_end)
               :  {
               :    col = *rp++ ;
               :    if (COL_IS_DEAD (col))
               :    {
               :      continue ;
               :    }
               :
               :    /* get hash number for this column */
               :    hash = Col [col].shared3.hash ;
               :    COLAMD_ASSERT (hash <= n_col) ;
               :
               :    /* === Get the first column in this hash bucket ===================== */
               :
               :    head_column = head [hash] ;
               :    if (head_column > COLAMD_EMPTY)
               :    {
               :      first_col = Col [head_column].shared3.headhash ;
               :    }
               :    else
               :    {
               :      first_col = - (head_column + 2) ;
               :    }
               :
               :    /* === Consider each column in the hash bucket ====================== */
               :
               :    for (super_c = first_col ; super_c != COLAMD_EMPTY ;
               :	 super_c = Col [super_c].shared4.hash_next)
               :    {
               :      COLAMD_ASSERT (COL_IS_ALIVE (super_c)) ;
               :      COLAMD_ASSERT (Col [super_c].shared3.hash == hash) ;
               :      length = Col [super_c].length ;
               :
               :      /* prev_c is the column preceding column c in the hash bucket */
               :      prev_c = super_c ;
               :
               :      /* === Compare super_c with all columns after it ================ */
               :
               :      for (c = Col [super_c].shared4.hash_next ;
               :	   c != COLAMD_EMPTY ; c = Col [c].shared4.hash_next)
               :      {
               :	COLAMD_ASSERT (c != super_c) ;
               :	COLAMD_ASSERT (COL_IS_ALIVE (c)) ;
               :	COLAMD_ASSERT (Col [c].shared3.hash == hash) ;
               :
               :	/* not identical if lengths or scores are different */
               :	if (Col [c].length != length ||
               :	    Col [c].shared2.score != Col [super_c].shared2.score)
               :	{
               :	  prev_c = c ;
               :	  continue ;
               :	}
               :
               :	/* compare the two columns */
               :	cp1 = &A [Col [super_c].start] ;
               :	cp2 = &A [Col [c].start] ;
               :
               :	for (i = 0 ; i < length ; i++)
               :	{
               :	  /* the columns are "clean" (no dead rows) */
               :	  COLAMD_ASSERT (ROW_IS_ALIVE (*cp1))  ;
               :	  COLAMD_ASSERT (ROW_IS_ALIVE (*cp2))  ;
               :	  /* row indices will same order for both supercols, */
               :	  /* no gather scatter nessasary */
               :	  if (*cp1++ != *cp2++)
               :	  {
               :	    break ;
               :	  }
               :	}
               :
               :	/* the two columns are different if the for-loop "broke" */
               :	if (i != length)
               :	{
               :	  prev_c = c ;
               :	  continue ;
               :	}
               :
               :	/* === Got it!  two columns are identical =================== */
               :
               :	COLAMD_ASSERT (Col [c].shared2.score == Col [super_c].shared2.score) ;
               :
               :	Col [super_c].shared1.thickness += Col [c].shared1.thickness ;
               :	Col [c].shared1.parent = super_c ;
               :	KILL_NON_PRINCIPAL_COL (c) ;
               :	/* order c later, in order_children() */
               :	Col [c].shared2.order = COLAMD_EMPTY ;
               :	/* remove c from hash bucket */
               :	Col [prev_c].shared4.hash_next = Col [c].shared4.hash_next ;
               :      }
               :    }
               :
               :    /* === Empty this hash bucket ======================================= */
               :
               :    if (head_column > COLAMD_EMPTY)
               :    {
               :      /* corresponding degree list "hash" is not empty */
               :      Col [head_column].shared3.headhash = COLAMD_EMPTY ;
               :    }
               :    else
               :    {
               :      /* corresponding degree list "hash" is empty */
               :      head [hash] = COLAMD_EMPTY ;
               :    }
               :  }
               :}
               :
               :
               :/* ========================================================================== */
               :/* === garbage_collection =================================================== */
               :/* ========================================================================== */
               :
               :/*
               :  Defragments and compacts columns and rows in the workspace A.  Used when
               :  all avaliable memory has been used while performing row merging.  Returns
               :  the index of the first free position in A, after garbage collection.  The
               :  time taken by this routine is linear is the size of the array A, which is
               :  itself linear in the number of nonzeros in the input matrix.
               :  Not user-callable.
               :*/
               :template <typename Index>
               :static Index garbage_collection  /* returns the new value of pfree */
               :  (
               :    /* === Parameters ======================================================= */
               :    
               :    Index n_row,      /* number of rows */
               :    Index n_col,      /* number of columns */
               :    Colamd_Row<Index> Row [],    /* row info */
               :    colamd_col<Index> Col [],    /* column info */
               :    Index A [],     /* A [0 ... Alen-1] holds the matrix */
               :    Index *pfree      /* &A [0] ... pfree is in use */
               :    )
               :{
               :  /* === Local variables ================================================== */
               :
               :  Index *psrc ;     /* source pointer */
               :  Index *pdest ;    /* destination pointer */
               :  Index j ;     /* counter */
               :  Index r ;     /* a row index */
               :  Index c ;     /* a column index */
               :  Index length ;    /* length of a row or column */
               :
               :  /* === Defragment the columns =========================================== */
               :
               :  pdest = &A[0] ;
               :  for (c = 0 ; c < n_col ; c++)
               :  {
               :    if (COL_IS_ALIVE (c))
               :    {
               :      psrc = &A [Col [c].start] ;
               :
               :      /* move and compact the column */
               :      COLAMD_ASSERT (pdest <= psrc) ;
               :      Col [c].start = (Index) (pdest - &A [0]) ;
               :      length = Col [c].length ;
               :      for (j = 0 ; j < length ; j++)
               :      {
               :	r = *psrc++ ;
               :	if (ROW_IS_ALIVE (r))
               :	{
               :	  *pdest++ = r ;
               :	}
               :      }
               :      Col [c].length = (Index) (pdest - &A [Col [c].start]) ;
               :    }
               :  }
               :
               :  /* === Prepare to defragment the rows =================================== */
               :
               :  for (r = 0 ; r < n_row ; r++)
               :  {
               :    if (ROW_IS_ALIVE (r))
               :    {
               :      if (Row [r].length == 0)
               :      {
               :	/* this row is of zero length.  cannot compact it, so kill it */
               :	COLAMD_DEBUG3 (("Defrag row kill\n")) ;
               :	KILL_ROW (r) ;
               :      }
               :      else
               :      {
               :	/* save first column index in Row [r].shared2.first_column */
               :	psrc = &A [Row [r].start] ;
               :	Row [r].shared2.first_column = *psrc ;
               :	COLAMD_ASSERT (ROW_IS_ALIVE (r)) ;
               :	/* flag the start of the row with the one's complement of row */
               :	*psrc = ONES_COMPLEMENT (r) ;
               :
               :      }
               :    }
               :  }
               :
               :  /* === Defragment the rows ============================================== */
               :
               :  psrc = pdest ;
               :  while (psrc < pfree)
               :  {
               :    /* find a negative number ... the start of a row */
               :    if (*psrc++ < 0)
               :    {
               :      psrc-- ;
               :      /* get the row index */
               :      r = ONES_COMPLEMENT (*psrc) ;
               :      COLAMD_ASSERT (r >= 0 && r < n_row) ;
               :      /* restore first column index */
               :      *psrc = Row [r].shared2.first_column ;
               :      COLAMD_ASSERT (ROW_IS_ALIVE (r)) ;
               :
               :      /* move and compact the row */
               :      COLAMD_ASSERT (pdest <= psrc) ;
               :      Row [r].start = (Index) (pdest - &A [0]) ;
               :      length = Row [r].length ;
               :      for (j = 0 ; j < length ; j++)
               :      {
               :	c = *psrc++ ;
               :	if (COL_IS_ALIVE (c))
               :	{
               :	  *pdest++ = c ;
               :	}
               :      }
               :      Row [r].length = (Index) (pdest - &A [Row [r].start]) ;
               :
               :    }
               :  }
               :  /* ensure we found all the rows */
               :  COLAMD_ASSERT (debug_rows == 0) ;
               :
               :  /* === Return the new value of pfree ==================================== */
               :
               :  return ((Index) (pdest - &A [0])) ;
               :}
               :
               :
               :/* ========================================================================== */
               :/* === clear_mark =========================================================== */
               :/* ========================================================================== */
               :
               :/*
               :  Clears the Row [].shared2.mark array, and returns the new tag_mark.
               :  Return value is the new tag_mark.  Not user-callable.
               :*/
               :template <typename Index>
               :static inline  Index clear_mark  /* return the new value for tag_mark */
               :  (
               :      /* === Parameters ======================================================= */
               :
               :    Index n_row,    /* number of rows in A */
               :    Colamd_Row<Index> Row [] /* Row [0 ... n_row-1].shared2.mark is set to zero */
               :    )
               :{
               :  /* === Local variables ================================================== */
               :
               :  Index r ;
               :
               :  for (r = 0 ; r < n_row ; r++)
               :  {
               :    if (ROW_IS_ALIVE (r))
               :    {
               :      Row [r].shared2.mark = 0 ;
               :    }
               :  }
               :  return (1) ;
               :}
               :
               :
               :} // namespace internal 
               :#endif
/* 
 * Total samples for file : "/build/buildd/eglibc-2.19/stdio-common/printf_fp.c"
 * 
 *      2  2.7778
 */


 /* __printf_fp total:      1  1.3889 */
 /* hack_digit.13629 total:      1  1.3889 */
/* 
 * Total samples for file : "/usr/include/c++/4.6/ext/new_allocator.h"
 * 
 *      1  1.3889
 */


               :// Allocator that wraps operator new -*- C++ -*-
               :
               :// Copyright (C) 2001, 2002, 2003, 2004, 2005, 2009, 2010
               :// Free Software Foundation, Inc.
               ://
               :// This file is part of the GNU ISO C++ Library.  This library is free
               :// software; you can redistribute it and/or modify it under the
               :// terms of the GNU General Public License as published by the
               :// Free Software Foundation; either version 3, or (at your option)
               :// any later version.
               :
               :// This library is distributed in the hope that it will be useful,
               :// but WITHOUT ANY WARRANTY; without even the implied warranty of
               :// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
               :// GNU General Public License for more details.
               :
               :// Under Section 7 of GPL version 3, you are granted additional
               :// permissions described in the GCC Runtime Library Exception, version
               :// 3.1, as published by the Free Software Foundation.
               :
               :// You should have received a copy of the GNU General Public License and
               :// a copy of the GCC Runtime Library Exception along with this program;
               :// see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
               :// <http://www.gnu.org/licenses/>.
               :
               :/** @file ext/new_allocator.h
               : *  This file is a GNU extension to the Standard C++ Library.
               : */
               :
               :#ifndef _NEW_ALLOCATOR_H
               :#define _NEW_ALLOCATOR_H 1
               :
               :#include <bits/c++config.h>
               :#include <new>
               :#include <bits/functexcept.h>
               :#include <bits/move.h>
               :
               :namespace __gnu_cxx _GLIBCXX_VISIBILITY(default)
               :{
               :_GLIBCXX_BEGIN_NAMESPACE_VERSION
               :
               :  using std::size_t;
               :  using std::ptrdiff_t;
               :
               :  /**
               :   *  @brief  An allocator that uses global new, as per [20.4].
               :   *  @ingroup allocators
               :   *
               :   *  This is precisely the allocator defined in the C++ Standard. 
               :   *    - all allocation calls operator new
               :   *    - all deallocation calls operator delete
               :   */
               :  template<typename _Tp>
               :    class new_allocator
               :    {
               :    public:
               :      typedef size_t     size_type;
               :      typedef ptrdiff_t  difference_type;
               :      typedef _Tp*       pointer;
               :      typedef const _Tp* const_pointer;
               :      typedef _Tp&       reference;
               :      typedef const _Tp& const_reference;
               :      typedef _Tp        value_type;
               :
               :      template<typename _Tp1>
               :        struct rebind
               :        { typedef new_allocator<_Tp1> other; };
               :
               :      new_allocator() throw() { }
               :
               :      new_allocator(const new_allocator&) throw() { }
               :
               :      template<typename _Tp1>
               :        new_allocator(const new_allocator<_Tp1>&) throw() { }
               :
               :      ~new_allocator() throw() { }
               :
               :      pointer
               :      address(reference __x) const { return std::__addressof(__x); }
               :
               :      const_pointer
               :      address(const_reference __x) const { return std::__addressof(__x); }
               :
               :      // NB: __n is permitted to be 0.  The C++ standard says nothing
               :      // about what the return value is when __n == 0.
               :      pointer
               :      allocate(size_type __n, const void* = 0)
               :      { 
               :	if (__n > this->max_size())
               :	  std::__throw_bad_alloc();
               :
               :	return static_cast<_Tp*>(::operator new(__n * sizeof(_Tp)));
               :      }
               :
               :      // __p is not permitted to be a null pointer.
               :      void
               :      deallocate(pointer __p, size_type)
               :      { ::operator delete(__p); }
               :
               :      size_type
               :      max_size() const throw() 
               :      { return size_t(-1) / sizeof(_Tp); }
               :
               :      // _GLIBCXX_RESOLVE_LIB_DEFECTS
               :      // 402. wrong new expression in [some_] allocator::construct
               :      void 
               :      construct(pointer __p, const _Tp& __val) 
               :      { ::new((void *)__p) _Tp(__val); }
               :
               :#ifdef __GXX_EXPERIMENTAL_CXX0X__
               :      template<typename... _Args>
               :        void
               :        construct(pointer __p, _Args&&... __args)
     1  1.3889 :	{ ::new((void *)__p) _Tp(std::forward<_Args>(__args)...); }
               :#endif
               :
               :      void 
               :      destroy(pointer __p) { __p->~_Tp(); }
               :    };
               :
               :  template<typename _Tp>
               :    inline bool
               :    operator==(const new_allocator<_Tp>&, const new_allocator<_Tp>&)
               :    { return true; }
               :  
               :  template<typename _Tp>
               :    inline bool
               :    operator!=(const new_allocator<_Tp>&, const new_allocator<_Tp>&)
               :    { return false; }
               :
               :_GLIBCXX_END_NAMESPACE_VERSION
               :} // namespace
               :
               :#endif
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/mesh_objects.hpp"
 * 
 *      1  1.3889
 */


               :#ifndef __MESH_OBJECTS_HPP__
               :#define __MESH_OBJECTS_HPP__
               :
               :
               :#include "RPDE.hpp"
               :
               ://Accord the NotValid meaning value
               ://const UInt NVAL=std::numeric_limits<UInt>::max();
               :
               :typedef UInt Id;
               :typedef UInt BcId;
               :
               ://!  This class gives some common methods to all mesh objects.
               :class Identifier{
               :public:
               :	
               :	//! An static const Unisgned Integer.
               :    /*! Needed to identify the Not Valid Id. */
               :	static const UInt NVAL;
               :	//Identifier():id_(NVAL),bcId_(NVAL){}
               :	Identifier(UInt id):id_(id),bcId_(NVAL){}
               :	Identifier(UInt id, UInt bcId):id_(id),bcId_(bcId){}
               :	
               :	bool unassignedId()const {return id_==NVAL;}
               :	bool unassignedBc()const {return bcId_==NVAL;}
               :	
               :	Id id() const {return id_;}
               :	BcId bcId() const {return bcId_;}
               :	Id getId() const {return id_;}
               :	
               :	
               :	protected:
               :	Id id_;
               :	BcId bcId_;
               :};
               :
               :
               ://!  This class implements a 2D point
               :class Point: public Identifier{
               :public:
               :	
               :	static const UInt ndim = 2;
               :
               :	Point(): Identifier(NVAL, NVAL){coord_.resize(2);};
               :	Point(Real x, Real y):Identifier(NVAL, NVAL)
               :		{coord_.resize(2);coord_[0]=x; coord_[1]=y;}
               :	Point(Id id, BcId bcId, Real x, Real y):Identifier(id, bcId)
               :		{coord_.resize(2);coord_[0]=x; coord_[1]=y;}
               :	void print(std::ostream & out) const;
               :	Real operator[](UInt i) const {return coord_[i];}
               :private:
               :	std::vector<Real> coord_;
               :	//std::array<Real, 2> coord_;
               :};
               :
               :
               ://!  This class implements an Edge, as an objects composed by two 2D points.
               :class Edge: public Identifier{
               :  public:
               :    static const UInt NNODES=2;
               :    static const UInt numSides=1;
               :    static const UInt myDim=1;
               :    
               :    Edge():Identifier(NVAL, NVAL){points_.resize(2);};
               :    Edge(Id id, BcId bcId, const Point& start,const Point& end):Identifier(id, bcId)
               :    {points_.resize(2); points_[0] = start; points_[1] = end;}
               :    
               :    void print(std::ostream & out) const;
               :    Point getFirst() const {return points_[0];}
               :    Point getEnd() const {return points_[1];}
               :    
               :    
               :    Point operator[](UInt i) const {return points_[i];}
               :   
               : private:
               :	// I don't store directly a eigen matrix because of the limitations
               :	// of the current problems of alignement (see eigen 3.0 documentation)
               :	// It is not very efficient and should be changed asap
               :    //std::array<Point, NNODES> points_;
               :    std::vector<Point> points_;
               :    //std::array<std::reference_wrapper<Point>, NNODES> M_points;
               :  };
               :  
               ://!  This class implements a Triangle as an objects composed by three or six nodes.
               :/*!
               : *  The first three nodes represent the vertices, the others the internal nodes,
               : *  following this enumeration: !IMPORTANT! different from Sangalli code!
               : * 
               : * 				3
               : * 				*
               : * 			 /	   \
               : * 		  5 *		* 4 
               : * 		  /			  \
               : * 		 *______*______*		
               : * 		1		6		2
               :*/
               :
               :template <UInt NNODES>
               :class Triangle : public Identifier {
               :public:
               :    static const UInt numVertices=3;
               :    static const UInt numSides=3;
               :	static const UInt myDim=2;
               :    
               :    //! This constructor creates an "empty" Triangle, with an Id Not Valid
     1  1.3889 :	Triangle():Identifier(NVAL){points_.resize(NNODES);}
               :	
               :	//! This constructor creates a Triangle, given its Id and an std array with the three object Point the will define the Triangle
               :    Triangle(Id id, const std::vector<Point> points) : Identifier(id)
               :	{ this->init(points); }
               :	
               :	//! Overloading of the operator [],  taking the Node number and returning a node as Point object.
               :    /*!
               :     * For node numbering convention see: 
               :      \param i an integer argument.
               :      \return the Point object
               :    */
               :	Point operator[](UInt i) const {return points_[i];}
               :	
               :	//! A member that computes the barycentric coordinates.
               :    /*!
               :      \param point a Point object
               :      \return The three baricentric coordinates of the point
               :    */
               :
               :	Real getDetJ() const {return detJ_;}
               :	Eigen::Matrix<Real,2,2> getM_J() const {return M_J_;}
               :	Eigen::Matrix<Real,2,2> getM_invJ() const {return M_invJ_;}
               :	Eigen::Matrix<Real,2,2> getMetric() const {return metric_;}
               :	//! A member returning the area of the finite element
               :	    /*!
               :	      \return a Real value representing the area of the triangle from which we updated the element
               :	      \sa  updateElement(Triangle<Integrator::NNODES> t)
               :	    */
               :	Real getArea() const {return (0.5 * detJ_);}
               :
               :	Eigen::Matrix<Real,3,1> getBaryCoordinates(const Point& point) const;
               :	
               :	//! A member that tests if a Point is located inside a Triangle.
               :    /*!
               :      \param point a Point object.
               :      \return True if the point is inside the triangle
               :    */
               :	bool isPointInside(const Point& point) const;
               :	
               :	//! A memeber that verifies which edge separates the Triangle from a Point.
               :    /*!
               :      \param point a Point object.
               :      \return The number of the Edge that separates the point
               :      from the triangle and -1 if the point is inside the triangle.
               :    */
               :	int getPointDirection(const Point& point) const;
               :	
               :	//! A member that prints the main properties of the triangle
               :    /*!
               :      \param out a std::outstream.
               :    */
               :	void print(std::ostream & out) const;
               :
               :private:
               :	//std::array<Point, NNODES> points_;
               :	std::vector<Point> points_;
               :	Eigen::Matrix<Real,2,2> M_J_;
               :	Eigen::Matrix<Real,2,2> M_invJ_;
               :	Eigen::Matrix<Real,2,2> metric_;
               :	Real detJ_;
               :	void init(const std::vector<Point> &points);
               :};
               :
               :template <UInt NNODES>
               :const int Triangle<NNODES>::myDim;
               :
               ://! A function for the evaluation of point value in a triangle.
               :/*!
               :  \param t a Triangle object
               :  \param point a point object
               :  \param coefficients a Eigen vector specifing the coefficients of the Lagrangian
               :		 base (1st or 2nd order) defined on the Triangle.
               :  \return The point evaluation of the function defined by the coefficients on
               :  the triangle
               :    */
               :template <UInt ORDER>
               :Real evaluate_point(const Triangle<3*ORDER>& t, const Point& point, const Eigen::Matrix<Real,3*ORDER,1>& coefficients);
               :
               :template <UInt ORDER>
               :Eigen::Matrix<Real,2,1> evaluate_der_point(const Triangle<3*ORDER>& t, const Point& point, const Eigen::Matrix<Real,3*ORDER,1>& coefficients);
               :#include "mesh_objects_imp.hpp"
               :
               :#endif
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/SparseLU/SparseLU_pruneL.h"
 * 
 *      1  1.3889
 */


               :// This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2012 Dsir Nuentsa-Wakam <desire.nuentsa_wakam@inria.fr>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :/* 
               : 
               : * NOTE: This file is the modified version of [s,d,c,z]pruneL.c file in SuperLU 
               : 
               : * -- SuperLU routine (version 2.0) --
               : * Univ. of California Berkeley, Xerox Palo Alto Research Center,
               : * and Lawrence Berkeley National Lab.
               : * November 15, 1997
               : *
               : * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.
               : *
               : * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY
               : * EXPRESSED OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.
               : *
               : * Permission is hereby granted to use or copy this program for any
               : * purpose, provided the above notices are retained on all copies.
               : * Permission to modify the code and to distribute modified code is
               : * granted, provided the above notices are retained, and a notice that
               : * the code was modified is included with the above copyright notice.
               : */
               :#ifndef SPARSELU_PRUNEL_H
               :#define SPARSELU_PRUNEL_H
               :
               :namespace Eigen {
               :namespace internal {
               :
               :/**
               : * \brief Prunes the L-structure.
               : *
               : * It prunes the L-structure  of supernodes whose L-structure contains the current pivot row "pivrow"
               : * 
               : * 
               : * \param jcol The current column of L
               : * \param[in] perm_r Row permutation
               : * \param[out] pivrow  The pivot row
               : * \param nseg Number of segments
               : * \param segrep 
               : * \param repfnz
               : * \param[out] xprune 
               : * \param glu Global LU data
               : * 
               : */
               :template <typename Scalar, typename Index>
               :void SparseLUImpl<Scalar,Index>::pruneL(const Index jcol, const IndexVector& perm_r, const Index pivrow, const Index nseg, const IndexVector& segrep, BlockIndexVector repfnz, IndexVector& xprune, GlobalLU_t& glu) /* Eigen::internal::SparseLUImpl<double, int>::pruneL(int, Eigen::Matrix<int, -1, 1, 0, -1, 1> const&, int, int, Eigen::Matrix<int, -1, 1, 0, -1, 1> const&, Eigen::Ref<Eigen::Matrix<int, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> >, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::internal::LU_GlobalLU_t<Eigen::Matrix<int, -1, 1, 0, -1, 1>, Eigen::Matrix<double, -1, 1, 0, -1, 1> >&) total:      1  1.3889 */
               :{
               :  // For each supernode-rep irep in U(*,j]
               :  Index jsupno = glu.supno(jcol); 
               :  Index i,irep,irep1; 
               :  bool movnum, do_prune = false; 
               :  Index kmin = 0, kmax = 0, minloc, maxloc,krow; 
               :  for (i = 0; i < nseg; i++)
               :  {
               :    irep = segrep(i); 
               :    irep1 = irep + 1; 
               :    do_prune = false; 
               :    
               :    // Don't prune with a zero U-segment 
               :    if (repfnz(irep) == emptyIdxLU) continue; 
               :    
               :    // If a snode overlaps with the next panel, then the U-segment
               :    // is fragmented into two parts -- irep and irep1. We should let 
               :    // pruning occur at the rep-column in irep1s snode. 
               :    if (glu.supno(irep) == glu.supno(irep1) ) continue; // don't prune 
               :    
               :    // If it has not been pruned & it has a nonz in row L(pivrow,i)
               :    if (glu.supno(irep) != jsupno )
               :    {
               :      if ( xprune (irep) >= glu.xlsub(irep1) )
               :      {
               :        kmin = glu.xlsub(irep);
               :        kmax = glu.xlsub(irep1) - 1; 
               :        for (krow = kmin; krow <= kmax; krow++)
               :        {
               :          if (glu.lsub(krow) == pivrow) 
               :          {
               :            do_prune = true; 
               :            break; 
               :          }
               :        }
               :      }
               :      
               :      if (do_prune) 
               :      {
               :        // do a quicksort-type partition
               :        // movnum=true means that the num values have to be exchanged
               :        movnum = false; 
               :        if (irep == glu.xsup(glu.supno(irep)) ) // Snode of size 1 
               :          movnum = true; 
               :        
               :        while (kmin <= kmax)
               :        {
               :          if (perm_r(glu.lsub(kmax)) == emptyIdxLU)
               :            kmax--; 
               :          else if ( perm_r(glu.lsub(kmin)) != emptyIdxLU)
               :            kmin++;
               :          else 
               :          {
               :            // kmin below pivrow (not yet pivoted), and kmax
               :            // above pivrow: interchange the two suscripts
               :            std::swap(glu.lsub(kmin), glu.lsub(kmax)); 
               :            
               :            // If the supernode has only one column, then we 
               :            // only keep one set of subscripts. For any subscript
               :            // intercnahge performed, similar interchange must be 
               :            // done on the numerical values. 
               :            if (movnum) 
               :            {
               :              minloc = glu.xlusup(irep) + ( kmin - glu.xlsub(irep) ); 
               :              maxloc = glu.xlusup(irep) + ( kmax - glu.xlsub(irep) ); 
     1  1.3889 :              std::swap(glu.lusup(minloc), glu.lusup(maxloc)); 
               :            }
               :            kmin++;
               :            kmax--;
               :          }
               :        } // end while 
               :        
               :        xprune(irep) = kmin;  //Pruning 
               :      } // end if do_prune 
               :    } // end pruning 
               :  } // End for each U-segment
               :}
               :
               :} // end namespace internal
               :} // end namespace Eigen
               :
               :#endif // SPARSELU_PRUNEL_H
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/SparseCore/SparseMatrix.h"
 * 
 *      1  1.3889
 */


               :// This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2008-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :#ifndef EIGEN_SPARSEMATRIX_H
               :#define EIGEN_SPARSEMATRIX_H
               :
               :namespace Eigen { 
               :
               :/** \ingroup SparseCore_Module
               :  *
               :  * \class SparseMatrix
               :  *
               :  * \brief A versatible sparse matrix representation
               :  *
               :  * This class implements a more versatile variants of the common \em compressed row/column storage format.
               :  * Each colmun's (resp. row) non zeros are stored as a pair of value with associated row (resp. colmiun) index.
               :  * All the non zeros are stored in a single large buffer. Unlike the \em compressed format, there might be extra
               :  * space inbetween the nonzeros of two successive colmuns (resp. rows) such that insertion of new non-zero
               :  * can be done with limited memory reallocation and copies.
               :  *
               :  * A call to the function makeCompressed() turns the matrix into the standard \em compressed format
               :  * compatible with many library.
               :  *
               :  * More details on this storage sceheme are given in the \ref TutorialSparse "manual pages".
               :  *
               :  * \tparam _Scalar the scalar type, i.e. the type of the coefficients
               :  * \tparam _Options Union of bit flags controlling the storage scheme. Currently the only possibility
               :  *                 is ColMajor or RowMajor. The default is 0 which means column-major.
               :  * \tparam _Index the type of the indices. It has to be a \b signed type (e.g., short, int, std::ptrdiff_t). Default is \c int.
               :  *
               :  * This class can be extended with the help of the plugin mechanism described on the page
               :  * \ref TopicCustomizingEigen by defining the preprocessor symbol \c EIGEN_SPARSEMATRIX_PLUGIN.
               :  */
               :
               :namespace internal {
               :template<typename _Scalar, int _Options, typename _Index>
               :struct traits<SparseMatrix<_Scalar, _Options, _Index> >
               :{
               :  typedef _Scalar Scalar;
               :  typedef _Index Index;
               :  typedef Sparse StorageKind;
               :  typedef MatrixXpr XprKind;
               :  enum {
               :    RowsAtCompileTime = Dynamic,
               :    ColsAtCompileTime = Dynamic,
               :    MaxRowsAtCompileTime = Dynamic,
               :    MaxColsAtCompileTime = Dynamic,
               :    Flags = _Options | NestByRefBit | LvalueBit,
               :    CoeffReadCost = NumTraits<Scalar>::ReadCost,
               :    SupportedAccessPatterns = InnerRandomAccessPattern
               :  };
               :};
               :
               :template<typename _Scalar, int _Options, typename _Index, int DiagIndex>
               :struct traits<Diagonal<const SparseMatrix<_Scalar, _Options, _Index>, DiagIndex> >
               :{
               :  typedef SparseMatrix<_Scalar, _Options, _Index> MatrixType;
               :  typedef typename nested<MatrixType>::type MatrixTypeNested;
               :  typedef typename remove_reference<MatrixTypeNested>::type _MatrixTypeNested;
               :
               :  typedef _Scalar Scalar;
               :  typedef Dense StorageKind;
               :  typedef _Index Index;
               :  typedef MatrixXpr XprKind;
               :
               :  enum {
               :    RowsAtCompileTime = Dynamic,
               :    ColsAtCompileTime = 1,
               :    MaxRowsAtCompileTime = Dynamic,
               :    MaxColsAtCompileTime = 1,
               :    Flags = 0,
               :    CoeffReadCost = _MatrixTypeNested::CoeffReadCost*10
               :  };
               :};
               :
               :} // end namespace internal
               :
               :template<typename _Scalar, int _Options, typename _Index>
               :class SparseMatrix
               :  : public SparseMatrixBase<SparseMatrix<_Scalar, _Options, _Index> >
               :{
               :  public:
               :    EIGEN_SPARSE_PUBLIC_INTERFACE(SparseMatrix)
               :    EIGEN_SPARSE_INHERIT_ASSIGNMENT_OPERATOR(SparseMatrix, +=)
               :    EIGEN_SPARSE_INHERIT_ASSIGNMENT_OPERATOR(SparseMatrix, -=)
               :
               :    typedef MappedSparseMatrix<Scalar,Flags> Map;
               :    using Base::IsRowMajor;
               :    typedef internal::CompressedStorage<Scalar,Index> Storage;
               :    enum {
               :      Options = _Options
               :    };
               :
               :  protected:
               :
               :    typedef SparseMatrix<Scalar,(Flags&~RowMajorBit)|(IsRowMajor?RowMajorBit:0)> TransposedSparseMatrix;
               :
               :    Index m_outerSize;
               :    Index m_innerSize;
               :    Index* m_outerIndex;
               :    Index* m_innerNonZeros;     // optional, if null then the data is compressed
               :    Storage m_data;
               :    
               :    Eigen::Map<Matrix<Index,Dynamic,1> > innerNonZeros() { return Eigen::Map<Matrix<Index,Dynamic,1> >(m_innerNonZeros, m_innerNonZeros?m_outerSize:0); }
               :    const  Eigen::Map<const Matrix<Index,Dynamic,1> > innerNonZeros() const { return Eigen::Map<const Matrix<Index,Dynamic,1> >(m_innerNonZeros, m_innerNonZeros?m_outerSize:0); }
               :
               :  public:
               :    
               :    /** \returns whether \c *this is in compressed form. */
               :    inline bool isCompressed() const { return m_innerNonZeros==0; }
               :
               :    /** \returns the number of rows of the matrix */
               :    inline Index rows() const { return IsRowMajor ? m_outerSize : m_innerSize; }
               :    /** \returns the number of columns of the matrix */
               :    inline Index cols() const { return IsRowMajor ? m_innerSize : m_outerSize; }
               :
               :    /** \returns the number of rows (resp. columns) of the matrix if the storage order column major (resp. row major) */
               :    inline Index innerSize() const { return m_innerSize; }
               :    /** \returns the number of columns (resp. rows) of the matrix if the storage order column major (resp. row major) */
               :    inline Index outerSize() const { return m_outerSize; }
               :    
               :    /** \returns a const pointer to the array of values.
               :      * This function is aimed at interoperability with other libraries.
               :      * \sa innerIndexPtr(), outerIndexPtr() */
               :    inline const Scalar* valuePtr() const { return &m_data.value(0); }
               :    /** \returns a non-const pointer to the array of values.
               :      * This function is aimed at interoperability with other libraries.
               :      * \sa innerIndexPtr(), outerIndexPtr() */
               :    inline Scalar* valuePtr() { return &m_data.value(0); }
               :
               :    /** \returns a const pointer to the array of inner indices.
               :      * This function is aimed at interoperability with other libraries.
               :      * \sa valuePtr(), outerIndexPtr() */
               :    inline const Index* innerIndexPtr() const { return &m_data.index(0); }
               :    /** \returns a non-const pointer to the array of inner indices.
               :      * This function is aimed at interoperability with other libraries.
               :      * \sa valuePtr(), outerIndexPtr() */
               :    inline Index* innerIndexPtr() { return &m_data.index(0); }
               :
               :    /** \returns a const pointer to the array of the starting positions of the inner vectors.
               :      * This function is aimed at interoperability with other libraries.
               :      * \sa valuePtr(), innerIndexPtr() */
               :    inline const Index* outerIndexPtr() const { return m_outerIndex; }
               :    /** \returns a non-const pointer to the array of the starting positions of the inner vectors.
               :      * This function is aimed at interoperability with other libraries.
               :      * \sa valuePtr(), innerIndexPtr() */
               :    inline Index* outerIndexPtr() { return m_outerIndex; }
               :
               :    /** \returns a const pointer to the array of the number of non zeros of the inner vectors.
               :      * This function is aimed at interoperability with other libraries.
               :      * \warning it returns the null pointer 0 in compressed mode */
               :    inline const Index* innerNonZeroPtr() const { return m_innerNonZeros; }
               :    /** \returns a non-const pointer to the array of the number of non zeros of the inner vectors.
               :      * This function is aimed at interoperability with other libraries.
               :      * \warning it returns the null pointer 0 in compressed mode */
               :    inline Index* innerNonZeroPtr() { return m_innerNonZeros; }
               :
               :    /** \internal */
               :    inline Storage& data() { return m_data; }
               :    /** \internal */
               :    inline const Storage& data() const { return m_data; }
               :
               :    /** \returns the value of the matrix at position \a i, \a j
               :      * This function returns Scalar(0) if the element is an explicit \em zero */
               :    inline Scalar coeff(Index row, Index col) const
               :    {
               :      eigen_assert(row>=0 && row<rows() && col>=0 && col<cols());
               :      
               :      const Index outer = IsRowMajor ? row : col;
               :      const Index inner = IsRowMajor ? col : row;
               :      Index end = m_innerNonZeros ? m_outerIndex[outer] + m_innerNonZeros[outer] : m_outerIndex[outer+1];
               :      return m_data.atInRange(m_outerIndex[outer], end, inner);
               :    }
               :
               :    /** \returns a non-const reference to the value of the matrix at position \a i, \a j
               :      *
               :      * If the element does not exist then it is inserted via the insert(Index,Index) function
               :      * which itself turns the matrix into a non compressed form if that was not the case.
               :      *
               :      * This is a O(log(nnz_j)) operation (binary search) plus the cost of insert(Index,Index)
               :      * function if the element does not already exist.
               :      */
               :    inline Scalar& coeffRef(Index row, Index col)
               :    {
               :      eigen_assert(row>=0 && row<rows() && col>=0 && col<cols());
               :      
               :      const Index outer = IsRowMajor ? row : col;
               :      const Index inner = IsRowMajor ? col : row;
               :
               :      Index start = m_outerIndex[outer];
               :      Index end = m_innerNonZeros ? m_outerIndex[outer] + m_innerNonZeros[outer] : m_outerIndex[outer+1];
               :      eigen_assert(end>=start && "you probably called coeffRef on a non finalized matrix");
               :      if(end<=start)
               :        return insert(row,col);
               :      const Index p = m_data.searchLowerIndex(start,end-1,inner);
               :      if((p<end) && (m_data.index(p)==inner))
               :        return m_data.value(p);
               :      else
               :        return insert(row,col);
               :    }
               :
               :    /** \returns a reference to a novel non zero coefficient with coordinates \a row x \a col.
               :      * The non zero coefficient must \b not already exist.
               :      *
               :      * If the matrix \c *this is in compressed mode, then \c *this is turned into uncompressed
               :      * mode while reserving room for 2 non zeros per inner vector. It is strongly recommended to first
               :      * call reserve(const SizesType &) to reserve a more appropriate number of elements per
               :      * inner vector that better match your scenario.
               :      *
               :      * This function performs a sorted insertion in O(1) if the elements of each inner vector are
               :      * inserted in increasing inner index order, and in O(nnz_j) for a random insertion.
               :      *
               :      */
               :    Scalar& insert(Index row, Index col)
               :    {
               :      eigen_assert(row>=0 && row<rows() && col>=0 && col<cols());
               :      
               :      if(isCompressed())
               :      {
               :        reserve(Matrix<Index,Dynamic,1>::Constant(outerSize(), 2));
               :      }
               :      return insertUncompressed(row,col);
               :    }
               :
               :  public:
               :
               :    class InnerIterator;
               :    class ReverseInnerIterator;
               :
               :    /** Removes all non zeros but keep allocated memory */
               :    inline void setZero()
               :    {
               :      m_data.clear();
               :      memset(m_outerIndex, 0, (m_outerSize+1)*sizeof(Index));
               :      if(m_innerNonZeros)
               :        memset(m_innerNonZeros, 0, (m_outerSize)*sizeof(Index));
               :    }
               :
               :    /** \returns the number of non zero coefficients */
               :    inline Index nonZeros() const
               :    {
               :      if(m_innerNonZeros)
               :        return innerNonZeros().sum();
               :      return static_cast<Index>(m_data.size());
               :    }
               :
               :    /** Preallocates \a reserveSize non zeros.
               :      *
               :      * Precondition: the matrix must be in compressed mode. */
               :    inline void reserve(Index reserveSize)
               :    {
               :      eigen_assert(isCompressed() && "This function does not make sense in non compressed mode.");
               :      m_data.reserve(reserveSize);
               :    }
               :    
               :    #ifdef EIGEN_PARSED_BY_DOXYGEN
               :    /** Preallocates \a reserveSize[\c j] non zeros for each column (resp. row) \c j.
               :      *
               :      * This function turns the matrix in non-compressed mode */
               :    template<class SizesType>
               :    inline void reserve(const SizesType& reserveSizes);
               :    #else
               :    template<class SizesType>
               :    inline void reserve(const SizesType& reserveSizes, const typename SizesType::value_type& enableif = typename SizesType::value_type())
               :    {
               :      EIGEN_UNUSED_VARIABLE(enableif);
               :      reserveInnerVectors(reserveSizes);
               :    }
               :    template<class SizesType>
               :    inline void reserve(const SizesType& reserveSizes, const typename SizesType::Scalar& enableif =
               :    #if (!defined(_MSC_VER)) || (_MSC_VER>=1500) // MSVC 2005 fails to compile with this typename
               :        typename
               :    #endif
               :        SizesType::Scalar())
               :    {
               :      EIGEN_UNUSED_VARIABLE(enableif);
               :      reserveInnerVectors(reserveSizes);
               :    }
               :    #endif // EIGEN_PARSED_BY_DOXYGEN
               :  protected:
               :    template<class SizesType>
               :    inline void reserveInnerVectors(const SizesType& reserveSizes)
               :    {
               :      if(isCompressed())
               :      {
               :        std::size_t totalReserveSize = 0;
               :        // turn the matrix into non-compressed mode
               :        m_innerNonZeros = static_cast<Index*>(std::malloc(m_outerSize * sizeof(Index)));
               :        if (!m_innerNonZeros) internal::throw_std_bad_alloc();
               :        
               :        // temporarily use m_innerSizes to hold the new starting points.
               :        Index* newOuterIndex = m_innerNonZeros;
               :        
               :        Index count = 0;
               :        for(Index j=0; j<m_outerSize; ++j)
               :        {
               :          newOuterIndex[j] = count;
               :          count += reserveSizes[j] + (m_outerIndex[j+1]-m_outerIndex[j]);
               :          totalReserveSize += reserveSizes[j];
               :        }
               :        m_data.reserve(totalReserveSize);
               :        Index previousOuterIndex = m_outerIndex[m_outerSize];
               :        for(Index j=m_outerSize-1; j>=0; --j)
               :        {
               :          Index innerNNZ = previousOuterIndex - m_outerIndex[j];
               :          for(Index i=innerNNZ-1; i>=0; --i)
               :          {
               :            m_data.index(newOuterIndex[j]+i) = m_data.index(m_outerIndex[j]+i);
               :            m_data.value(newOuterIndex[j]+i) = m_data.value(m_outerIndex[j]+i);
               :          }
               :          previousOuterIndex = m_outerIndex[j];
               :          m_outerIndex[j] = newOuterIndex[j];
               :          m_innerNonZeros[j] = innerNNZ;
               :        }
               :        m_outerIndex[m_outerSize] = m_outerIndex[m_outerSize-1] + m_innerNonZeros[m_outerSize-1] + reserveSizes[m_outerSize-1];
               :        
               :        m_data.resize(m_outerIndex[m_outerSize]);
               :      }
               :      else
               :      {
               :        Index* newOuterIndex = static_cast<Index*>(std::malloc((m_outerSize+1)*sizeof(Index)));
               :        if (!newOuterIndex) internal::throw_std_bad_alloc();
               :        
               :        Index count = 0;
               :        for(Index j=0; j<m_outerSize; ++j)
               :        {
               :          newOuterIndex[j] = count;
               :          Index alreadyReserved = (m_outerIndex[j+1]-m_outerIndex[j]) - m_innerNonZeros[j];
               :          Index toReserve = std::max<Index>(reserveSizes[j], alreadyReserved);
               :          count += toReserve + m_innerNonZeros[j];
               :        }
               :        newOuterIndex[m_outerSize] = count;
               :        
               :        m_data.resize(count);
               :        for(Index j=m_outerSize-1; j>=0; --j)
               :        {
               :          Index offset = newOuterIndex[j] - m_outerIndex[j];
               :          if(offset>0)
               :          {
               :            Index innerNNZ = m_innerNonZeros[j];
               :            for(Index i=innerNNZ-1; i>=0; --i)
               :            {
               :              m_data.index(newOuterIndex[j]+i) = m_data.index(m_outerIndex[j]+i);
               :              m_data.value(newOuterIndex[j]+i) = m_data.value(m_outerIndex[j]+i);
               :            }
               :          }
               :        }
               :        
               :        std::swap(m_outerIndex, newOuterIndex);
               :        std::free(newOuterIndex);
               :      }
               :      
               :    }
               :  public:
               :
               :    //--- low level purely coherent filling ---
               :
               :    /** \internal
               :      * \returns a reference to the non zero coefficient at position \a row, \a col assuming that:
               :      * - the nonzero does not already exist
               :      * - the new coefficient is the last one according to the storage order
               :      *
               :      * Before filling a given inner vector you must call the statVec(Index) function.
               :      *
               :      * After an insertion session, you should call the finalize() function.
               :      *
               :      * \sa insert, insertBackByOuterInner, startVec */
               :    inline Scalar& insertBack(Index row, Index col)
               :    {
               :      return insertBackByOuterInner(IsRowMajor?row:col, IsRowMajor?col:row);
               :    }
               :
               :    /** \internal
               :      * \sa insertBack, startVec */
               :    inline Scalar& insertBackByOuterInner(Index outer, Index inner)
               :    {
               :      eigen_assert(size_t(m_outerIndex[outer+1]) == m_data.size() && "Invalid ordered insertion (invalid outer index)");
               :      eigen_assert( (m_outerIndex[outer+1]-m_outerIndex[outer]==0 || m_data.index(m_data.size()-1)<inner) && "Invalid ordered insertion (invalid inner index)");
               :      Index p = m_outerIndex[outer+1];
               :      ++m_outerIndex[outer+1];
               :      m_data.append(0, inner);
               :      return m_data.value(p);
               :    }
               :
               :    /** \internal
               :      * \warning use it only if you know what you are doing */
               :    inline Scalar& insertBackByOuterInnerUnordered(Index outer, Index inner)
               :    {
               :      Index p = m_outerIndex[outer+1];
               :      ++m_outerIndex[outer+1];
               :      m_data.append(0, inner);
               :      return m_data.value(p);
               :    }
               :
               :    /** \internal
               :      * \sa insertBack, insertBackByOuterInner */
               :    inline void startVec(Index outer)
               :    {
               :      eigen_assert(m_outerIndex[outer]==Index(m_data.size()) && "You must call startVec for each inner vector sequentially");
               :      eigen_assert(m_outerIndex[outer+1]==0 && "You must call startVec for each inner vector sequentially");
               :      m_outerIndex[outer+1] = m_outerIndex[outer];
               :    }
               :
               :    /** \internal
               :      * Must be called after inserting a set of non zero entries using the low level compressed API.
               :      */
               :    inline void finalize()
               :    {
               :      if(isCompressed())
               :      {
               :        Index size = static_cast<Index>(m_data.size());
               :        Index i = m_outerSize;
               :        // find the last filled column
               :        while (i>=0 && m_outerIndex[i]==0)
               :          --i;
               :        ++i;
               :        while (i<=m_outerSize)
               :        {
               :          m_outerIndex[i] = size;
               :          ++i;
               :        }
               :      }
               :    }
               :
               :    //---
               :
               :    template<typename InputIterators>
               :    void setFromTriplets(const InputIterators& begin, const InputIterators& end);
               :
               :    void sumupDuplicates();
               :
               :    //---
               :    
               :    /** \internal
               :      * same as insert(Index,Index) except that the indices are given relative to the storage order */
               :    Scalar& insertByOuterInner(Index j, Index i)
               :    {
               :      return insert(IsRowMajor ? j : i, IsRowMajor ? i : j);
               :    }
               :
               :    /** Turns the matrix into the \em compressed format.
               :      */
               :    void makeCompressed()
               :    {
               :      if(isCompressed())
               :        return;
               :      
               :      Index oldStart = m_outerIndex[1];
               :      m_outerIndex[1] = m_innerNonZeros[0];
               :      for(Index j=1; j<m_outerSize; ++j)
               :      {
               :        Index nextOldStart = m_outerIndex[j+1];
               :        Index offset = oldStart - m_outerIndex[j];
               :        if(offset>0)
               :        {
               :          for(Index k=0; k<m_innerNonZeros[j]; ++k)
               :          {
               :            m_data.index(m_outerIndex[j]+k) = m_data.index(oldStart+k);
               :            m_data.value(m_outerIndex[j]+k) = m_data.value(oldStart+k);
               :          }
               :        }
               :        m_outerIndex[j+1] = m_outerIndex[j] + m_innerNonZeros[j];
               :        oldStart = nextOldStart;
               :      }
               :      std::free(m_innerNonZeros);
               :      m_innerNonZeros = 0;
               :      m_data.resize(m_outerIndex[m_outerSize]);
               :      m_data.squeeze();
               :    }
               :
               :    /** Turns the matrix into the uncompressed mode */
               :    void uncompress()
               :    {
               :      if(m_innerNonZeros != 0)
               :        return; 
               :      m_innerNonZeros = static_cast<Index*>(std::malloc(m_outerSize * sizeof(Index)));
               :      for (Index i = 0; i < m_outerSize; i++)
               :      {
               :        m_innerNonZeros[i] = m_outerIndex[i+1] - m_outerIndex[i]; 
               :      }
               :    }
               :    
               :    /** Suppresses all nonzeros which are \b much \b smaller \b than \a reference under the tolerence \a epsilon */
               :    void prune(const Scalar& reference, const RealScalar& epsilon = NumTraits<RealScalar>::dummy_precision())
               :    {
               :      prune(default_prunning_func(reference,epsilon));
               :    }
               :    
               :    /** Turns the matrix into compressed format, and suppresses all nonzeros which do not satisfy the predicate \a keep.
               :      * The functor type \a KeepFunc must implement the following function:
               :      * \code
               :      * bool operator() (const Index& row, const Index& col, const Scalar& value) const;
               :      * \endcode
               :      * \sa prune(Scalar,RealScalar)
               :      */
               :    template<typename KeepFunc>
               :    void prune(const KeepFunc& keep = KeepFunc())
               :    {
               :      // TODO optimize the uncompressed mode to avoid moving and allocating the data twice
               :      // TODO also implement a unit test
               :      makeCompressed();
               :
               :      Index k = 0;
               :      for(Index j=0; j<m_outerSize; ++j)
               :      {
               :        Index previousStart = m_outerIndex[j];
               :        m_outerIndex[j] = k;
               :        Index end = m_outerIndex[j+1];
               :        for(Index i=previousStart; i<end; ++i)
               :        {
               :          if(keep(IsRowMajor?j:m_data.index(i), IsRowMajor?m_data.index(i):j, m_data.value(i)))
               :          {
               :            m_data.value(k) = m_data.value(i);
               :            m_data.index(k) = m_data.index(i);
               :            ++k;
               :          }
               :        }
               :      }
               :      m_outerIndex[m_outerSize] = k;
               :      m_data.resize(k,0);
               :    }
               :
               :    /** Resizes the matrix to a \a rows x \a cols matrix leaving old values untouched.
               :      * \sa resizeNonZeros(Index), reserve(), setZero()
               :      */
               :    void conservativeResize(Index rows, Index cols) 
               :    {
               :      // No change
               :      if (this->rows() == rows && this->cols() == cols) return;
               :      
               :      // If one dimension is null, then there is nothing to be preserved
               :      if(rows==0 || cols==0) return resize(rows,cols);
               :
               :      Index innerChange = IsRowMajor ? cols - this->cols() : rows - this->rows();
               :      Index outerChange = IsRowMajor ? rows - this->rows() : cols - this->cols();
               :      Index newInnerSize = IsRowMajor ? cols : rows;
               :
               :      // Deals with inner non zeros
               :      if (m_innerNonZeros)
               :      {
               :        // Resize m_innerNonZeros
               :        Index *newInnerNonZeros = static_cast<Index*>(std::realloc(m_innerNonZeros, (m_outerSize + outerChange) * sizeof(Index)));
               :        if (!newInnerNonZeros) internal::throw_std_bad_alloc();
               :        m_innerNonZeros = newInnerNonZeros;
               :        
               :        for(Index i=m_outerSize; i<m_outerSize+outerChange; i++)          
               :          m_innerNonZeros[i] = 0;
               :      } 
               :      else if (innerChange < 0) 
               :      {
               :        // Inner size decreased: allocate a new m_innerNonZeros
               :        m_innerNonZeros = static_cast<Index*>(std::malloc((m_outerSize+outerChange+1) * sizeof(Index)));
               :        if (!m_innerNonZeros) internal::throw_std_bad_alloc();
               :        for(Index i = 0; i < m_outerSize; i++)
               :          m_innerNonZeros[i] = m_outerIndex[i+1] - m_outerIndex[i];
               :      }
               :      
               :      // Change the m_innerNonZeros in case of a decrease of inner size
               :      if (m_innerNonZeros && innerChange < 0)
               :      {
               :        for(Index i = 0; i < m_outerSize + (std::min)(outerChange, Index(0)); i++)
               :        {
               :          Index &n = m_innerNonZeros[i];
               :          Index start = m_outerIndex[i];
               :          while (n > 0 && m_data.index(start+n-1) >= newInnerSize) --n; 
               :        }
               :      }
               :      
               :      m_innerSize = newInnerSize;
               :
               :      // Re-allocate outer index structure if necessary
               :      if (outerChange == 0)
               :        return;
               :          
               :      Index *newOuterIndex = static_cast<Index*>(std::realloc(m_outerIndex, (m_outerSize + outerChange + 1) * sizeof(Index)));
               :      if (!newOuterIndex) internal::throw_std_bad_alloc();
               :      m_outerIndex = newOuterIndex;
               :      if (outerChange > 0)
               :      {
               :        Index last = m_outerSize == 0 ? 0 : m_outerIndex[m_outerSize];
               :        for(Index i=m_outerSize; i<m_outerSize+outerChange+1; i++)          
               :          m_outerIndex[i] = last; 
               :      }
               :      m_outerSize += outerChange;
               :    }
               :    
               :    /** Resizes the matrix to a \a rows x \a cols matrix and initializes it to zero.
               :      * \sa resizeNonZeros(Index), reserve(), setZero()
               :      */
               :    void resize(Index rows, Index cols)
               :    {
               :      const Index outerSize = IsRowMajor ? rows : cols;
               :      m_innerSize = IsRowMajor ? cols : rows;
               :      m_data.clear();
               :      if (m_outerSize != outerSize || m_outerSize==0)
               :      {
               :        std::free(m_outerIndex);
               :        m_outerIndex = static_cast<Index*>(std::malloc((outerSize + 1) * sizeof(Index)));
               :        if (!m_outerIndex) internal::throw_std_bad_alloc();
               :        
               :        m_outerSize = outerSize;
               :      }
               :      if(m_innerNonZeros)
               :      {
               :        std::free(m_innerNonZeros);
               :        m_innerNonZeros = 0;
               :      }
               :      memset(m_outerIndex, 0, (m_outerSize+1)*sizeof(Index));
               :    }
               :
               :    /** \internal
               :      * Resize the nonzero vector to \a size */
               :    void resizeNonZeros(Index size)
               :    {
               :      // TODO remove this function
               :      m_data.resize(size);
               :    }
               :
               :    /** \returns a const expression of the diagonal coefficients */
               :    const Diagonal<const SparseMatrix> diagonal() const { return *this; }
               :
               :    /** Default constructor yielding an empty \c 0 \c x \c 0 matrix */
               :    inline SparseMatrix()
               :      : m_outerSize(-1), m_innerSize(0), m_outerIndex(0), m_innerNonZeros(0)
               :    {
               :      check_template_parameters();
               :      resize(0, 0);
               :    }
               :
               :    /** Constructs a \a rows \c x \a cols empty matrix */
               :    inline SparseMatrix(Index rows, Index cols)
               :      : m_outerSize(0), m_innerSize(0), m_outerIndex(0), m_innerNonZeros(0)
               :    {
               :      check_template_parameters();
               :      resize(rows, cols);
               :    }
               :
               :    /** Constructs a sparse matrix from the sparse expression \a other */
               :    template<typename OtherDerived>
               :    inline SparseMatrix(const SparseMatrixBase<OtherDerived>& other)
               :      : m_outerSize(0), m_innerSize(0), m_outerIndex(0), m_innerNonZeros(0)
               :    {
               :      EIGEN_STATIC_ASSERT((internal::is_same<Scalar, typename OtherDerived::Scalar>::value),
               :        YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY)
               :      check_template_parameters();
               :      *this = other.derived();
               :    }
               :    
               :    /** Constructs a sparse matrix from the sparse selfadjoint view \a other */
               :    template<typename OtherDerived, unsigned int UpLo>
               :    inline SparseMatrix(const SparseSelfAdjointView<OtherDerived, UpLo>& other)
               :      : m_outerSize(0), m_innerSize(0), m_outerIndex(0), m_innerNonZeros(0)
               :    {
               :      check_template_parameters();
               :      *this = other;
               :    }
               :
               :    /** Copy constructor (it performs a deep copy) */
               :    inline SparseMatrix(const SparseMatrix& other)
               :      : Base(), m_outerSize(0), m_innerSize(0), m_outerIndex(0), m_innerNonZeros(0)
               :    {
               :      check_template_parameters();
               :      *this = other.derived();
               :    }
               :
               :    /** \brief Copy constructor with in-place evaluation */
               :    template<typename OtherDerived>
               :    SparseMatrix(const ReturnByValue<OtherDerived>& other)
               :      : Base(), m_outerSize(0), m_innerSize(0), m_outerIndex(0), m_innerNonZeros(0)
               :    {
               :      check_template_parameters();
               :      initAssignment(other);
               :      other.evalTo(*this);
               :    }
               :
               :    /** Swaps the content of two sparse matrices of the same type.
               :      * This is a fast operation that simply swaps the underlying pointers and parameters. */
               :    inline void swap(SparseMatrix& other)
               :    {
               :      //EIGEN_DBG_SPARSE(std::cout << "SparseMatrix:: swap\n");
               :      std::swap(m_outerIndex, other.m_outerIndex);
               :      std::swap(m_innerSize, other.m_innerSize);
               :      std::swap(m_outerSize, other.m_outerSize);
               :      std::swap(m_innerNonZeros, other.m_innerNonZeros);
               :      m_data.swap(other.m_data);
               :    }
               :
               :    /** Sets *this to the identity matrix */
               :    inline void setIdentity()
               :    {
               :      eigen_assert(rows() == cols() && "ONLY FOR SQUARED MATRICES");
               :      this->m_data.resize(rows());
               :      Eigen::Map<Matrix<Index, Dynamic, 1> >(&this->m_data.index(0), rows()).setLinSpaced(0, rows()-1);
               :      Eigen::Map<Matrix<Scalar, Dynamic, 1> >(&this->m_data.value(0), rows()).setOnes();
               :      Eigen::Map<Matrix<Index, Dynamic, 1> >(this->m_outerIndex, rows()+1).setLinSpaced(0, rows());
               :    }
               :    inline SparseMatrix& operator=(const SparseMatrix& other)
               :    {
               :      if (other.isRValue())
               :      {
               :        swap(other.const_cast_derived());
               :      }
               :      else if(this!=&other)
               :      {
               :        initAssignment(other);
               :        if(other.isCompressed())
               :        {
               :          memcpy(m_outerIndex, other.m_outerIndex, (m_outerSize+1)*sizeof(Index));
               :          m_data = other.m_data;
               :        }
               :        else
               :        {
               :          Base::operator=(other);
               :        }
               :      }
               :      return *this;
               :    }
               :
               :    #ifndef EIGEN_PARSED_BY_DOXYGEN
               :    template<typename Lhs, typename Rhs>
               :    inline SparseMatrix& operator=(const SparseSparseProduct<Lhs,Rhs>& product)
               :    { return Base::operator=(product); }
               :    
               :    template<typename OtherDerived>
               :    inline SparseMatrix& operator=(const ReturnByValue<OtherDerived>& other)
               :    {
               :      initAssignment(other);
               :      return Base::operator=(other.derived());
               :    }
               :    
               :    template<typename OtherDerived>
               :    inline SparseMatrix& operator=(const EigenBase<OtherDerived>& other)
               :    { return Base::operator=(other.derived()); }
               :    #endif
               :
               :    template<typename OtherDerived>
               :    EIGEN_DONT_INLINE SparseMatrix& operator=(const SparseMatrixBase<OtherDerived>& other);
               :
               :    friend std::ostream & operator << (std::ostream & s, const SparseMatrix& m)
               :    {
               :      EIGEN_DBG_SPARSE(
               :        s << "Nonzero entries:\n";
               :        if(m.isCompressed())
               :          for (Index i=0; i<m.nonZeros(); ++i)
               :            s << "(" << m.m_data.value(i) << "," << m.m_data.index(i) << ") ";
               :        else
               :          for (Index i=0; i<m.outerSize(); ++i)
               :          {
               :            Index p = m.m_outerIndex[i];
               :            Index pe = m.m_outerIndex[i]+m.m_innerNonZeros[i];
               :            Index k=p;
               :            for (; k<pe; ++k)
               :              s << "(" << m.m_data.value(k) << "," << m.m_data.index(k) << ") ";
               :            for (; k<m.m_outerIndex[i+1]; ++k)
               :              s << "(_,_) ";
               :          }
               :        s << std::endl;
               :        s << std::endl;
               :        s << "Outer pointers:\n";
               :        for (Index i=0; i<m.outerSize(); ++i)
               :          s << m.m_outerIndex[i] << " ";
               :        s << " $" << std::endl;
               :        if(!m.isCompressed())
               :        {
               :          s << "Inner non zeros:\n";
               :          for (Index i=0; i<m.outerSize(); ++i)
               :            s << m.m_innerNonZeros[i] << " ";
               :          s << " $" << std::endl;
               :        }
               :        s << std::endl;
               :      );
               :      s << static_cast<const SparseMatrixBase<SparseMatrix>&>(m);
               :      return s;
               :    }
               :
               :    /** Destructor */
               :    inline ~SparseMatrix()
               :    {
               :      std::free(m_outerIndex);
               :      std::free(m_innerNonZeros);
               :    }
               :
               :#ifndef EIGEN_PARSED_BY_DOXYGEN
               :    /** Overloaded for performance */
               :    Scalar sum() const;
               :#endif
               :    
               :#   ifdef EIGEN_SPARSEMATRIX_PLUGIN
               :#     include EIGEN_SPARSEMATRIX_PLUGIN
               :#   endif
               :
               :protected:
               :
               :    template<typename Other>
               :    void initAssignment(const Other& other)
               :    {
               :      resize(other.rows(), other.cols());
               :      if(m_innerNonZeros)
               :      {
               :        std::free(m_innerNonZeros);
               :        m_innerNonZeros = 0;
               :      }
               :    }
               :
               :    /** \internal
               :      * \sa insert(Index,Index) */
               :    EIGEN_DONT_INLINE Scalar& insertCompressed(Index row, Index col);
               :
               :    /** \internal
               :      * A vector object that is equal to 0 everywhere but v at the position i */
               :    class SingletonVector
               :    {
               :        Index m_index;
               :        Index m_value;
               :      public:
               :        typedef Index value_type;
               :        SingletonVector(Index i, Index v)
               :          : m_index(i), m_value(v)
               :        {}
               :
               :        Index operator[](Index i) const { return i==m_index ? m_value : 0; }
               :    };
               :
               :    /** \internal
               :      * \sa insert(Index,Index) */
               :    EIGEN_DONT_INLINE Scalar& insertUncompressed(Index row, Index col);
               :
               :public:
               :    /** \internal
               :      * \sa insert(Index,Index) */
               :    EIGEN_STRONG_INLINE Scalar& insertBackUncompressed(Index row, Index col)
               :    {
               :      const Index outer = IsRowMajor ? row : col;
               :      const Index inner = IsRowMajor ? col : row;
               :
               :      eigen_assert(!isCompressed());
               :      eigen_assert(m_innerNonZeros[outer]<=(m_outerIndex[outer+1] - m_outerIndex[outer]));
               :
     1  1.3889 :      Index p = m_outerIndex[outer] + m_innerNonZeros[outer]++;
               :      m_data.index(p) = inner;
               :      return (m_data.value(p) = 0);
               :    }
               :
               :private:
               :  static void check_template_parameters()
               :  {
               :    EIGEN_STATIC_ASSERT(NumTraits<Index>::IsSigned,THE_INDEX_TYPE_MUST_BE_A_SIGNED_TYPE);
               :    EIGEN_STATIC_ASSERT((Options&(ColMajor|RowMajor))==Options,INVALID_MATRIX_TEMPLATE_PARAMETERS);
               :  }
               :
               :  struct default_prunning_func {
               :    default_prunning_func(const Scalar& ref, const RealScalar& eps) : reference(ref), epsilon(eps) {}
               :    inline bool operator() (const Index&, const Index&, const Scalar& value) const
               :    {
               :      return !internal::isMuchSmallerThan(value, reference, epsilon);
               :    }
               :    Scalar reference;
               :    RealScalar epsilon;
               :  };
               :};
               :
               :template<typename Scalar, int _Options, typename _Index>
               :class SparseMatrix<Scalar,_Options,_Index>::InnerIterator
               :{
               :  public:
               :    InnerIterator(const SparseMatrix& mat, Index outer)
               :      : m_values(mat.valuePtr()), m_indices(mat.innerIndexPtr()), m_outer(outer), m_id(mat.m_outerIndex[outer])
               :    {
               :      if(mat.isCompressed())
               :        m_end = mat.m_outerIndex[outer+1];
               :      else
               :        m_end = m_id + mat.m_innerNonZeros[outer];
               :    }
               :
               :    inline InnerIterator& operator++() { m_id++; return *this; }
               :
               :    inline const Scalar& value() const { return m_values[m_id]; }
               :    inline Scalar& valueRef() { return const_cast<Scalar&>(m_values[m_id]); }
               :
               :    inline Index index() const { return m_indices[m_id]; }
               :    inline Index outer() const { return m_outer; }
               :    inline Index row() const { return IsRowMajor ? m_outer : index(); }
               :    inline Index col() const { return IsRowMajor ? index() : m_outer; }
               :
               :    inline operator bool() const { return (m_id < m_end); }
               :
               :  protected:
               :    const Scalar* m_values;
               :    const Index* m_indices;
               :    const Index m_outer;
               :    Index m_id;
               :    Index m_end;
               :};
               :
               :template<typename Scalar, int _Options, typename _Index>
               :class SparseMatrix<Scalar,_Options,_Index>::ReverseInnerIterator
               :{
               :  public:
               :    ReverseInnerIterator(const SparseMatrix& mat, Index outer)
               :      : m_values(mat.valuePtr()), m_indices(mat.innerIndexPtr()), m_outer(outer), m_start(mat.m_outerIndex[outer])
               :    {
               :      if(mat.isCompressed())
               :        m_id = mat.m_outerIndex[outer+1];
               :      else
               :        m_id = m_start + mat.m_innerNonZeros[outer];
               :    }
               :
               :    inline ReverseInnerIterator& operator--() { --m_id; return *this; }
               :
               :    inline const Scalar& value() const { return m_values[m_id-1]; }
               :    inline Scalar& valueRef() { return const_cast<Scalar&>(m_values[m_id-1]); }
               :
               :    inline Index index() const { return m_indices[m_id-1]; }
               :    inline Index outer() const { return m_outer; }
               :    inline Index row() const { return IsRowMajor ? m_outer : index(); }
               :    inline Index col() const { return IsRowMajor ? index() : m_outer; }
               :
               :    inline operator bool() const { return (m_id > m_start); }
               :
               :  protected:
               :    const Scalar* m_values;
               :    const Index* m_indices;
               :    const Index m_outer;
               :    Index m_id;
               :    const Index m_start;
               :};
               :
               :namespace internal {
               :
               :template<typename InputIterator, typename SparseMatrixType>
               :void set_from_triplets(const InputIterator& begin, const InputIterator& end, SparseMatrixType& mat, int Options = 0) /* void Eigen::internal::set_from_triplets<__gnu_cxx::__normal_iterator<Eigen::Triplet<double, int>*, std::vector<Eigen::Triplet<double, int>, std::allocator<Eigen::Triplet<double, int> > > >, Eigen::SparseMatrix<double, 0, int> >(__gnu_cxx::__normal_iterator<Eigen::Triplet<double, int>*, std::vector<Eigen::Triplet<double, int>, std::allocator<Eigen::Triplet<double, int> > > > const&, __gnu_cxx::__normal_iterator<Eigen::Triplet<double, int>*, std::vector<Eigen::Triplet<double, int>, std::allocator<Eigen::Triplet<double, int> > > > const&, Eigen::SparseMatrix<double, 0, int>&, int) total:      1  1.3889 */
               :{
               :  EIGEN_UNUSED_VARIABLE(Options);
               :  enum { IsRowMajor = SparseMatrixType::IsRowMajor };
               :  typedef typename SparseMatrixType::Scalar Scalar;
               :  typedef typename SparseMatrixType::Index Index;
               :  SparseMatrix<Scalar,IsRowMajor?ColMajor:RowMajor,Index> trMat(mat.rows(),mat.cols());
               :
               :  if(begin!=end)
               :  {
               :    // pass 1: count the nnz per inner-vector
               :    Matrix<Index,Dynamic,1> wi(trMat.outerSize());
               :    wi.setZero();
               :    for(InputIterator it(begin); it!=end; ++it)
               :    {
               :      eigen_assert(it->row()>=0 && it->row()<mat.rows() && it->col()>=0 && it->col()<mat.cols());
               :      wi(IsRowMajor ? it->col() : it->row())++;
               :    }
               :
               :    // pass 2: insert all the elements into trMat
               :    trMat.reserve(wi);
               :    for(InputIterator it(begin); it!=end; ++it)
               :      trMat.insertBackUncompressed(it->row(),it->col()) = it->value();
               :
               :    // pass 3:
               :    trMat.sumupDuplicates();
               :  }
               :
               :  // pass 4: transposed copy -> implicit sorting
               :  mat = trMat;
               :}
               :
               :}
               :
               :
               :/** Fill the matrix \c *this with the list of \em triplets defined by the iterator range \a begin - \a end.
               :  *
               :  * A \em triplet is a tuple (i,j,value) defining a non-zero element.
               :  * The input list of triplets does not have to be sorted, and can contains duplicated elements.
               :  * In any case, the result is a \b sorted and \b compressed sparse matrix where the duplicates have been summed up.
               :  * This is a \em O(n) operation, with \em n the number of triplet elements.
               :  * The initial contents of \c *this is destroyed.
               :  * The matrix \c *this must be properly resized beforehand using the SparseMatrix(Index,Index) constructor,
               :  * or the resize(Index,Index) method. The sizes are not extracted from the triplet list.
               :  *
               :  * The \a InputIterators value_type must provide the following interface:
               :  * \code
               :  * Scalar value() const; // the value
               :  * Scalar row() const;   // the row index i
               :  * Scalar col() const;   // the column index j
               :  * \endcode
               :  * See for instance the Eigen::Triplet template class.
               :  *
               :  * Here is a typical usage example:
               :  * \code
               :    typedef Triplet<double> T;
               :    std::vector<T> tripletList;
               :    triplets.reserve(estimation_of_entries);
               :    for(...)
               :    {
               :      // ...
               :      tripletList.push_back(T(i,j,v_ij));
               :    }
               :    SparseMatrixType m(rows,cols);
               :    m.setFromTriplets(tripletList.begin(), tripletList.end());
               :    // m is ready to go!
               :  * \endcode
               :  *
               :  * \warning The list of triplets is read multiple times (at least twice). Therefore, it is not recommended to define
               :  * an abstract iterator over a complex data-structure that would be expensive to evaluate. The triplets should rather
               :  * be explicitely stored into a std::vector for instance.
               :  */
               :template<typename Scalar, int _Options, typename _Index>
               :template<typename InputIterators>
               :void SparseMatrix<Scalar,_Options,_Index>::setFromTriplets(const InputIterators& begin, const InputIterators& end)
               :{
               :  internal::set_from_triplets(begin, end, *this);
               :}
               :
               :/** \internal */
               :template<typename Scalar, int _Options, typename _Index>
               :void SparseMatrix<Scalar,_Options,_Index>::sumupDuplicates()
               :{
               :  eigen_assert(!isCompressed());
               :  // TODO, in practice we should be able to use m_innerNonZeros for that task
               :  Matrix<Index,Dynamic,1> wi(innerSize());
               :  wi.fill(-1);
               :  Index count = 0;
               :  // for each inner-vector, wi[inner_index] will hold the position of first element into the index/value buffers
               :  for(Index j=0; j<outerSize(); ++j)
               :  {
               :    Index start   = count;
               :    Index oldEnd  = m_outerIndex[j]+m_innerNonZeros[j];
               :    for(Index k=m_outerIndex[j]; k<oldEnd; ++k)
               :    {
               :      Index i = m_data.index(k);
               :      if(wi(i)>=start)
               :      {
               :        // we already meet this entry => accumulate it
               :        m_data.value(wi(i)) += m_data.value(k);
               :      }
               :      else
               :      {
               :        m_data.value(count) = m_data.value(k);
               :        m_data.index(count) = m_data.index(k);
               :        wi(i) = count;
               :        ++count;
               :      }
               :    }
               :    m_outerIndex[j] = start;
               :  }
               :  m_outerIndex[m_outerSize] = count;
               :
               :  // turn the matrix into compressed form
               :  std::free(m_innerNonZeros);
               :  m_innerNonZeros = 0;
               :  m_data.resize(m_outerIndex[m_outerSize]);
               :}
               :
               :template<typename Scalar, int _Options, typename _Index>
               :template<typename OtherDerived>
               :EIGEN_DONT_INLINE SparseMatrix<Scalar,_Options,_Index>& SparseMatrix<Scalar,_Options,_Index>::operator=(const SparseMatrixBase<OtherDerived>& other)
               :{
               :  EIGEN_STATIC_ASSERT((internal::is_same<Scalar, typename OtherDerived::Scalar>::value),
               :        YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY)
               :  
               :  const bool needToTranspose = (Flags & RowMajorBit) != (OtherDerived::Flags & RowMajorBit);
               :  if (needToTranspose)
               :  {
               :    // two passes algorithm:
               :    //  1 - compute the number of coeffs per dest inner vector
               :    //  2 - do the actual copy/eval
               :    // Since each coeff of the rhs has to be evaluated twice, let's evaluate it if needed
               :    typedef typename internal::nested<OtherDerived,2>::type OtherCopy;
               :    typedef typename internal::remove_all<OtherCopy>::type _OtherCopy;
               :    OtherCopy otherCopy(other.derived());
               :
               :    SparseMatrix dest(other.rows(),other.cols());
               :    Eigen::Map<Matrix<Index, Dynamic, 1> > (dest.m_outerIndex,dest.outerSize()).setZero();
               :
               :    // pass 1
               :    // FIXME the above copy could be merged with that pass
               :    for (Index j=0; j<otherCopy.outerSize(); ++j)
               :      for (typename _OtherCopy::InnerIterator it(otherCopy, j); it; ++it)
               :        ++dest.m_outerIndex[it.index()];
               :
               :    // prefix sum
               :    Index count = 0;
               :    Matrix<Index,Dynamic,1> positions(dest.outerSize());
               :    for (Index j=0; j<dest.outerSize(); ++j)
               :    {
               :      Index tmp = dest.m_outerIndex[j];
               :      dest.m_outerIndex[j] = count;
               :      positions[j] = count;
               :      count += tmp;
               :    }
               :    dest.m_outerIndex[dest.outerSize()] = count;
               :    // alloc
               :    dest.m_data.resize(count);
               :    // pass 2
               :    for (Index j=0; j<otherCopy.outerSize(); ++j)
               :    {
               :      for (typename _OtherCopy::InnerIterator it(otherCopy, j); it; ++it)
               :      {
               :        Index pos = positions[it.index()]++;
               :        dest.m_data.index(pos) = j;
               :        dest.m_data.value(pos) = it.value();
               :      }
               :    }
               :    this->swap(dest);
               :    return *this;
               :  }
               :  else
               :  {
               :    if(other.isRValue())
               :      initAssignment(other.derived());
               :    // there is no special optimization
               :    return Base::operator=(other.derived());
               :  }
               :}
               :
               :template<typename _Scalar, int _Options, typename _Index>
               :EIGEN_DONT_INLINE typename SparseMatrix<_Scalar,_Options,_Index>::Scalar& SparseMatrix<_Scalar,_Options,_Index>::insertUncompressed(Index row, Index col)
               :{
               :  eigen_assert(!isCompressed());
               :
               :  const Index outer = IsRowMajor ? row : col;
               :  const Index inner = IsRowMajor ? col : row;
               :
               :  Index room = m_outerIndex[outer+1] - m_outerIndex[outer];
               :  Index innerNNZ = m_innerNonZeros[outer];
               :  if(innerNNZ>=room)
               :  {
               :    // this inner vector is full, we need to reallocate the whole buffer :(
               :    reserve(SingletonVector(outer,std::max<Index>(2,innerNNZ)));
               :  }
               :
               :  Index startId = m_outerIndex[outer];
               :  Index p = startId + m_innerNonZeros[outer];
               :  while ( (p > startId) && (m_data.index(p-1) > inner) )
               :  {
               :    m_data.index(p) = m_data.index(p-1);
               :    m_data.value(p) = m_data.value(p-1);
               :    --p;
               :  }
               :  eigen_assert((p<=startId || m_data.index(p-1)!=inner) && "you cannot insert an element that already exist, you must call coeffRef to this end");
               :
               :  m_innerNonZeros[outer]++;
               :
               :  m_data.index(p) = inner;
               :  return (m_data.value(p) = 0);
               :}
               :
               :template<typename _Scalar, int _Options, typename _Index>
               :EIGEN_DONT_INLINE typename SparseMatrix<_Scalar,_Options,_Index>::Scalar& SparseMatrix<_Scalar,_Options,_Index>::insertCompressed(Index row, Index col)
               :{
               :  eigen_assert(isCompressed());
               :
               :  const Index outer = IsRowMajor ? row : col;
               :  const Index inner = IsRowMajor ? col : row;
               :
               :  Index previousOuter = outer;
               :  if (m_outerIndex[outer+1]==0)
               :  {
               :    // we start a new inner vector
               :    while (previousOuter>=0 && m_outerIndex[previousOuter]==0)
               :    {
               :      m_outerIndex[previousOuter] = static_cast<Index>(m_data.size());
               :      --previousOuter;
               :    }
               :    m_outerIndex[outer+1] = m_outerIndex[outer];
               :  }
               :
               :  // here we have to handle the tricky case where the outerIndex array
               :  // starts with: [ 0 0 0 0 0 1 ...] and we are inserted in, e.g.,
               :  // the 2nd inner vector...
               :  bool isLastVec = (!(previousOuter==-1 && m_data.size()!=0))
               :                && (size_t(m_outerIndex[outer+1]) == m_data.size());
               :
               :  size_t startId = m_outerIndex[outer];
               :  // FIXME let's make sure sizeof(long int) == sizeof(size_t)
               :  size_t p = m_outerIndex[outer+1];
               :  ++m_outerIndex[outer+1];
               :
               :  double reallocRatio = 1;
               :  if (m_data.allocatedSize()<=m_data.size())
               :  {
               :    // if there is no preallocated memory, let's reserve a minimum of 32 elements
               :    if (m_data.size()==0)
               :    {
               :      m_data.reserve(32);
               :    }
               :    else
               :    {
               :      // we need to reallocate the data, to reduce multiple reallocations
               :      // we use a smart resize algorithm based on the current filling ratio
               :      // in addition, we use double to avoid integers overflows
               :      double nnzEstimate = double(m_outerIndex[outer])*double(m_outerSize)/double(outer+1);
               :      reallocRatio = (nnzEstimate-double(m_data.size()))/double(m_data.size());
               :      // furthermore we bound the realloc ratio to:
               :      //   1) reduce multiple minor realloc when the matrix is almost filled
               :      //   2) avoid to allocate too much memory when the matrix is almost empty
               :      reallocRatio = (std::min)((std::max)(reallocRatio,1.5),8.);
               :    }
               :  }
               :  m_data.resize(m_data.size()+1,reallocRatio);
               :
               :  if (!isLastVec)
               :  {
               :    if (previousOuter==-1)
               :    {
               :      // oops wrong guess.
               :      // let's correct the outer offsets
               :      for (Index k=0; k<=(outer+1); ++k)
               :        m_outerIndex[k] = 0;
               :      Index k=outer+1;
               :      while(m_outerIndex[k]==0)
               :        m_outerIndex[k++] = 1;
               :      while (k<=m_outerSize && m_outerIndex[k]!=0)
               :        m_outerIndex[k++]++;
               :      p = 0;
               :      --k;
               :      k = m_outerIndex[k]-1;
               :      while (k>0)
               :      {
               :        m_data.index(k) = m_data.index(k-1);
               :        m_data.value(k) = m_data.value(k-1);
               :        k--;
               :      }
               :    }
               :    else
               :    {
               :      // we are not inserting into the last inner vec
               :      // update outer indices:
               :      Index j = outer+2;
               :      while (j<=m_outerSize && m_outerIndex[j]!=0)
               :        m_outerIndex[j++]++;
               :      --j;
               :      // shift data of last vecs:
               :      Index k = m_outerIndex[j]-1;
               :      while (k>=Index(p))
               :      {
               :        m_data.index(k) = m_data.index(k-1);
               :        m_data.value(k) = m_data.value(k-1);
               :        k--;
               :      }
               :    }
               :  }
               :
               :  while ( (p > startId) && (m_data.index(p-1) > inner) )
               :  {
               :    m_data.index(p) = m_data.index(p-1);
               :    m_data.value(p) = m_data.value(p-1);
               :    --p;
               :  }
               :
               :  m_data.index(p) = inner;
               :  return (m_data.value(p) = 0);
               :}
               :
               :} // end namespace Eigen
               :
               :#endif // EIGEN_SPARSEMATRIX_H
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/SparseCore/SparseColEtree.h"
 * 
 *      1  1.3889
 */


               :// This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2012 Dsir Nuentsa-Wakam <desire.nuentsa_wakam@inria.fr>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :
               :/* 
               : 
               : * NOTE: This file is the modified version of sp_coletree.c file in SuperLU 
               : 
               : * -- SuperLU routine (version 3.1) --
               : * Univ. of California Berkeley, Xerox Palo Alto Research Center,
               : * and Lawrence Berkeley National Lab.
               : * August 1, 2008
               : *
               : * Copyright (c) 1994 by Xerox Corporation.  All rights reserved.
               : *
               : * THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY
               : * EXPRESSED OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.
               : *
               : * Permission is hereby granted to use or copy this program for any
               : * purpose, provided the above notices are retained on all copies.
               : * Permission to modify the code and to distribute modified code is
               : * granted, provided the above notices are retained, and a notice that
               : * the code was modified is included with the above copyright notice.
               : */
               :#ifndef SPARSE_COLETREE_H
               :#define SPARSE_COLETREE_H
               :
               :namespace Eigen {
               :
               :namespace internal {
               :
               :/** Find the root of the tree/set containing the vertex i : Use Path halving */ 
               :template<typename Index, typename IndexVector>
               :Index etree_find (Index i, IndexVector& pp)
               :{
               :  Index p = pp(i); // Parent 
               :  Index gp = pp(p); // Grand parent 
               :  while (gp != p) 
               :  {
               :    pp(i) = gp; // Parent pointer on find path is changed to former grand parent
               :    i = gp; 
               :    p = pp(i);
               :    gp = pp(p);
               :  }
               :  return p; 
               :}
               :
               :/** Compute the column elimination tree of a sparse matrix
               :  * \param mat The matrix in column-major format. 
               :  * \param parent The elimination tree
               :  * \param firstRowElt The column index of the first element in each row
               :  * \param perm The permutation to apply to the column of \b mat
               :  */
               :template <typename MatrixType, typename IndexVector>
               :int coletree(const MatrixType& mat, IndexVector& parent, IndexVector& firstRowElt, typename MatrixType::Index *perm=0) /* int Eigen::internal::coletree<Eigen::SparseMatrix<double, 0, int>, Eigen::Matrix<int, -1, 1, 0, -1, 1> >(Eigen::SparseMatrix<double, 0, int> const&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::Matrix<int, -1, 1, 0, -1, 1>&, Eigen::SparseMatrix<double, 0, int>::Index*) total:      1  1.3889 */
               :{
               :  typedef typename MatrixType::Index Index;
               :  Index nc = mat.cols(); // Number of columns 
               :  Index m = mat.rows();
               :  Index diagSize = (std::min)(nc,m);
               :  IndexVector root(nc); // root of subtree of etree 
               :  root.setZero();
               :  IndexVector pp(nc); // disjoint sets 
               :  pp.setZero(); // Initialize disjoint sets 
               :  parent.resize(mat.cols());
               :  //Compute first nonzero column in each row 
               :  Index row,col; 
               :  firstRowElt.resize(m);
               :  firstRowElt.setConstant(nc);
               :  firstRowElt.segment(0, diagSize).setLinSpaced(diagSize, 0, diagSize-1);
               :  bool found_diag;
               :  for (col = 0; col < nc; col++)
               :  {
               :    Index pcol = col;
               :    if(perm) pcol  = perm[col];
               :    for (typename MatrixType::InnerIterator it(mat, pcol); it; ++it)
               :    { 
               :      row = it.row();
               :      firstRowElt(row) = (std::min)(firstRowElt(row), col);
               :    }
               :  }
               :  /* Compute etree by Liu's algorithm for symmetric matrices,
               :          except use (firstRowElt[r],c) in place of an edge (r,c) of A.
               :    Thus each row clique in A'*A is replaced by a star
               :    centered at its first vertex, which has the same fill. */
               :  Index rset, cset, rroot; 
               :  for (col = 0; col < nc; col++) 
               :  {
               :    found_diag = col>=m;
               :    pp(col) = col; 
               :    cset = col; 
               :    root(cset) = col; 
               :    parent(col) = nc; 
               :    /* The diagonal element is treated here even if it does not exist in the matrix
               :     * hence the loop is executed once more */ 
               :    Index pcol = col;
               :    if(perm) pcol  = perm[col];
               :    for (typename MatrixType::InnerIterator it(mat, pcol); it||!found_diag; ++it)
               :    { //  A sequence of interleaved find and union is performed 
               :      Index i = col;
               :      if(it) i = it.index();
     1  1.3889 :      if (i == col) found_diag = true;
               :      
               :      row = firstRowElt(i);
               :      if (row >= col) continue; 
               :      rset = internal::etree_find(row, pp); // Find the name of the set containing row
               :      rroot = root(rset);
               :      if (rroot != col) 
               :      {
               :        parent(rroot) = col; 
               :        pp(cset) = rset; 
               :        cset = rset; 
               :        root(cset) = col; 
               :      }
               :    }
               :  }
               :  return 0;  
               :}
               :
               :/** 
               :  * Depth-first search from vertex n.  No recursion.
               :  * This routine was contributed by Cdric Doucet, CEDRAT Group, Meylan, France.
               :*/
               :template <typename Index, typename IndexVector>
               :void nr_etdfs (Index n, IndexVector& parent, IndexVector& first_kid, IndexVector& next_kid, IndexVector& post, Index postnum)
               :{
               :  Index current = n, first, next;
               :  while (postnum != n) 
               :  {
               :    // No kid for the current node
               :    first = first_kid(current);
               :    
               :    // no kid for the current node
               :    if (first == -1) 
               :    {
               :      // Numbering this node because it has no kid 
               :      post(current) = postnum++;
               :      
               :      // looking for the next kid 
               :      next = next_kid(current); 
               :      while (next == -1) 
               :      {
               :        // No more kids : back to the parent node
               :        current = parent(current); 
               :        // numbering the parent node 
               :        post(current) = postnum++;
               :        
               :        // Get the next kid 
               :        next = next_kid(current); 
               :      }
               :      // stopping criterion 
               :      if (postnum == n+1) return; 
               :      
               :      // Updating current node 
               :      current = next; 
               :    }
               :    else 
               :    {
               :      current = first; 
               :    }
               :  }
               :}
               :
               :
               :/**
               :  * \brief Post order a tree 
               :  * \param n the number of nodes
               :  * \param parent Input tree
               :  * \param post postordered tree
               :  */
               :template <typename Index, typename IndexVector>
               :void treePostorder(Index n, IndexVector& parent, IndexVector& post)
               :{
               :  IndexVector first_kid, next_kid; // Linked list of children 
               :  Index postnum; 
               :  // Allocate storage for working arrays and results 
               :  first_kid.resize(n+1); 
               :  next_kid.setZero(n+1);
               :  post.setZero(n+1);
               :  
               :  // Set up structure describing children
               :  Index v, dad; 
               :  first_kid.setConstant(-1); 
               :  for (v = n-1; v >= 0; v--) 
               :  {
               :    dad = parent(v);
               :    next_kid(v) = first_kid(dad); 
               :    first_kid(dad) = v; 
               :  }
               :  
               :  // Depth-first search from dummy root vertex #n
               :  postnum = 0; 
               :  internal::nr_etdfs(n, parent, first_kid, next_kid, post, postnum);
               :}
               :
               :} // end namespace internal
               :
               :} // end namespace Eigen
               :
               :#endif // SPARSE_COLETREE_H
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/Core/PlainObjectBase.h"
 * 
 *      1  1.3889
 */


               :// This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2008-2009 Gael Guennebaud <gael.guennebaud@inria.fr>
               :// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :#ifndef EIGEN_DENSESTORAGEBASE_H
               :#define EIGEN_DENSESTORAGEBASE_H
               :
               :#if defined(EIGEN_INITIALIZE_MATRICES_BY_ZERO)
               :# define EIGEN_INITIALIZE_COEFFS
               :# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED for(int i=0;i<base().size();++i) coeffRef(i)=Scalar(0);
               :#elif defined(EIGEN_INITIALIZE_MATRICES_BY_NAN)
               :# define EIGEN_INITIALIZE_COEFFS
               :# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED for(int i=0;i<base().size();++i) coeffRef(i)=std::numeric_limits<Scalar>::quiet_NaN();
               :#else
               :# undef EIGEN_INITIALIZE_COEFFS
               :# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
               :#endif
               :
               :namespace Eigen {
               :
               :namespace internal {
               :
               :template<int MaxSizeAtCompileTime> struct check_rows_cols_for_overflow {
               :  template<typename Index>
               :  static EIGEN_ALWAYS_INLINE void run(Index, Index)
               :  {
               :  }
               :};
               :
               :template<> struct check_rows_cols_for_overflow<Dynamic> {
               :  template<typename Index>
               :  static EIGEN_ALWAYS_INLINE void run(Index rows, Index cols)
               :  {
               :    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
               :    // we assume Index is signed
               :    Index max_index = (size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
               :    bool error = (rows == 0 || cols == 0) ? false
               :               : (rows > max_index / cols);
               :    if (error)
               :      throw_std_bad_alloc();
               :  }
               :};
               :
               :template <typename Derived,
               :          typename OtherDerived = Derived,
               :          bool IsVector = bool(Derived::IsVectorAtCompileTime) && bool(OtherDerived::IsVectorAtCompileTime)>
               :struct conservative_resize_like_impl;
               :
               :template<typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers> struct matrix_swap_impl;
               :
               :} // end namespace internal
               :
               :/** \class PlainObjectBase
               :  * \brief %Dense storage base class for matrices and arrays.
               :  *
               :  * This class can be extended with the help of the plugin mechanism described on the page
               :  * \ref TopicCustomizingEigen by defining the preprocessor symbol \c EIGEN_PLAINOBJECTBASE_PLUGIN.
               :  *
               :  * \sa \ref TopicClassHierarchy
               :  */
               :#ifdef EIGEN_PARSED_BY_DOXYGEN
               :namespace internal {
               :
               :// this is a warkaround to doxygen not being able to understand the inheritence logic
               :// when it is hidden by the dense_xpr_base helper struct.
               :template<typename Derived> struct dense_xpr_base_dispatcher_for_doxygen;// : public MatrixBase<Derived> {};
               :/** This class is just a workaround for Doxygen and it does not not actually exist. */
               :template<typename _Scalar, int _Rows, int _Cols, int _Options, int _MaxRows, int _MaxCols>
               :struct dense_xpr_base_dispatcher_for_doxygen<Matrix<_Scalar, _Rows, _Cols, _Options, _MaxRows, _MaxCols> >
               :    : public MatrixBase<Matrix<_Scalar, _Rows, _Cols, _Options, _MaxRows, _MaxCols> > {};
               :/** This class is just a workaround for Doxygen and it does not not actually exist. */
               :template<typename _Scalar, int _Rows, int _Cols, int _Options, int _MaxRows, int _MaxCols>
               :struct dense_xpr_base_dispatcher_for_doxygen<Array<_Scalar, _Rows, _Cols, _Options, _MaxRows, _MaxCols> >
               :    : public ArrayBase<Array<_Scalar, _Rows, _Cols, _Options, _MaxRows, _MaxCols> > {};
               :
               :} // namespace internal
               :
               :template<typename Derived>
               :class PlainObjectBase : public internal::dense_xpr_base_dispatcher_for_doxygen<Derived>
               :#else
               :template<typename Derived>
               :class PlainObjectBase : public internal::dense_xpr_base<Derived>::type
               :#endif
               :{
               :  public:
               :    enum { Options = internal::traits<Derived>::Options };
               :    typedef typename internal::dense_xpr_base<Derived>::type Base;
               :
               :    typedef typename internal::traits<Derived>::StorageKind StorageKind;
               :    typedef typename internal::traits<Derived>::Index Index;
               :    typedef typename internal::traits<Derived>::Scalar Scalar;
               :    typedef typename internal::packet_traits<Scalar>::type PacketScalar;
               :    typedef typename NumTraits<Scalar>::Real RealScalar;
               :    typedef Derived DenseType;
               :
               :    using Base::RowsAtCompileTime;
               :    using Base::ColsAtCompileTime;
               :    using Base::SizeAtCompileTime;
               :    using Base::MaxRowsAtCompileTime;
               :    using Base::MaxColsAtCompileTime;
               :    using Base::MaxSizeAtCompileTime;
               :    using Base::IsVectorAtCompileTime;
               :    using Base::Flags;
               :
               :    template<typename PlainObjectType, int MapOptions, typename StrideType> friend class Eigen::Map;
               :    friend  class Eigen::Map<Derived, Unaligned>;
               :    typedef Eigen::Map<Derived, Unaligned>  MapType;
               :    friend  class Eigen::Map<const Derived, Unaligned>;
               :    typedef const Eigen::Map<const Derived, Unaligned> ConstMapType;
               :    friend  class Eigen::Map<Derived, Aligned>;
               :    typedef Eigen::Map<Derived, Aligned> AlignedMapType;
               :    friend  class Eigen::Map<const Derived, Aligned>;
               :    typedef const Eigen::Map<const Derived, Aligned> ConstAlignedMapType;
               :    template<typename StrideType> struct StridedMapType { typedef Eigen::Map<Derived, Unaligned, StrideType> type; };
               :    template<typename StrideType> struct StridedConstMapType { typedef Eigen::Map<const Derived, Unaligned, StrideType> type; };
               :    template<typename StrideType> struct StridedAlignedMapType { typedef Eigen::Map<Derived, Aligned, StrideType> type; };
               :    template<typename StrideType> struct StridedConstAlignedMapType { typedef Eigen::Map<const Derived, Aligned, StrideType> type; };
               :
               :  protected:
               :    DenseStorage<Scalar, Base::MaxSizeAtCompileTime, Base::RowsAtCompileTime, Base::ColsAtCompileTime, Options> m_storage;
               :
               :  public:
               :    enum { NeedsToAlign = SizeAtCompileTime != Dynamic && (internal::traits<Derived>::Flags & AlignedBit) != 0 };
               :    EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)
               :
               :    Base& base() { return *static_cast<Base*>(this); }
               :    const Base& base() const { return *static_cast<const Base*>(this); }
               :
               :    EIGEN_STRONG_INLINE Index rows() const { return m_storage.rows(); }
               :    EIGEN_STRONG_INLINE Index cols() const { return m_storage.cols(); }
               :
               :    EIGEN_STRONG_INLINE const Scalar& coeff(Index rowId, Index colId) const
               :    {
               :      if(Flags & RowMajorBit)
               :        return m_storage.data()[colId + rowId * m_storage.cols()];
               :      else // column-major
               :        return m_storage.data()[rowId + colId * m_storage.rows()];
               :    }
               :
               :    EIGEN_STRONG_INLINE const Scalar& coeff(Index index) const
               :    {
               :      return m_storage.data()[index];
               :    }
               :
               :    EIGEN_STRONG_INLINE Scalar& coeffRef(Index rowId, Index colId)
               :    {
               :      if(Flags & RowMajorBit)
               :        return m_storage.data()[colId + rowId * m_storage.cols()];
               :      else // column-major
     1  1.3889 :        return m_storage.data()[rowId + colId * m_storage.rows()];
               :    }
               :
               :    EIGEN_STRONG_INLINE Scalar& coeffRef(Index index)
               :    {
               :      return m_storage.data()[index];
               :    }
               :
               :    EIGEN_STRONG_INLINE const Scalar& coeffRef(Index rowId, Index colId) const
               :    {
               :      if(Flags & RowMajorBit)
               :        return m_storage.data()[colId + rowId * m_storage.cols()];
               :      else // column-major
               :        return m_storage.data()[rowId + colId * m_storage.rows()];
               :    }
               :
               :    EIGEN_STRONG_INLINE const Scalar& coeffRef(Index index) const
               :    {
               :      return m_storage.data()[index];
               :    }
               :
               :    /** \internal */
               :    template<int LoadMode>
               :    EIGEN_STRONG_INLINE PacketScalar packet(Index rowId, Index colId) const
               :    {
               :      return internal::ploadt<PacketScalar, LoadMode>
               :               (m_storage.data() + (Flags & RowMajorBit
               :                                   ? colId + rowId * m_storage.cols()
               :                                   : rowId + colId * m_storage.rows()));
               :    }
               :
               :    /** \internal */
               :    template<int LoadMode>
               :    EIGEN_STRONG_INLINE PacketScalar packet(Index index) const
               :    {
               :      return internal::ploadt<PacketScalar, LoadMode>(m_storage.data() + index);
               :    }
               :
               :    /** \internal */
               :    template<int StoreMode>
               :    EIGEN_STRONG_INLINE void writePacket(Index rowId, Index colId, const PacketScalar& val)
               :    {
               :      internal::pstoret<Scalar, PacketScalar, StoreMode>
               :              (m_storage.data() + (Flags & RowMajorBit
               :                                   ? colId + rowId * m_storage.cols()
               :                                   : rowId + colId * m_storage.rows()), val);
               :    }
               :
               :    /** \internal */
               :    template<int StoreMode>
               :    EIGEN_STRONG_INLINE void writePacket(Index index, const PacketScalar& val)
               :    {
               :      internal::pstoret<Scalar, PacketScalar, StoreMode>(m_storage.data() + index, val);
               :    }
               :
               :    /** \returns a const pointer to the data array of this matrix */
               :    EIGEN_STRONG_INLINE const Scalar *data() const
               :    { return m_storage.data(); }
               :
               :    /** \returns a pointer to the data array of this matrix */
               :    EIGEN_STRONG_INLINE Scalar *data()
               :    { return m_storage.data(); }
               :
               :    /** Resizes \c *this to a \a rows x \a cols matrix.
               :      *
               :      * This method is intended for dynamic-size matrices, although it is legal to call it on any
               :      * matrix as long as fixed dimensions are left unchanged. If you only want to change the number
               :      * of rows and/or of columns, you can use resize(NoChange_t, Index), resize(Index, NoChange_t).
               :      *
               :      * If the current number of coefficients of \c *this exactly matches the
               :      * product \a rows * \a cols, then no memory allocation is performed and
               :      * the current values are left unchanged. In all other cases, including
               :      * shrinking, the data is reallocated and all previous values are lost.
               :      *
               :      * Example: \include Matrix_resize_int_int.cpp
               :      * Output: \verbinclude Matrix_resize_int_int.out
               :      *
               :      * \sa resize(Index) for vectors, resize(NoChange_t, Index), resize(Index, NoChange_t)
               :      */
               :    EIGEN_STRONG_INLINE void resize(Index nbRows, Index nbCols)
               :    {
               :      eigen_assert(   EIGEN_IMPLIES(RowsAtCompileTime!=Dynamic,nbRows==RowsAtCompileTime)
               :                   && EIGEN_IMPLIES(ColsAtCompileTime!=Dynamic,nbCols==ColsAtCompileTime)
               :                   && EIGEN_IMPLIES(RowsAtCompileTime==Dynamic && MaxRowsAtCompileTime!=Dynamic,nbRows<=MaxRowsAtCompileTime)
               :                   && EIGEN_IMPLIES(ColsAtCompileTime==Dynamic && MaxColsAtCompileTime!=Dynamic,nbCols<=MaxColsAtCompileTime)
               :                   && nbRows>=0 && nbCols>=0 && "Invalid sizes when resizing a matrix or array.");
               :      internal::check_rows_cols_for_overflow<MaxSizeAtCompileTime>::run(nbRows, nbCols);
               :      #ifdef EIGEN_INITIALIZE_COEFFS
               :        Index size = nbRows*nbCols;
               :        bool size_changed = size != this->size();
               :        m_storage.resize(size, nbRows, nbCols);
               :        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
               :      #else
               :        internal::check_rows_cols_for_overflow<MaxSizeAtCompileTime>::run(nbRows, nbCols);
               :        m_storage.resize(nbRows*nbCols, nbRows, nbCols);
               :      #endif
               :    }
               :
               :    /** Resizes \c *this to a vector of length \a size
               :      *
               :      * \only_for_vectors. This method does not work for
               :      * partially dynamic matrices when the static dimension is anything other
               :      * than 1. For example it will not work with Matrix<double, 2, Dynamic>.
               :      *
               :      * Example: \include Matrix_resize_int.cpp
               :      * Output: \verbinclude Matrix_resize_int.out
               :      *
               :      * \sa resize(Index,Index), resize(NoChange_t, Index), resize(Index, NoChange_t)
               :      */
               :    inline void resize(Index size)
               :    {
               :      EIGEN_STATIC_ASSERT_VECTOR_ONLY(PlainObjectBase)
               :      eigen_assert(((SizeAtCompileTime == Dynamic && (MaxSizeAtCompileTime==Dynamic || size<=MaxSizeAtCompileTime)) || SizeAtCompileTime == size) && size>=0);
               :      #ifdef EIGEN_INITIALIZE_COEFFS
               :        bool size_changed = size != this->size();
               :      #endif
               :      if(RowsAtCompileTime == 1)
               :        m_storage.resize(size, 1, size);
               :      else
               :        m_storage.resize(size, size, 1);
               :      #ifdef EIGEN_INITIALIZE_COEFFS
               :        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
               :      #endif
               :    }
               :
               :    /** Resizes the matrix, changing only the number of columns. For the parameter of type NoChange_t, just pass the special value \c NoChange
               :      * as in the example below.
               :      *
               :      * Example: \include Matrix_resize_NoChange_int.cpp
               :      * Output: \verbinclude Matrix_resize_NoChange_int.out
               :      *
               :      * \sa resize(Index,Index)
               :      */
               :    inline void resize(NoChange_t, Index nbCols)
               :    {
               :      resize(rows(), nbCols);
               :    }
               :
               :    /** Resizes the matrix, changing only the number of rows. For the parameter of type NoChange_t, just pass the special value \c NoChange
               :      * as in the example below.
               :      *
               :      * Example: \include Matrix_resize_int_NoChange.cpp
               :      * Output: \verbinclude Matrix_resize_int_NoChange.out
               :      *
               :      * \sa resize(Index,Index)
               :      */
               :    inline void resize(Index nbRows, NoChange_t)
               :    {
               :      resize(nbRows, cols());
               :    }
               :
               :    /** Resizes \c *this to have the same dimensions as \a other.
               :      * Takes care of doing all the checking that's needed.
               :      *
               :      * Note that copying a row-vector into a vector (and conversely) is allowed.
               :      * The resizing, if any, is then done in the appropriate way so that row-vectors
               :      * remain row-vectors and vectors remain vectors.
               :      */
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE void resizeLike(const EigenBase<OtherDerived>& _other)
               :    {
               :      const OtherDerived& other = _other.derived();
               :      internal::check_rows_cols_for_overflow<MaxSizeAtCompileTime>::run(other.rows(), other.cols());
               :      const Index othersize = other.rows()*other.cols();
               :      if(RowsAtCompileTime == 1)
               :      {
               :        eigen_assert(other.rows() == 1 || other.cols() == 1);
               :        resize(1, othersize);
               :      }
               :      else if(ColsAtCompileTime == 1)
               :      {
               :        eigen_assert(other.rows() == 1 || other.cols() == 1);
               :        resize(othersize, 1);
               :      }
               :      else resize(other.rows(), other.cols());
               :    }
               :
               :    /** Resizes the matrix to \a rows x \a cols while leaving old values untouched.
               :      *
               :      * The method is intended for matrices of dynamic size. If you only want to change the number
               :      * of rows and/or of columns, you can use conservativeResize(NoChange_t, Index) or
               :      * conservativeResize(Index, NoChange_t).
               :      *
               :      * Matrices are resized relative to the top-left element. In case values need to be 
               :      * appended to the matrix they will be uninitialized.
               :      */
               :    EIGEN_STRONG_INLINE void conservativeResize(Index nbRows, Index nbCols)
               :    {
               :      internal::conservative_resize_like_impl<Derived>::run(*this, nbRows, nbCols);
               :    }
               :
               :    /** Resizes the matrix to \a rows x \a cols while leaving old values untouched.
               :      *
               :      * As opposed to conservativeResize(Index rows, Index cols), this version leaves
               :      * the number of columns unchanged.
               :      *
               :      * In case the matrix is growing, new rows will be uninitialized.
               :      */
               :    EIGEN_STRONG_INLINE void conservativeResize(Index nbRows, NoChange_t)
               :    {
               :      // Note: see the comment in conservativeResize(Index,Index)
               :      conservativeResize(nbRows, cols());
               :    }
               :
               :    /** Resizes the matrix to \a rows x \a cols while leaving old values untouched.
               :      *
               :      * As opposed to conservativeResize(Index rows, Index cols), this version leaves
               :      * the number of rows unchanged.
               :      *
               :      * In case the matrix is growing, new columns will be uninitialized.
               :      */
               :    EIGEN_STRONG_INLINE void conservativeResize(NoChange_t, Index nbCols)
               :    {
               :      // Note: see the comment in conservativeResize(Index,Index)
               :      conservativeResize(rows(), nbCols);
               :    }
               :
               :    /** Resizes the vector to \a size while retaining old values.
               :      *
               :      * \only_for_vectors. This method does not work for
               :      * partially dynamic matrices when the static dimension is anything other
               :      * than 1. For example it will not work with Matrix<double, 2, Dynamic>.
               :      *
               :      * When values are appended, they will be uninitialized.
               :      */
               :    EIGEN_STRONG_INLINE void conservativeResize(Index size)
               :    {
               :      internal::conservative_resize_like_impl<Derived>::run(*this, size);
               :    }
               :
               :    /** Resizes the matrix to \a rows x \a cols of \c other, while leaving old values untouched.
               :      *
               :      * The method is intended for matrices of dynamic size. If you only want to change the number
               :      * of rows and/or of columns, you can use conservativeResize(NoChange_t, Index) or
               :      * conservativeResize(Index, NoChange_t).
               :      *
               :      * Matrices are resized relative to the top-left element. In case values need to be 
               :      * appended to the matrix they will copied from \c other.
               :      */
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE void conservativeResizeLike(const DenseBase<OtherDerived>& other)
               :    {
               :      internal::conservative_resize_like_impl<Derived,OtherDerived>::run(*this, other);
               :    }
               :
               :    /** This is a special case of the templated operator=. Its purpose is to
               :      * prevent a default operator= from hiding the templated operator=.
               :      */
               :    EIGEN_STRONG_INLINE Derived& operator=(const PlainObjectBase& other)
               :    {
               :      return _set(other);
               :    }
               :
               :    /** \sa MatrixBase::lazyAssign() */
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE Derived& lazyAssign(const DenseBase<OtherDerived>& other)
               :    {
               :      _resize_to_match(other);
               :      return Base::lazyAssign(other.derived());
               :    }
               :
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE Derived& operator=(const ReturnByValue<OtherDerived>& func)
               :    {
               :      resize(func.rows(), func.cols());
               :      return Base::operator=(func);
               :    }
               :
               :    EIGEN_STRONG_INLINE PlainObjectBase() : m_storage()
               :    {
               ://       _check_template_params();
               ://       EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
               :    }
               :
               :#ifndef EIGEN_PARSED_BY_DOXYGEN
               :    // FIXME is it still needed ?
               :    /** \internal */
               :    PlainObjectBase(internal::constructor_without_unaligned_array_assert)
               :      : m_storage(internal::constructor_without_unaligned_array_assert())
               :    {
               ://       _check_template_params(); EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
               :    }
               :#endif
               :
               :    EIGEN_STRONG_INLINE PlainObjectBase(Index a_size, Index nbRows, Index nbCols)
               :      : m_storage(a_size, nbRows, nbCols)
               :    {
               ://       _check_template_params();
               ://       EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
               :    }
               :
               :    /** \copydoc MatrixBase::operator=(const EigenBase<OtherDerived>&)
               :      */
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE Derived& operator=(const EigenBase<OtherDerived> &other)
               :    {
               :      _resize_to_match(other);
               :      Base::operator=(other.derived());
               :      return this->derived();
               :    }
               :
               :    /** \sa MatrixBase::operator=(const EigenBase<OtherDerived>&) */
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE PlainObjectBase(const EigenBase<OtherDerived> &other)
               :      : m_storage(other.derived().rows() * other.derived().cols(), other.derived().rows(), other.derived().cols())
               :    {
               :      _check_template_params();
               :      internal::check_rows_cols_for_overflow<MaxSizeAtCompileTime>::run(other.derived().rows(), other.derived().cols());
               :      Base::operator=(other.derived());
               :    }
               :
               :    /** \name Map
               :      * These are convenience functions returning Map objects. The Map() static functions return unaligned Map objects,
               :      * while the AlignedMap() functions return aligned Map objects and thus should be called only with 16-byte-aligned
               :      * \a data pointers.
               :      *
               :      * \see class Map
               :      */
               :    //@{
               :    static inline ConstMapType Map(const Scalar* data)
               :    { return ConstMapType(data); }
               :    static inline MapType Map(Scalar* data)
               :    { return MapType(data); }
               :    static inline ConstMapType Map(const Scalar* data, Index size)
               :    { return ConstMapType(data, size); }
               :    static inline MapType Map(Scalar* data, Index size)
               :    { return MapType(data, size); }
               :    static inline ConstMapType Map(const Scalar* data, Index rows, Index cols)
               :    { return ConstMapType(data, rows, cols); }
               :    static inline MapType Map(Scalar* data, Index rows, Index cols)
               :    { return MapType(data, rows, cols); }
               :
               :    static inline ConstAlignedMapType MapAligned(const Scalar* data)
               :    { return ConstAlignedMapType(data); }
               :    static inline AlignedMapType MapAligned(Scalar* data)
               :    { return AlignedMapType(data); }
               :    static inline ConstAlignedMapType MapAligned(const Scalar* data, Index size)
               :    { return ConstAlignedMapType(data, size); }
               :    static inline AlignedMapType MapAligned(Scalar* data, Index size)
               :    { return AlignedMapType(data, size); }
               :    static inline ConstAlignedMapType MapAligned(const Scalar* data, Index rows, Index cols)
               :    { return ConstAlignedMapType(data, rows, cols); }
               :    static inline AlignedMapType MapAligned(Scalar* data, Index rows, Index cols)
               :    { return AlignedMapType(data, rows, cols); }
               :
               :    template<int Outer, int Inner>
               :    static inline typename StridedConstMapType<Stride<Outer, Inner> >::type Map(const Scalar* data, const Stride<Outer, Inner>& stride)
               :    { return typename StridedConstMapType<Stride<Outer, Inner> >::type(data, stride); }
               :    template<int Outer, int Inner>
               :    static inline typename StridedMapType<Stride<Outer, Inner> >::type Map(Scalar* data, const Stride<Outer, Inner>& stride)
               :    { return typename StridedMapType<Stride<Outer, Inner> >::type(data, stride); }
               :    template<int Outer, int Inner>
               :    static inline typename StridedConstMapType<Stride<Outer, Inner> >::type Map(const Scalar* data, Index size, const Stride<Outer, Inner>& stride)
               :    { return typename StridedConstMapType<Stride<Outer, Inner> >::type(data, size, stride); }
               :    template<int Outer, int Inner>
               :    static inline typename StridedMapType<Stride<Outer, Inner> >::type Map(Scalar* data, Index size, const Stride<Outer, Inner>& stride)
               :    { return typename StridedMapType<Stride<Outer, Inner> >::type(data, size, stride); }
               :    template<int Outer, int Inner>
               :    static inline typename StridedConstMapType<Stride<Outer, Inner> >::type Map(const Scalar* data, Index rows, Index cols, const Stride<Outer, Inner>& stride)
               :    { return typename StridedConstMapType<Stride<Outer, Inner> >::type(data, rows, cols, stride); }
               :    template<int Outer, int Inner>
               :    static inline typename StridedMapType<Stride<Outer, Inner> >::type Map(Scalar* data, Index rows, Index cols, const Stride<Outer, Inner>& stride)
               :    { return typename StridedMapType<Stride<Outer, Inner> >::type(data, rows, cols, stride); }
               :
               :    template<int Outer, int Inner>
               :    static inline typename StridedConstAlignedMapType<Stride<Outer, Inner> >::type MapAligned(const Scalar* data, const Stride<Outer, Inner>& stride)
               :    { return typename StridedConstAlignedMapType<Stride<Outer, Inner> >::type(data, stride); }
               :    template<int Outer, int Inner>
               :    static inline typename StridedAlignedMapType<Stride<Outer, Inner> >::type MapAligned(Scalar* data, const Stride<Outer, Inner>& stride)
               :    { return typename StridedAlignedMapType<Stride<Outer, Inner> >::type(data, stride); }
               :    template<int Outer, int Inner>
               :    static inline typename StridedConstAlignedMapType<Stride<Outer, Inner> >::type MapAligned(const Scalar* data, Index size, const Stride<Outer, Inner>& stride)
               :    { return typename StridedConstAlignedMapType<Stride<Outer, Inner> >::type(data, size, stride); }
               :    template<int Outer, int Inner>
               :    static inline typename StridedAlignedMapType<Stride<Outer, Inner> >::type MapAligned(Scalar* data, Index size, const Stride<Outer, Inner>& stride)
               :    { return typename StridedAlignedMapType<Stride<Outer, Inner> >::type(data, size, stride); }
               :    template<int Outer, int Inner>
               :    static inline typename StridedConstAlignedMapType<Stride<Outer, Inner> >::type MapAligned(const Scalar* data, Index rows, Index cols, const Stride<Outer, Inner>& stride)
               :    { return typename StridedConstAlignedMapType<Stride<Outer, Inner> >::type(data, rows, cols, stride); }
               :    template<int Outer, int Inner>
               :    static inline typename StridedAlignedMapType<Stride<Outer, Inner> >::type MapAligned(Scalar* data, Index rows, Index cols, const Stride<Outer, Inner>& stride)
               :    { return typename StridedAlignedMapType<Stride<Outer, Inner> >::type(data, rows, cols, stride); }
               :    //@}
               :
               :    using Base::setConstant;
               :    Derived& setConstant(Index size, const Scalar& value);
               :    Derived& setConstant(Index rows, Index cols, const Scalar& value);
               :
               :    using Base::setZero;
               :    Derived& setZero(Index size);
               :    Derived& setZero(Index rows, Index cols);
               :
               :    using Base::setOnes;
               :    Derived& setOnes(Index size);
               :    Derived& setOnes(Index rows, Index cols);
               :
               :    using Base::setRandom;
               :    Derived& setRandom(Index size);
               :    Derived& setRandom(Index rows, Index cols);
               :
               :    #ifdef EIGEN_PLAINOBJECTBASE_PLUGIN
               :    #include EIGEN_PLAINOBJECTBASE_PLUGIN
               :    #endif
               :
               :  protected:
               :    /** \internal Resizes *this in preparation for assigning \a other to it.
               :      * Takes care of doing all the checking that's needed.
               :      *
               :      * Note that copying a row-vector into a vector (and conversely) is allowed.
               :      * The resizing, if any, is then done in the appropriate way so that row-vectors
               :      * remain row-vectors and vectors remain vectors.
               :      */
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE void _resize_to_match(const EigenBase<OtherDerived>& other)
               :    {
               :      #ifdef EIGEN_NO_AUTOMATIC_RESIZING
               :      eigen_assert((this->size()==0 || (IsVectorAtCompileTime ? (this->size() == other.size())
               :                 : (rows() == other.rows() && cols() == other.cols())))
               :        && "Size mismatch. Automatic resizing is disabled because EIGEN_NO_AUTOMATIC_RESIZING is defined");
               :      EIGEN_ONLY_USED_FOR_DEBUG(other);
               :      #else
               :      resizeLike(other);
               :      #endif
               :    }
               :
               :    /**
               :      * \brief Copies the value of the expression \a other into \c *this with automatic resizing.
               :      *
               :      * *this might be resized to match the dimensions of \a other. If *this was a null matrix (not already initialized),
               :      * it will be initialized.
               :      *
               :      * Note that copying a row-vector into a vector (and conversely) is allowed.
               :      * The resizing, if any, is then done in the appropriate way so that row-vectors
               :      * remain row-vectors and vectors remain vectors.
               :      *
               :      * \sa operator=(const MatrixBase<OtherDerived>&), _set_noalias()
               :      *
               :      * \internal
               :      */
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE Derived& _set(const DenseBase<OtherDerived>& other)
               :    {
               :      _set_selector(other.derived(), typename internal::conditional<static_cast<bool>(int(OtherDerived::Flags) & EvalBeforeAssigningBit), internal::true_type, internal::false_type>::type());
               :      return this->derived();
               :    }
               :
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE void _set_selector(const OtherDerived& other, const internal::true_type&) { _set_noalias(other.eval()); }
               :
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE void _set_selector(const OtherDerived& other, const internal::false_type&) { _set_noalias(other); }
               :
               :    /** \internal Like _set() but additionally makes the assumption that no aliasing effect can happen (which
               :      * is the case when creating a new matrix) so one can enforce lazy evaluation.
               :      *
               :      * \sa operator=(const MatrixBase<OtherDerived>&), _set()
               :      */
               :    template<typename OtherDerived>
               :    EIGEN_STRONG_INLINE Derived& _set_noalias(const DenseBase<OtherDerived>& other)
               :    {
               :      // I don't think we need this resize call since the lazyAssign will anyways resize
               :      // and lazyAssign will be called by the assign selector.
               :      //_resize_to_match(other);
               :      // the 'false' below means to enforce lazy evaluation. We don't use lazyAssign() because
               :      // it wouldn't allow to copy a row-vector into a column-vector.
               :      return internal::assign_selector<Derived,OtherDerived,false>::run(this->derived(), other.derived());
               :    }
               :
               :    template<typename T0, typename T1>
               :    EIGEN_STRONG_INLINE void _init2(Index nbRows, Index nbCols, typename internal::enable_if<Base::SizeAtCompileTime!=2,T0>::type* = 0)
               :    {
               :      EIGEN_STATIC_ASSERT(bool(NumTraits<T0>::IsInteger) &&
               :                          bool(NumTraits<T1>::IsInteger),
               :                          FLOATING_POINT_ARGUMENT_PASSED__INTEGER_WAS_EXPECTED)
               :      resize(nbRows,nbCols);
               :    }
               :    template<typename T0, typename T1>
               :    EIGEN_STRONG_INLINE void _init2(const Scalar& val0, const Scalar& val1, typename internal::enable_if<Base::SizeAtCompileTime==2,T0>::type* = 0)
               :    {
               :      EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, 2)
               :      m_storage.data()[0] = val0;
               :      m_storage.data()[1] = val1;
               :    }
               :
               :    template<typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers>
               :    friend struct internal::matrix_swap_impl;
               :
               :    /** \internal generic implementation of swap for dense storage since for dynamic-sized matrices of same type it is enough to swap the
               :      * data pointers.
               :      */
               :    template<typename OtherDerived>
               :    void _swap(DenseBase<OtherDerived> const & other)
               :    {
               :      enum { SwapPointers = internal::is_same<Derived, OtherDerived>::value && Base::SizeAtCompileTime==Dynamic };
               :      internal::matrix_swap_impl<Derived, OtherDerived, bool(SwapPointers)>::run(this->derived(), other.const_cast_derived());
               :    }
               :
               :  public:
               :#ifndef EIGEN_PARSED_BY_DOXYGEN
               :    static EIGEN_STRONG_INLINE void _check_template_params()
               :    {
               :      EIGEN_STATIC_ASSERT((EIGEN_IMPLIES(MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1, (Options&RowMajor)==RowMajor)
               :                        && EIGEN_IMPLIES(MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1, (Options&RowMajor)==0)
               :                        && ((RowsAtCompileTime == Dynamic) || (RowsAtCompileTime >= 0))
               :                        && ((ColsAtCompileTime == Dynamic) || (ColsAtCompileTime >= 0))
               :                        && ((MaxRowsAtCompileTime == Dynamic) || (MaxRowsAtCompileTime >= 0))
               :                        && ((MaxColsAtCompileTime == Dynamic) || (MaxColsAtCompileTime >= 0))
               :                        && (MaxRowsAtCompileTime == RowsAtCompileTime || RowsAtCompileTime==Dynamic)
               :                        && (MaxColsAtCompileTime == ColsAtCompileTime || ColsAtCompileTime==Dynamic)
               :                        && (Options & (DontAlign|RowMajor)) == Options),
               :        INVALID_MATRIX_TEMPLATE_PARAMETERS)
               :    }
               :#endif
               :
               :private:
               :    enum { ThisConstantIsPrivateInPlainObjectBase };
               :};
               :
               :namespace internal {
               :
               :template <typename Derived, typename OtherDerived, bool IsVector>
               :struct conservative_resize_like_impl
               :{
               :  typedef typename Derived::Index Index;
               :  static void run(DenseBase<Derived>& _this, Index rows, Index cols)
               :  {
               :    if (_this.rows() == rows && _this.cols() == cols) return;
               :    EIGEN_STATIC_ASSERT_DYNAMIC_SIZE(Derived)
               :
               :    if ( ( Derived::IsRowMajor && _this.cols() == cols) || // row-major and we change only the number of rows
               :         (!Derived::IsRowMajor && _this.rows() == rows) )  // column-major and we change only the number of columns
               :    {
               :      internal::check_rows_cols_for_overflow<Derived::MaxSizeAtCompileTime>::run(rows, cols);
               :      _this.derived().m_storage.conservativeResize(rows*cols,rows,cols);
               :    }
               :    else
               :    {
               :      // The storage order does not allow us to use reallocation.
               :      typename Derived::PlainObject tmp(rows,cols);
               :      const Index common_rows = (std::min)(rows, _this.rows());
               :      const Index common_cols = (std::min)(cols, _this.cols());
               :      tmp.block(0,0,common_rows,common_cols) = _this.block(0,0,common_rows,common_cols);
               :      _this.derived().swap(tmp);
               :    }
               :  }
               :
               :  static void run(DenseBase<Derived>& _this, const DenseBase<OtherDerived>& other)
               :  {
               :    if (_this.rows() == other.rows() && _this.cols() == other.cols()) return;
               :
               :    // Note: Here is space for improvement. Basically, for conservativeResize(Index,Index),
               :    // neither RowsAtCompileTime or ColsAtCompileTime must be Dynamic. If only one of the
               :    // dimensions is dynamic, one could use either conservativeResize(Index rows, NoChange_t) or
               :    // conservativeResize(NoChange_t, Index cols). For these methods new static asserts like
               :    // EIGEN_STATIC_ASSERT_DYNAMIC_ROWS and EIGEN_STATIC_ASSERT_DYNAMIC_COLS would be good.
               :    EIGEN_STATIC_ASSERT_DYNAMIC_SIZE(Derived)
               :    EIGEN_STATIC_ASSERT_DYNAMIC_SIZE(OtherDerived)
               :
               :    if ( ( Derived::IsRowMajor && _this.cols() == other.cols()) || // row-major and we change only the number of rows
               :         (!Derived::IsRowMajor && _this.rows() == other.rows()) )  // column-major and we change only the number of columns
               :    {
               :      const Index new_rows = other.rows() - _this.rows();
               :      const Index new_cols = other.cols() - _this.cols();
               :      _this.derived().m_storage.conservativeResize(other.size(),other.rows(),other.cols());
               :      if (new_rows>0)
               :        _this.bottomRightCorner(new_rows, other.cols()) = other.bottomRows(new_rows);
               :      else if (new_cols>0)
               :        _this.bottomRightCorner(other.rows(), new_cols) = other.rightCols(new_cols);
               :    }
               :    else
               :    {
               :      // The storage order does not allow us to use reallocation.
               :      typename Derived::PlainObject tmp(other);
               :      const Index common_rows = (std::min)(tmp.rows(), _this.rows());
               :      const Index common_cols = (std::min)(tmp.cols(), _this.cols());
               :      tmp.block(0,0,common_rows,common_cols) = _this.block(0,0,common_rows,common_cols);
               :      _this.derived().swap(tmp);
               :    }
               :  }
               :};
               :
               :// Here, the specialization for vectors inherits from the general matrix case
               :// to allow calling .conservativeResize(rows,cols) on vectors.
               :template <typename Derived, typename OtherDerived>
               :struct conservative_resize_like_impl<Derived,OtherDerived,true>
               :  : conservative_resize_like_impl<Derived,OtherDerived,false>
               :{
               :  using conservative_resize_like_impl<Derived,OtherDerived,false>::run;
               :  
               :  typedef typename Derived::Index Index;
               :  static void run(DenseBase<Derived>& _this, Index size)
               :  {
               :    const Index new_rows = Derived::RowsAtCompileTime==1 ? 1 : size;
               :    const Index new_cols = Derived::RowsAtCompileTime==1 ? size : 1;
               :    _this.derived().m_storage.conservativeResize(size,new_rows,new_cols);
               :  }
               :
               :  static void run(DenseBase<Derived>& _this, const DenseBase<OtherDerived>& other)
               :  {
               :    if (_this.rows() == other.rows() && _this.cols() == other.cols()) return;
               :
               :    const Index num_new_elements = other.size() - _this.size();
               :
               :    const Index new_rows = Derived::RowsAtCompileTime==1 ? 1 : other.rows();
               :    const Index new_cols = Derived::RowsAtCompileTime==1 ? other.cols() : 1;
               :    _this.derived().m_storage.conservativeResize(other.size(),new_rows,new_cols);
               :
               :    if (num_new_elements > 0)
               :      _this.tail(num_new_elements) = other.tail(num_new_elements);
               :  }
               :};
               :
               :template<typename MatrixTypeA, typename MatrixTypeB, bool SwapPointers>
               :struct matrix_swap_impl
               :{
               :  static inline void run(MatrixTypeA& a, MatrixTypeB& b)
               :  {
               :    a.base().swap(b);
               :  }
               :};
               :
               :template<typename MatrixTypeA, typename MatrixTypeB>
               :struct matrix_swap_impl<MatrixTypeA, MatrixTypeB, true>
               :{
               :  static inline void run(MatrixTypeA& a, MatrixTypeB& b)
               :  {
               :    static_cast<typename MatrixTypeA::Base&>(a).m_storage.swap(static_cast<typename MatrixTypeB::Base&>(b).m_storage);
               :  }
               :};
               :
               :} // end namespace internal
               :
               :} // end namespace Eigen
               :
               :#endif // EIGEN_DENSESTORAGEBASE_H
/* 
 * Total samples for file : "/home/eardi/workspace/RPDE/Debug/src/../../src/Eigen/Eigen/src/Core/IO.h"
 * 
 *      1  1.3889
 */


               :// This file is part of Eigen, a lightweight C++ template library
               :// for linear algebra.
               ://
               :// Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
               :// Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
               ://
               :// This Source Code Form is subject to the terms of the Mozilla
               :// Public License v. 2.0. If a copy of the MPL was not distributed
               :// with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
               :
               :#ifndef EIGEN_IO_H
               :#define EIGEN_IO_H
               :
               :namespace Eigen { 
               :
               :enum { DontAlignCols = 1 };
               :enum { StreamPrecision = -1,
               :       FullPrecision = -2 };
               :
               :namespace internal {
               :template<typename Derived>
               :std::ostream & print_matrix(std::ostream & s, const Derived& _m, const IOFormat& fmt);
               :}
               :
               :/** \class IOFormat
               :  * \ingroup Core_Module
               :  *
               :  * \brief Stores a set of parameters controlling the way matrices are printed
               :  *
               :  * List of available parameters:
               :  *  - \b precision number of digits for floating point values, or one of the special constants \c StreamPrecision and \c FullPrecision.
               :  *                 The default is the special value \c StreamPrecision which means to use the
               :  *                 stream's own precision setting, as set for instance using \c cout.precision(3). The other special value
               :  *                 \c FullPrecision means that the number of digits will be computed to match the full precision of each floating-point
               :  *                 type.
               :  *  - \b flags an OR-ed combination of flags, the default value is 0, the only currently available flag is \c DontAlignCols which
               :  *             allows to disable the alignment of columns, resulting in faster code.
               :  *  - \b coeffSeparator string printed between two coefficients of the same row
               :  *  - \b rowSeparator string printed between two rows
               :  *  - \b rowPrefix string printed at the beginning of each row
               :  *  - \b rowSuffix string printed at the end of each row
               :  *  - \b matPrefix string printed at the beginning of the matrix
               :  *  - \b matSuffix string printed at the end of the matrix
               :  *
               :  * Example: \include IOFormat.cpp
               :  * Output: \verbinclude IOFormat.out
               :  *
               :  * \sa DenseBase::format(), class WithFormat
               :  */
     1  1.3889 :struct IOFormat
               :{
               :  /** Default contructor, see class IOFormat for the meaning of the parameters */
               :  IOFormat(int _precision = StreamPrecision, int _flags = 0,
               :    const std::string& _coeffSeparator = " ",
               :    const std::string& _rowSeparator = "\n", const std::string& _rowPrefix="", const std::string& _rowSuffix="",
               :    const std::string& _matPrefix="", const std::string& _matSuffix="")
               :  : matPrefix(_matPrefix), matSuffix(_matSuffix), rowPrefix(_rowPrefix), rowSuffix(_rowSuffix), rowSeparator(_rowSeparator),
               :    rowSpacer(""), coeffSeparator(_coeffSeparator), precision(_precision), flags(_flags)
               :  {
               :    int i = int(matSuffix.length())-1;
               :    while (i>=0 && matSuffix[i]!='\n')
               :    {
               :      rowSpacer += ' ';
               :      i--;
               :    }
               :  }
               :  std::string matPrefix, matSuffix;
               :  std::string rowPrefix, rowSuffix, rowSeparator, rowSpacer;
               :  std::string coeffSeparator;
               :  int precision;
               :  int flags;
               :};
               :
               :/** \class WithFormat
               :  * \ingroup Core_Module
               :  *
               :  * \brief Pseudo expression providing matrix output with given format
               :  *
               :  * \param ExpressionType the type of the object on which IO stream operations are performed
               :  *
               :  * This class represents an expression with stream operators controlled by a given IOFormat.
               :  * It is the return type of DenseBase::format()
               :  * and most of the time this is the only way it is used.
               :  *
               :  * See class IOFormat for some examples.
               :  *
               :  * \sa DenseBase::format(), class IOFormat
               :  */
               :template<typename ExpressionType>
               :class WithFormat
               :{
               :  public:
               :
               :    WithFormat(const ExpressionType& matrix, const IOFormat& format)
               :      : m_matrix(matrix), m_format(format)
               :    {}
               :
               :    friend std::ostream & operator << (std::ostream & s, const WithFormat& wf)
               :    {
               :      return internal::print_matrix(s, wf.m_matrix.eval(), wf.m_format);
               :    }
               :
               :  protected:
               :    const typename ExpressionType::Nested m_matrix;
               :    IOFormat m_format;
               :};
               :
               :/** \returns a WithFormat proxy object allowing to print a matrix the with given
               :  * format \a fmt.
               :  *
               :  * See class IOFormat for some examples.
               :  *
               :  * \sa class IOFormat, class WithFormat
               :  */
               :template<typename Derived>
               :inline const WithFormat<Derived>
               :DenseBase<Derived>::format(const IOFormat& fmt) const
               :{
               :  return WithFormat<Derived>(derived(), fmt);
               :}
               :
               :namespace internal {
               :
               :template<typename Scalar, bool IsInteger>
               :struct significant_decimals_default_impl
               :{
               :  typedef typename NumTraits<Scalar>::Real RealScalar;
               :  static inline int run()
               :  {
               :    using std::ceil;
               :    using std::log;
               :    return cast<RealScalar,int>(ceil(-log(NumTraits<RealScalar>::epsilon())/log(RealScalar(10))));
               :  }
               :};
               :
               :template<typename Scalar>
               :struct significant_decimals_default_impl<Scalar, true>
               :{
               :  static inline int run()
               :  {
               :    return 0;
               :  }
               :};
               :
               :template<typename Scalar>
               :struct significant_decimals_impl
               :  : significant_decimals_default_impl<Scalar, NumTraits<Scalar>::IsInteger>
               :{};
               :
               :/** \internal
               :  * print the matrix \a _m to the output stream \a s using the output format \a fmt */
               :template<typename Derived>
               :std::ostream & print_matrix(std::ostream & s, const Derived& _m, const IOFormat& fmt)
               :{
               :  if(_m.size() == 0)
               :  {
               :    s << fmt.matPrefix << fmt.matSuffix;
               :    return s;
               :  }
               :  
               :  typename Derived::Nested m = _m;
               :  typedef typename Derived::Scalar Scalar;
               :  typedef typename Derived::Index Index;
               :
               :  Index width = 0;
               :
               :  std::streamsize explicit_precision;
               :  if(fmt.precision == StreamPrecision)
               :  {
               :    explicit_precision = 0;
               :  }
               :  else if(fmt.precision == FullPrecision)
               :  {
               :    if (NumTraits<Scalar>::IsInteger)
               :    {
               :      explicit_precision = 0;
               :    }
               :    else
               :    {
               :      explicit_precision = significant_decimals_impl<Scalar>::run();
               :    }
               :  }
               :  else
               :  {
               :    explicit_precision = fmt.precision;
               :  }
               :
               :  std::streamsize old_precision = 0;
               :  if(explicit_precision) old_precision = s.precision(explicit_precision);
               :
               :  bool align_cols = !(fmt.flags & DontAlignCols);
               :  if(align_cols)
               :  {
               :    // compute the largest width
               :    for(Index j = 0; j < m.cols(); ++j)
               :      for(Index i = 0; i < m.rows(); ++i)
               :      {
               :        std::stringstream sstr;
               :        sstr.copyfmt(s);
               :        sstr << m.coeff(i,j);
               :        width = std::max<Index>(width, Index(sstr.str().length()));
               :      }
               :  }
               :  s << fmt.matPrefix;
               :  for(Index i = 0; i < m.rows(); ++i)
               :  {
               :    if (i)
               :      s << fmt.rowSpacer;
               :    s << fmt.rowPrefix;
               :    if(width) s.width(width);
               :    s << m.coeff(i, 0);
               :    for(Index j = 1; j < m.cols(); ++j)
               :    {
               :      s << fmt.coeffSeparator;
               :      if (width) s.width(width);
               :      s << m.coeff(i, j);
               :    }
               :    s << fmt.rowSuffix;
               :    if( i < m.rows() - 1)
               :      s << fmt.rowSeparator;
               :  }
               :  s << fmt.matSuffix;
               :  if(explicit_precision) s.precision(old_precision);
               :  return s;
               :}
               :
               :} // end namespace internal
               :
               :/** \relates DenseBase
               :  *
               :  * Outputs the matrix, to the given stream.
               :  *
               :  * If you wish to print the matrix with a format different than the default, use DenseBase::format().
               :  *
               :  * It is also possible to change the default format by defining EIGEN_DEFAULT_IO_FORMAT before including Eigen headers.
               :  * If not defined, this will automatically be defined to Eigen::IOFormat(), that is the Eigen::IOFormat with default parameters.
               :  *
               :  * \sa DenseBase::format()
               :  */
               :template<typename Derived>
               :std::ostream & operator <<
               :(std::ostream & s,
               : const DenseBase<Derived> & m)
               :{
               :  return internal::print_matrix(s, m.eval(), EIGEN_DEFAULT_IO_FORMAT);
               :}
               :
               :} // end namespace Eigen
               :
               :#endif // EIGEN_IO_H
/* 
 * Total samples for file : "/build/buildd/eglibc-2.19/string/../sysdeps/x86_64/multiarch/memcpy-ssse3-back.S"
 * 
 *      1  1.3889
 */


 /* __memmove_ssse3_back total:      1  1.3889 */
/* 
 * Total samples for file : "/build/buildd/eglibc-2.19/libio/strops.c"
 * 
 *      1  1.3889
 */


 /* _IO_str_init_static_internal total:      1  1.3889 */
/* 
 * Total samples for file : "/build/buildd/eglibc-2.19/elf/dl-cache.c"
 * 
 *      1  1.3889
 */


 /* _dl_load_cache_lookup total:      1  1.3889 */
/* 
 * Total samples for file : "/build/buildd/eglibc-2.19/elf/dl-addr.c"
 * 
 *      1  1.3889
 */


 /* _dl_addr total:      1  1.3889 */
